{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd0df9e",
   "metadata": {},
   "source": [
    "# Step 3: Data Collection of Indexed as retracted and Covered in\n",
    "\n",
    "This notebook contains code for finding items covered but not indexed in the database sources.\n",
    "\n",
    "Input File: \n",
    "   - retracted publications from each source\n",
    "   - unionlist of retracted publications\n",
    "       - unionlist/unionlist_with_nodoi_{date}.csv\n",
    "\n",
    "Output File: \n",
    "   - items not covered in each source\n",
    "   - items not indexed but covered in each source\n",
    "   - items not indexed nor found in each source (for PubMed items alone)\n",
    "       - coverednotindexed/pubmed_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/compendex_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/geobase_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/georef_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/inspec_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/scopus_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/webofsciencecore_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/bci_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/bioabs_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/ccc_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/medline_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/zoorec_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/crossref_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/sciencedirect_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/ieee_coverednotindexed_{coverage_date}.csv\n",
    "       - coverednotindexed/ads_coverednotindexed_{coverage_date}.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time,datetime\n",
    "import re\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from urllib.parse import urlencode # Need for ADS databases platform\n",
    "from urllib.parse import quote_plus as url_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f5f80",
   "metadata": {},
   "source": [
    "### Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the retraction_index_path\n",
    "retraction_index_path = os.path.abspath('./.')\n",
    "retraction_index_path\n",
    "\n",
    "data_dir = retraction_index_path+'/data/' # data directory\n",
    "result_dir = retraction_index_path+'/result/'\n",
    "\n",
    "# Create 'coverednotindexed' folder for coverage check in sources\n",
    "if not os.path.exists(data_dir+'coverednotindexed'): #(data+source)\n",
    "    os.mkdir(data_dir+'coverednotindexed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b2c06",
   "metadata": {},
   "source": [
    "### Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "con_file = open(retraction_index_path+\"/config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "# Initializing variable for configuration file\n",
    "my_email = config['my_email']\n",
    "elsevier_api_key = config['Elsevier_APIKEY']\n",
    "elsevier_insttoken = config['insttoken']\n",
    "ieee_xplore_api_key = config['IEEEXplore_APIKEY']\n",
    "wos_api_key = config['WoS_APIKEY']\n",
    "ads_api_key= config['ADS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc662d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global initializatiion\n",
    "global my_email\n",
    "global elsevier_api_key\n",
    "global elsevier_insttoken\n",
    "global ieee_xplore_api_key\n",
    "global wos_api_key\n",
    "global ads_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates coverage for unionlist DOIs were checked in each source\n",
    "date_coverage = {\n",
    "            'ads': '2024-08-15',\n",
    "            'crossref':'2024-08-06',\n",
    "            'retractionwatch': '', # Retraction Watch only covers retracted publications, all of which are in the unionlist. Its coverage does not need to be checked.\n",
    "            'pubmed': '2024-07-26',\n",
    "            'geobase': '2024-07-29',\n",
    "            'compendex': '2024-07-29',\n",
    "            'georef':'2024-07-30',\n",
    "            'inspec': '2024-08-02',\n",
    "            'scopus': '2024-08-02',\n",
    "            'ieee': '2024-08-07',\n",
    "                \n",
    "            'bci': '2024-08-02',\n",
    "            'bioabs': '2024-08-13',\n",
    "            'ccc': '2024-08-05',\n",
    "            'medline': '2024-08-05',\n",
    "            'zoorec': '2024-08-05',\n",
    "            'unionlist':'', # Unionlist date hardcoded in cell below.\n",
    "            'webofsciencecore': '2024-07-30',\n",
    "            'sciencedirect': '2024-08-05'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f41398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Unionlist\n",
    "\"\"\"\n",
    "\n",
    "unionlist = pd.read_csv(data_dir+f\"/unionlist/unionlist_with_nodoi_2024-07-09.csv\").drop('Unnamed: 0',axis=1)\n",
    "unionlist['PubMedID']= unionlist['PubMedID'].fillna(0).astype(int)\\\n",
    "                .replace(0,'').astype(str).str.strip()\n",
    "unionlist['DOI'].str.strip()\n",
    "unionlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba205be",
   "metadata": {},
   "source": [
    "### Filtering Unindexed Retracted Publications List for each Sources\n",
    "\n",
    "For each source except for PubMed, we use the unionlist to filter the DOI of items not found in that source. For Pubmed, we use PMID because some items have no DOI but have PMID.\n",
    "\n",
    "Output files:\n",
    "- source_doinotindexed e.g. crossref_doinotindexed.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c403956",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_sources = ['BCI', 'BIOABS', 'CCC', 'Compendex', 'Crossref', 'GEOBASE', 'Medline',\n",
    "                   'PubMed', 'Retraction Watch', 'Scopus', 'WoS_Core']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a9135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using DOI as identifier to extract items  (except PubMed in which PubMedID is used) not indexed as \n",
    "retracted publications for each source from the union_list : \n",
    "BCI','BIOABS','CCC','Compendex','Crossref', 'GEOBASE', 'Medline','PubMed', 'Retraction Watch', 'Scopus', 'WoS_Core\n",
    "\n",
    "Output overall: 'source_doi_notindexedasretracted.csv'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "bciDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'BCI',regex=True, na=False)]\n",
    "\n",
    "bioabsDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'BIOABS',regex=True, na=False)]\n",
    "\n",
    "cccDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'CCC',regex=True, na=False)]\n",
    "\n",
    "compendexDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'Compendex',regex=True, na=False)]\n",
    "\n",
    "crossrefDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'Crossref',regex=True, na=False)]\n",
    "\n",
    "\n",
    "geobaseDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'GEOBASE',regex=True, na=False)]\n",
    "\n",
    "\n",
    "medlineDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'Medline',regex=True, na=False)]\n",
    "\n",
    "retractionwatchDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'Retraction Watch',regex=True, na=False)]\n",
    "\n",
    "woscoreDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'WoS_Core',regex=True, na=False)]\n",
    "\n",
    "scopusDOI_notindexed= unionlist[~unionlist['source'].str.contains(r'Scopus',regex=True, na=False)]\n",
    "\n",
    "\n",
    "# Using PubMedID for PubMed: \n",
    "pubmedDOI_notindexed_temp = unionlist[~unionlist['source'].str.contains(r'PubMed',regex=True, na=False)]\n",
    "pubmedDOI_notindexed_temp['PubMedID']= pubmedDOI_notindexed_temp['PubMedID'].str.strip()\n",
    "pubmedDOI_notindexed = pubmedDOI_notindexed_temp[pubmedDOI_notindexed_temp['PubMedID']!='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19406d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unionlist[unionlist['source'].str.contains(r'Scopus',regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251650cf",
   "metadata": {},
   "source": [
    "## Finding items that are covered (i.e. can be found) in the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_items(pmids:list, cut:int)-> list[list]:\n",
    "    \"\"\"\n",
    "    It divides the list of items into batches for processing. \n",
    "    :param pmids: list of items \n",
    "    :param cut: maximum number of records to assign to a batch\n",
    "    \n",
    "    :return: list of pmid batches (batches are also lists)\n",
    "    \"\"\"\n",
    "    pmids_batches=[]\n",
    "    \n",
    "    while len(pmids) >= cut:\n",
    "        selected_pmids= pmids[:cut]\n",
    "        pmids_batches.append(selected_pmids)\n",
    "#         print(selected_pmids)    \n",
    "        pmids = pmids[cut:]\n",
    "\n",
    "    if pmids:\n",
    "        pmids_batches.append(pmids)\n",
    "#         print(pmids)\n",
    "\n",
    "    return pmids_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DOIs(df):\n",
    "    \"\"\"\n",
    "    It filters the DataFrame to select valid DOI\n",
    "    \n",
    "    :param df: DataFrame to work on \n",
    "    :return: list - list of valid DOIs within df\n",
    "    \"\"\"\n",
    "    df_filtered= df[df['DOI'].str.startswith('10')]\n",
    "    dois_list = df_filtered['DOI'].tolist()\n",
    "    \n",
    "    return dois_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7658ce",
   "metadata": {},
   "source": [
    "### PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c59815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pubmed_doi(pmids:list):\n",
    "    \"\"\"\n",
    "    It will check the PMIDs of items in the PMID list.\n",
    "    \n",
    "    :param pmids: list of pmids\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    \n",
    "    email = my_email # Supply your email\n",
    "    \n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": pmids,\n",
    "        \"retmode\": \"json\",\n",
    "        \"retmax\": 10000,  # Maximum number of results per request\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmedDOI_notindexed\n",
    "\"\"\"\n",
    "It calls function: check_pubmed_doi to confirm if the item's PMID is found from PubMed. It stores the results \n",
    "in pmids_covered_not_indexed, which is used to create final pubmed_doi_covered_notindexedasretracted.csv.\n",
    "\n",
    "Input: pubmedDOI_notindexed['PubMedID'].tolist() # List of PubMedIDs\n",
    "Output: 'pubmed_doi_covered_notindexedasretracted.csv'\n",
    "\"\"\"\n",
    "\n",
    "pmids_list = list(set(pubmedDOI_notindexed['PubMedID'].tolist()))\n",
    "print(f\"The total unique numbers of PubMedIDs to check coverage in PubMed is {len(pmids_list)}\")\n",
    "\n",
    "# break PMIDs in batches\n",
    "pmid_batches = batch_items(pmids_list,300)\n",
    "\n",
    "pmids_covered_not_indexed=[]\n",
    "for batch in pmid_batches:\n",
    "    dois = ','.join(batch)\n",
    "    \n",
    "    # Checking the PubMedIDs in PubMed\n",
    "    result= check_pubmed_doi(dois) \n",
    "    pmids_covered_not_indexed +=result['esearchresult']['idlist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24bac50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in PubMed:\n",
    "\n",
    "Filter PubMedIDs that have PubMed in the Unionlist.\n",
    "\n",
    "This is because the PubMedID can be messy. We can have many situations where the same PubMedID appears in multiple\n",
    "sources that include PubMed in one record and do not include PubMed in another record. Such as '25684504','15370385'\n",
    "Run a check if you would like an example:\n",
    "    unionlist[unionlist['PubMedID']== '15370385']\n",
    "This implies a PubMedID may appear as both indexed source and not indexed for different source\n",
    "    \n",
    "Hence, we filtered out 'PubMed' source from the result of the coverage check in pmids_covered_not_indexed\n",
    "\"\"\"\n",
    "\n",
    "pubmed_notin_unionlist= unionlist[unionlist['PubMedID'].isin(pmids_covered_not_indexed) & \\\n",
    "          (~unionlist['source'].str.contains('PubMed'))]\n",
    "\n",
    "pubmed_notin_unionlist\\\n",
    "#     .to_csv(data_dir+'coverednotindexed/pubmed_coverednotindexed_'+date_coverage['pubmed']+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a47585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing how PMID is inconsistent--PubMed is listed as a source in one version but not in the other.\n",
    "unionlist[unionlist['PubMedID']== '15370385']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a73829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of duplicated PMIDs from Unionlist, investigate first few.\n",
    "unionlist[unionlist['PubMedID'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72243e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "unionlist[unionlist['PubMedID']== '8989457']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error Check Encountered:\n",
    "\n",
    "First Pass: checking DOIs for coverage in PubMed on one-by-one basis\n",
    "\n",
    "PMID 27258211 \n",
    "- '10.1001/jama.2016.7190' - Scopus, retraction notice\n",
    "- '10.1001/jama.296.4.396-a' - Retraction Watch, letter from authors re: retracted article \n",
    "'Inaccurate Description of Collaborating Hospitals in a Study of the Effect of Folate and Mecobalamin on Hip Fractures After Stroke'\n",
    "- '10.1001/jama.2016.7190' - shows up when manually searching PubMed but not in unionlist.\n",
    "\n",
    "PMID 8989457\n",
    "- 10.1002/(sici)1096-8628(19961230)66:4403::aid-ajmg43.0.co;2-l - Retraction Watch, DOI not found when searched\n",
    "- 10.1002/(sici)1096-8628(19961230)66:4<403::aid-ajmg4>3.0.co;2-l - CCC, PubMed, Medline, WoS_Core, DOI resolves to\n",
    "regular article, not flagged as retracted when accessed via DOI only.\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db2cec",
   "metadata": {},
   "source": [
    " #  Engineering Village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf36352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_ev(results):   \n",
    "    \"\"\"\n",
    "    This function extracts data from the metadata result from Engineering Village API\n",
    "    \n",
    "    :param results: results return from the Engineering Village search\n",
    "    \"\"\"\n",
    "    \n",
    "    store = []\n",
    "\n",
    "    for result in results:\n",
    "        try:\n",
    "            metadata= result['EI-DOCUMENT'] # put in paper details\n",
    "\n",
    "            doi= metadata['DOCUMENTPROPERTIES'].get('DO',\"\")\n",
    "            document_type=metadata['DOCUMENTPROPERTIES'].get('DT',\"\")\n",
    "            complete_year= metadata['DOCUMENTPROPERTIES'].get('SD',\"\")\n",
    "            year= metadata['DOCUMENTPROPERTIES'].get('YR',0)\n",
    "            title= metadata['DOCUMENTPROPERTIES'].get('TI',\"\")\n",
    "            journal_title= metadata['DOCUMENTPROPERTIES'].get('SO',\"\")\n",
    "\n",
    "            database = metadata['DOC']['DB'].get('DBNAME',\"\")\n",
    "            affiliation = metadata.get('AFS',\"\")\n",
    "            author= metadata.get('AFS',\"\")\n",
    "\n",
    "            store.append([doi,document_type,year,complete_year,title, journal_title, database,\n",
    "                          author, affiliation])\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_all_DBs_check_DOI2(DOIs_lists: list, database: str)-> list:\n",
    "    \"\"\"\n",
    "    It searches and fetches records from Engineering Village API by DOI listed. It does so in batches.\n",
    "    \n",
    "    :params DOIs: list of list DOIs to be searched via the API\n",
    "    \n",
    "    :params database: indicate which of the databases e.g. 'c' indicates Compendex\n",
    "    See: https://dev.elsevier.com/documentation/EngineeringVillageAPI.wadl\n",
    "    \n",
    "        c - Compendex/EI Backfile\n",
    "        i - Inspec/Inspec Archive\n",
    "        n - NTIS\n",
    "        pc - Paperchem\n",
    "        cm - Chimica\n",
    "        cb - CBNB\n",
    "        el - EnCompassLIT\n",
    "        ep - EnCompassPAT\n",
    "        g - GEOBASE\n",
    "        f - GeoRef\n",
    "        u - US Patents\n",
    "        e - EP Patents\n",
    "        w - WO Patents\n",
    "        k - Knovel\n",
    "        \n",
    "    \"\"\"\n",
    "    c= 0\n",
    "    ev_covered_doi = []\n",
    "    ev_unresolved_doi = []\n",
    "    \n",
    "    global elsevier_api_key\n",
    "    global elsevier_insttoken\n",
    "    # Set your API key\n",
    "    api_key = elsevier_api_key\n",
    "    elsevier_insttoken = elsevier_insttoken\n",
    "    \n",
    "    # Set the request headers with the API key\n",
    "    headers = {\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-Insttoken': elsevier_insttoken\n",
    "        }\n",
    "\n",
    "        \n",
    "    # Set the base URL for the API\n",
    "    base_url = 'https://api.elsevier.com/content/ev/results?' \n",
    "\n",
    "\n",
    "    # DOI query format for coverage\n",
    "    #     q2 = '(10.1002/2016WR020060 WN DOI) OR (10.1001/archdermatol.2012 WN DOI)'\n",
    "\n",
    "\n",
    "    for batch in tqdm(DOIs_lists):\n",
    "        \n",
    "        # Formatting the DOIs in suitable Engineering Village searchable format\n",
    "        batch_formatted = ['(' + item.strip() + ' WN DOI)' for item in batch]\n",
    "        check_now_query = (' OR ').join(batch_formatted) # now formatted DOI query for EV search\n",
    "\n",
    "\n",
    "        # API request\n",
    "        response = requests.get(\n",
    "                base_url,\n",
    "                headers=headers,\n",
    "                params=urlencode({'query': check_now_query ,\n",
    "                        'database':database})) # comment the database parameters to retrieve from databases\n",
    "        #params=urlencode(params)\n",
    "\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result_per_page = response.json()\n",
    "            try: \n",
    "                if result_per_page['PAGE']['RESULTS-PER-PAGE'] is not None:\n",
    "\n",
    "                    if result_per_page['PAGE']['RESULTS-COUNT'] > 0:\n",
    "                        results = result_per_page['PAGE']['PAGE-RESULTS']['PAGE-ENTRY']\n",
    "                        \n",
    "                        # Extract metadata\n",
    "                        metadata_result = extract_metadata_ev(results)\n",
    "                        \n",
    "                        ev_covered_doi.append(metadata_result)\n",
    "                        \n",
    "            except Exception:\n",
    "                ev_unresolved_doi.append(batch)\n",
    "                print(f\"Error in processing, not API Request failure. Error in batch: {c}\")\n",
    "                pass\n",
    "\n",
    "        else: \n",
    "            ev_unresolved_doi.append(batch)\n",
    "            # If the request was not successful, print the error message\n",
    "            print(f\"Request failed with status code: {response.status_code} in batch: {c}\")\n",
    "        \n",
    "#         print('batch :',c)\n",
    "        time.sleep(0.10)\n",
    "        c+=1\n",
    "        \n",
    "    \n",
    "    return [ev_covered_doi, ev_unresolved_doi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_all_DBs_check_DOI(DOIs_list: list, database: str)-> list:\n",
    "    \"\"\"\n",
    "    It searches and fetches records from Engineering Village API by DOI listed\n",
    "    \n",
    "    :params DOIs: list of DOIs to be searched via the API\n",
    "    \n",
    "    :params database: indicate which of the databases e.g. 'c' indicates Compendex\n",
    "    See: https://dev.elsevier.com/documentation/EngineeringVillageAPI.wadl\n",
    "    \n",
    "        c - Compendex/EI Backfile\n",
    "        i - Inspec/Inspec Archive\n",
    "        n - NTIS\n",
    "        pc - Paperchem\n",
    "        cm - Chimica\n",
    "        cb - CBNB\n",
    "        el - EnCompassLIT\n",
    "        ep - EnCompassPAT\n",
    "        g - GEOBASE\n",
    "        f - GeoRef\n",
    "        u - US Patents\n",
    "        e - EP Patents\n",
    "        w - WO Patents\n",
    "        k - Knovel\n",
    "        \n",
    "    \"\"\"\n",
    "    c= 0\n",
    "    ev_covered_doi = []\n",
    "    ev_unresolved_doi = []\n",
    "    \n",
    "    global elsevier_api_key\n",
    "    global elsevier_insttoken\n",
    "    # Set your API key\n",
    "    api_key = elsevier_api_key\n",
    "    elsevier_insttoken = elsevier_insttoken\n",
    "    \n",
    "    # Set the request headers with the API key\n",
    "    headers = {\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-Insttoken':elsevier_insttoken\n",
    "        }\n",
    "\n",
    "        \n",
    "    # Set the base URL for the API\n",
    "    base_url = 'https://api.elsevier.com/content/ev/results?' \n",
    "\n",
    "\n",
    "\n",
    "    # DOI query format for coverage\n",
    "    #     q2 = '(10.1002/2016WR020060 WN DOI) OR (10.1001/archdermatol.2012 WN DOI)'\n",
    "\n",
    "\n",
    "  \n",
    "        \n",
    "    # Formatting the DOIs in suitable Engineering Village searchable format\n",
    "    batch_formatted = ['(' + item.strip() + ' WN DOI)' for item in DOIs_list]\n",
    "    check_now_query = (' OR ').join(batch_formatted) # now formatted DOI query for EV search\n",
    "\n",
    "\n",
    "    # API request\n",
    "    response = requests.get(base_url,\n",
    "                            headers=headers,\n",
    "                            params=urlencode({'query': check_now_query ,\n",
    "                            'database':database}))\n",
    "\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result_per_page = response.json()\n",
    "#         print(result_per_page)\n",
    "        try: \n",
    "            if result_per_page['PAGE']['RESULTS-PER-PAGE'] is not None:\n",
    "\n",
    "                if result_per_page['PAGE']['RESULTS-COUNT'] > 0:\n",
    "                    results = result_per_page['PAGE']['PAGE-RESULTS']['PAGE-ENTRY']\n",
    "                        \n",
    "                    # Extract metadata\n",
    "                    metadata_result = extract_metadata_ev(results)\n",
    "                        \n",
    "                    ev_covered_doi.append(metadata_result)\n",
    "                        \n",
    "        except Exception:\n",
    "            ev_unresolved_doi.append(DOIs_list)\n",
    "            print(f\"Error in processing, not API Request failure. Error in batch: {c}\")\n",
    "            pass\n",
    "\n",
    "    else: \n",
    "        ev_unresolved_doi.append(DOIs_list)\n",
    "        # If the request was not successful, print the error message\n",
    "        print(f\"Request failed with status code: {response.status_code} in batch: {c}\")\n",
    "        \n",
    "    \n",
    "    return [ev_covered_doi, ev_unresolved_doi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e816c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering Parsable DOIs. \n",
    "\n",
    "For Engineering Village DOI parsing. Some DOIs that contains any of these '()>;[\\]' characters ran into error.\n",
    "Such as:\n",
    "'10.1002/(SICI)1097-0215(19980330)76:1154::AID-IJC243.0.CO;2-B'\n",
    "'10.1002/1521-396X(200207)192:1<212::AID-PSSA212>3.0.CO;2-B'\n",
    "'10.1016/0003-4975(93)90269-n'\n",
    "\n",
    "Hence we separated those with the above characters into 'nonparsable_dois' and those that work fine into 'parsable'\n",
    "\n",
    "We tried using escape characters for items with the problem characters listed above, but it did not work\n",
    "For example, we added escape e.g: '10.1016/S2589-7004\\(19\\)30009-6' but it is not working as suggested in:\n",
    "https://solr.apache.org/guide/8_11/the-standard-query-parser.html#escaping-special-characters\n",
    "\"\"\"\n",
    "\n",
    "def get_parsable_DOI(doi_list: list):\n",
    "    \"\"\"\n",
    "    It collects doi that do not contain not any of these characters '()>;[\\]' to coverage check at source API\n",
    "    \n",
    "    :param doi_list: list of DOI for a given source\n",
    "    :return: parasable and nonparsable DOI\n",
    "    \"\"\"\n",
    "    notparsable_dois=[]\n",
    "    parsable_dois=[]\n",
    "    pattern = r'[()>;[\\]]'\n",
    "\n",
    "    for doi in doi_list:\n",
    "        if re.search(pattern, doi):\n",
    "            notparsable_dois.append(doi)\n",
    "        else:\n",
    "            parsable_dois.append(doi)\n",
    "    \n",
    "    return [parsable_dois, notparsable_dois]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking # of DOI that are parsable and nonparsable via  Engineering Village API\n",
    "\"\"\"\n",
    "ev_dois=get_DOIs(unionlist) \n",
    "parsable_ev_dois,nonparsable_ev_dois= get_parsable_DOI(ev_dois)\n",
    "\n",
    "print(f'The total DOIs that are parsable via Engineering Village API is {len(parsable_ev_dois)}')\n",
    "print(f'The total DOIs that are nonparsable via Engineering Village API is {len(nonparsable_ev_dois)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e392cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: Failed test of nonparsable DOI\n",
    "per Engineering Village API documentation: https://dev.elsevier.com/documentation/EngineeringVillageAPI.wadl\n",
    "400 - Invalid Request - This is an error that occurs when invalid information is submitted. \n",
    "\"\"\"\n",
    "#return [ev_covered_doi, ev_unresolved_doi]\n",
    "ev_all_DBs_check_DOI(['10.1016/s0928-8244(02)00344-9'],'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: Testing API for coverage check in Engineering Village, parseable DOIs\n",
    "\n",
    "Uncomment any of the last two lines to test coverage of the API \n",
    "\"\"\"\n",
    "ev_test_dois= ['10.1002/adma.202302631','10.7567/JJAP.55.05FH03','10.7863/ultra.32.11.2047','10.1001/jama.2014.7247']\n",
    "\n",
    "ev_all_DBs_check_DOI2([ev_test_dois],'c') # For Compendex\n",
    "\n",
    "# ev_all_DBs_check_DOI2([ev_test_dois],'g')  # For GEOBASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6687a",
   "metadata": {},
   "source": [
    " ## Compendex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa385820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking availability of DOIs in Compendex \n",
    "\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Engineering Village is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "ev_cut= 50\n",
    "check_doi_in_compendex= get_DOIs(compendexDOI_notindexed) \n",
    "\n",
    "# Extract parsable DOIs \n",
    "parsable_compendex_doi,nonparsable_compendex_doi= get_parsable_DOI(check_doi_in_compendex)\n",
    "\n",
    "#Break DOIs into sets\n",
    "check_doi_in_compendex_batches = batch_items(parsable_compendex_doi, ev_cut)\n",
    "\n",
    "print(f'The total DOIs that are nonparsable is {len(nonparsable_compendex_doi)}')\n",
    "print(f'The total items to search in Compendex is {len(parsable_compendex_doi)}, which are divided into {len(check_doi_in_compendex_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {ev_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parsable_compendex_doi and nonparsable_compendex_doi\n",
    "\n",
    "print(parsable_compendex_doi[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64edf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nonparsable_compendex_doi[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Checking DOIs coverage in Compendex\n",
    "\"\"\"\n",
    "\n",
    "compendex_covered_doi, compendex_unresolved_doi= [],[]\n",
    "\n",
    "for doi_list in tqdm(check_doi_in_compendex_batches[:]):\n",
    "    compendex_result= ev_all_DBs_check_DOI(doi_list,'c')\n",
    "    compendex_covered_doi.extend(compendex_result[0])\n",
    "    compendex_unresolved_doi.extend(compendex_result[1])\n",
    "    time.sleep(0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compendex_covered_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "compendex_unresolved_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d590f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Compendex:\n",
    "\n",
    "Filter DOIs that have Compendex in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "count= 0\n",
    "compendex_tempo=[]\n",
    "for batch in compendex_covered_doi:\n",
    "    compendex_tempo.extend(batch)\n",
    "    count+=len(batch)\n",
    "compendex_df_tempo= pd.DataFrame(compendex_tempo)\n",
    "compendex_df_tempo\n",
    "\n",
    "\n",
    "compendex_coveredInDOI_tempo= compendex_df_tempo.iloc[:,0].tolist()\n",
    "\n",
    "compendex_coveredInDOI_tempo = [x.lower() for x in compendex_coveredInDOI_tempo]\n",
    "\n",
    "# API can be messy: Ensure the check covered_notindexedasretracted DOI are not part of DOIs indexed as retracted in the source\n",
    "compendex_notin_unionlist= unionlist[unionlist['DOI'].isin(compendex_coveredInDOI_tempo)  & \\\n",
    "          (~unionlist['source'].str.contains('Compendex'))]\n",
    "\n",
    "compendex_notin_unionlist\\\n",
    "#     .to_csv(data_dir+'coverednotindexed/compendex_coverednotindexed_'+date_coverage['compendex']+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3782e0",
   "metadata": {},
   "source": [
    " ## GEOBASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking availability of DOIs in GEOBASE \n",
    "\n",
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Engineering Village is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "\n",
    "ev_cut= 50\n",
    "check_doi_in_geobase= get_DOIs(geobaseDOI_notindexed)\n",
    "parsable_geobase_doi,nonparsable_geobase_doi= get_parsable_DOI(check_doi_in_geobase)\n",
    "\n",
    "check_doi_in_geobase_batches = batch_items(parsable_geobase_doi, ev_cut)\n",
    "\n",
    "print(f'The total DOIs that are nonparsable is {len(nonparsable_geobase_doi)}')\n",
    "print(f'The total items to search in geobase is {len(parsable_geobase_doi)}, which are divided into {len(check_doi_in_geobase_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {ev_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Checking DOIs coverage in GEOBASE\n",
    "\"\"\"\n",
    "geobase_covered_doi, geobase_unresolved_doi= [],[]\n",
    "\n",
    "\"\"\"\n",
    "If case you run out of API requests, keep track and check your coverage in batch, and save it. \n",
    "Then merge your batch results after you complete the processing.\n",
    "\n",
    "example of batch is check_doi_in_geobase_batches[:3001] i.e. 0 to 3000 (upper bound is excluded) DOI,\n",
    "then next will start from [3001:]\n",
    "\"\"\"\n",
    "\n",
    "# If testing is needed, update batches to list \n",
    "# check_doi_in_geobase_batches[1573:1574] for testing\n",
    "\n",
    "for doi_list in tqdm(check_doi_in_geobase_batches[:]):\n",
    "    geobase_result= ev_all_DBs_check_DOI(doi_list,'g') # Checking the API\n",
    "    geobase_covered_doi.extend(geobase_result[0])\n",
    "    geobase_unresolved_doi.extend(geobase_result[1])\n",
    "    time.sleep(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "geobase_unresolved_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e681d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in GEOBASE:\n",
    "\n",
    "Filter DOIs that have geobase in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "geo_count= 0\n",
    "geobase_tempo=[]\n",
    "for batch in geobase_covered_doi: # geobase_covered_not_indexed[0] is \n",
    "    geobase_tempo.extend(batch)\n",
    "    geo_count+=len(batch)\n",
    "geobase_df_tempo= pd.DataFrame(geobase_tempo)\n",
    "geobase_df_tempo\n",
    "\n",
    "\n",
    "geobase_coveredInDOI_tempo= geobase_df_tempo.iloc[:,0].tolist() \n",
    "\n",
    "geobase_coveredInDOI_tempo = [x.lower() for x in geobase_coveredInDOI_tempo]\n",
    "\n",
    "# API can be messy: Ensure the check covered_notindexedasretracted DOI are outside of our unionlist \n",
    "geobase_notin_unionlist= unionlist[unionlist['DOI'].isin(geobase_coveredInDOI_tempo)  & \\\n",
    "          (~unionlist['source'].str.contains('geobase'))]\n",
    "\n",
    "geobase_notin_unionlist\\\n",
    "#     .to_csv(data_dir+'coverednotindexed/geobase_coverednotindexed_'+date_coverage['geobase']+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example of API Messy:\n",
    "For instance, checking coverage in GEOBASE retrieved the following DOIs below which are out of the scope\n",
    "of the our Unionlist DOIs (i.e. DOIs not the Unionlist)\n",
    "\n",
    "{'10.1002/2017jd027595',\n",
    " '10.1038/NGEO2118',\n",
    " '10.1039/d0se00033g',\n",
    " '10.1093/GJI/GGY267',\n",
    " '10.1130/G30584.1.',\n",
    " '10.1139/CJCE-2019-0536',\n",
    " '10.1190/GEO2013-0325.1',\n",
    " '10.1190/GEO2017-0028.1',\n",
    " '10.1215/1089201x-25-2-481'}\n",
    "\"\"\"\n",
    "'10.1139/CJCE-2019-0536' in parsable_geobase_doi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8785e",
   "metadata": {},
   "source": [
    "## GEOREF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking availability of DOIs in GEOREF\n",
    "\n",
    "Check the entire DOI list in the Unionlist since  GeoRef does not index retracted publication\n",
    "\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Enigineering Village is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "ev_cut= 50\n",
    "check_doi_in_georef= get_DOIs(unionlist) # Check the entire Unionlist\n",
    "\n",
    "parsable_georef_doi,nonparsable_georef_doi= get_parsable_DOI(check_doi_in_georef)\n",
    "\n",
    "check_doi_in_georef_batches = batch_items(parsable_georef_doi, ev_cut)\n",
    "\n",
    "print(f'The total DOIs that are nonparsable is {len(nonparsable_georef_doi)}')\n",
    "print(f'The total items to search in georef is {len(parsable_georef_doi)}, which are divided into {len(check_doi_in_georef_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {ev_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda55e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Checking DOIs coverage in Georef\n",
    "\"\"\"\n",
    "\n",
    "georef_covered_doi, georef_unresolved_doi= [],[]\n",
    "\n",
    "# For testing - check_doi_in_georef_batches[40:41]\n",
    "\n",
    "for doi_list in tqdm(check_doi_in_georef_batches[:]):\n",
    "    georef_result= ev_all_DBs_check_DOI(doi_list,'f') # Checking the DOIs in Georef\n",
    "    georef_covered_doi.extend(georef_result[0])\n",
    "    georef_unresolved_doi.extend(georef_result[1])\n",
    "    time.sleep(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2997f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Georef:\n",
    "\"\"\"\n",
    "# Sometimes, break checking the coverage of DOIs into two or more rounds\n",
    "\n",
    "# georef_df_tempo1= georef_df_tempo.copy(deep=True)   #check_doi_in_georef_batches[:801]\n",
    "# georef_df_tempo2= georef_df_tempo.copy(deep=True)  #check_doi_in_georef_batches[801:]\n",
    "\n",
    "# georef_df_tempo= pd.concat([georef_df_tempo1,georef_df_tempo2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03061f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "georef_unresolved_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Georef:\n",
    "\n",
    "Filter DOIs that have georef in the Unionlist.\n",
    "\n",
    "\"\"\"\n",
    "georef_count= 0\n",
    "georef_tempo=[]\n",
    "for batch in georef_covered_doi:\n",
    "    georef_tempo.extend(batch)\n",
    "    georef_count+=len(batch)\n",
    "georef_df_tempo= pd.DataFrame(georef_tempo)\n",
    "georef_df_tempo\n",
    "\n",
    "\n",
    "georef_coveredInDOI_tempo= georef_df_tempo.iloc[:,0].tolist()\n",
    "\n",
    "georef_coveredInDOI_tempo = [x.lower() for x in georef_coveredInDOI_tempo]\n",
    "\n",
    "\n",
    "# API can be messy: Ensure the check covered_notindexedasretracted DOI are not outside of our unionlist \n",
    "georef_notin_unionlist= unionlist[unionlist['DOI'].isin(georef_coveredInDOI_tempo)]\n",
    "\n",
    "georef_notin_unionlist\\\n",
    "#     .to_csv(data_dir+'coverednotindexed/georef_coverednotindexed_'+date_coverage['georef']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example of API Messy in Georef:\n",
    "For instance, checking coverage in Georef retrieved the following DOIs below which are out of the scope\n",
    "of the Unionlist DOIs (i.e. DOIs not the Unionlist)\n",
    "\n",
    "{'10.1038/nature 02699'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e50cb1",
   "metadata": {},
   "source": [
    " ## Inspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f22e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Checking availability of DOIs in Inspec \n",
    "\n",
    "Check the entire DOI in the Unionlist since Inspec does not index retracted publication\n",
    "\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Enigineering Village is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "ev_cut= 50\n",
    "check_doi_in_inspec= get_DOIs(unionlist) # Check the entire Unionlist\n",
    "\n",
    "parsable_inspec_doi,nonparsable_inspec_doi= get_parsable_DOI(check_doi_in_inspec)\n",
    "\n",
    "check_doi_in_inspec_batches = batch_items(parsable_inspec_doi, ev_cut)\n",
    "\n",
    "print(f'The total DOIs that are nonparsable is {len(nonparsable_inspec_doi)}')\n",
    "print(f'The total items to search in inspec is {len(parsable_inspec_doi)}, which are divided into {len(check_doi_in_inspec_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {ev_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Checking DOIs coverage in Inspec\n",
    "\n",
    "In case you ran out of API request, continue from where you left after 24 hours and merge your results\n",
    "\"\"\"\n",
    "\n",
    "inspec_covered_doi, inspec_unresolved_doi= [],[]\n",
    "for doi_list in tqdm(check_doi_in_inspec_batches[:]):\n",
    "    inspec_result= ev_all_DBs_check_DOI(doi_list,'i')\n",
    "    inspec_covered_doi.extend(inspec_result[0])\n",
    "    inspec_unresolved_doi.extend(inspec_result[1])\n",
    "    time.sleep(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c62d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Inspec:\n",
    "\"\"\"\n",
    "\n",
    "inspec_count= 0\n",
    "inspec_tempo=[]\n",
    "for batch in inspec_covered_doi: \n",
    "    inspec_tempo.extend(batch)\n",
    "    inspec_count+=len(batch)\n",
    "inspec_df_tempo= pd.DataFrame(inspec_tempo)\n",
    "inspec_df_tempo\n",
    "#inspec_df_tempo1= inspec_df_tempo.copy(deep=True)  #9785\n",
    "#inspec_df_tempo2= inspec_df_tempo.copy(deep=True) #4027\n",
    "#inspec_df_tempo3= inspec_df_tempo.copy(deep=True) #575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05662112",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Inspec:\n",
    "\"\"\"\n",
    "\n",
    "# inspec_df_tempo = inspec_df_tempo1[0].tolist() + inspec_df_tempo2[0].tolist() + inspec_df_tempo3[0].tolist()\n",
    "\n",
    "inspec_coveredInDOI_tempo= inspec_df_tempo.iloc[:,0].tolist() \n",
    "\n",
    "inspec_coveredInDOI_tempo = [x.lower() for x in inspec_coveredInDOI_tempo]\n",
    "\n",
    "# API can be messy: Ensure the check covered_notindexedasretracted DOI are outside of our unionlist \n",
    "inspec_notin_unionlist= unionlist[unionlist['DOI'].isin(inspec_coveredInDOI_tempo)]\n",
    "\n",
    "inspec_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/inspec_coverednotindexed_'+date_coverage['inspec']+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f875a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example of API Messy in Inspec :\n",
    "For instance, in prior runs, checking coverage in Inspec retrieved the following DOIs (41) below which are out of \n",
    "the scope of our Unoinlist DOIs (i.e. DOIs not the Unionlist)\n",
    "\n",
    "{'10.1007/S10853-006-1486-5', '10.1117/1.JEI.31.6.061802', '10.1039/c8tc03423k', '10.1039/c5ta01191d', \n",
    "'10.1007/BF00613233', '10.1039/c7ta02733h', '10.1111/J.1467-6486.2010.00994.X', '10.1007/s12083-021-01138-x', \n",
    "'10.1039/c6ta08172j', '10.1039/c6ta11168h', '10.1039/c5ta04288g', '10.1557/JMR.2006.0380', \n",
    "'10.1190/GEO2013-0325.1', '10.1039/c6ta07859a', '10.1038/NMAT3256', '10.1039/c3cy00214d', \n",
    "'10.1039/c3tb21558j', '10.1039/c3tc00082f', '10.1038/NPHOTON.2010.2', '10.1039/c7ta05459a', \n",
    "'10.1039/c7tc03449k', '10.1109/ICETA.2011.6112609', '10.1039/c7ta02116j', '10.1134/S0021364018140138', \n",
    "'10.1515/secm-2012-0053', '10.1134/S1063772918130012', '10.1109/ICNDS.2010.5479348', '10.1039/c7py01218g', \n",
    "'10.1039/c3ta13906a', '10.1557/JMR.2007.0087', '10.1039/c6tb01306f', '10.1039/d1qi00733e', '10.1039/c2nr30460k',\n",
    "'10.1039/c2ta00015f', '10.1039/c5ta06387f', '10.1039/c7ta04927g', '10.1039/c3tb20262c', '10.1039/c2jm16106k', \n",
    "'10.1039/c4cy01331j', '10.1039/c3tb21363c', '10.4028/www.scientific.net/AMM.217.219.1077'}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "set(inspec_coveredInDOI_tempo) - set(inspec_notin_unionlist['DOI'])\n",
    "\n",
    "#'10.1007/S10853-006-1486-5' in unionlist['DOI'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspec_unresolved_doi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54025a9f",
   "metadata": {},
   "source": [
    "# Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 25 items in each batch. \n",
    "The limit per page for Scopus is 25 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "scopus_cut= 25\n",
    "check_doi_in_scopus= scopusDOI_notindexed['DOI'].tolist() # change scopus to notindexedasretracted_source\n",
    "\n",
    "# Extract parsable DOIs \n",
    "# parsable_scopus_doi,nonparsable_scopus_doi= get_parsable_DOI(check_doi_in_scopus)\n",
    "\n",
    "check_doi_in_scopus_batches = batch_items(check_doi_in_scopus, scopus_cut) #check_doi_in_scopus\n",
    "\n",
    "\n",
    "print(f'The total items to search in Scopus is {len(check_doi_in_scopus)}, which are divided into {len(check_doi_in_scopus_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {scopus_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aabb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking DOIs coverage in Scopus\n",
    "\"\"\"\n",
    "\n",
    "scopus_covered_doi = []\n",
    "scopus_unresolved_doi = []\n",
    "\n",
    "# Set your API key\n",
    "api_key = elsevier_api_key\n",
    "elsevier_insttoken = elsevier_insttoken\n",
    "\n",
    "url_base = \"https://api.elsevier.com/content/search/scopus\" \n",
    "headers = {\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-Insttoken':elsevier_insttoken}\n",
    "\n",
    "\n",
    "for batch in tqdm(check_doi_in_scopus_batches[:]):\n",
    "    \n",
    "    # Putting search format 'DOI(10.1038/s41598-023-31439-5) OR DOI(...)'\n",
    "    check_now = ' OR '.join(f'DOI({doi})' for doi in batch) \n",
    "    params= {\"query\": check_now}\n",
    "        \n",
    "    response = requests.get(url_base,\n",
    "                        headers= headers,\n",
    "                    params = params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "\n",
    "        store=[]\n",
    "            \n",
    "        totalresult= int(results['search-results'].get('opensearch:totalResults',0))\n",
    "    \n",
    "        if totalresult > 0:\n",
    "        \n",
    "            try:\n",
    "                for result in results['search-results']['entry']:\n",
    "                    try:\n",
    "                        store.append(result['prism:doi'])\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                        scopus_unresolved_doi.extend(batch)\n",
    "            except KeyError:\n",
    "                pass\n",
    "    else:\n",
    "        scopus_unresolved_doi.extend(batch)\n",
    "\n",
    "    scopus_covered_doi.extend(store)\n",
    "    \n",
    "    time.sleep(0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Scopus:\n",
    "\n",
    "Filter DOIs that have Scopus in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "scopus_coveredInDOI_tempo= scopus_covered_doi\n",
    "\n",
    "scopus_coveredInDOI_tempo= [x.strip().lower() for x in scopus_coveredInDOI_tempo]\n",
    "\n",
    "# API can be messy: Ensure the check covered_notindexedasretracted DOI are outside our unionlist \n",
    "scopus_notin_unionlist= unionlist[unionlist['DOI'].isin(scopus_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('Scopus'))]\n",
    "\n",
    "scopus_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/scopus_coverednotindexed_'+date_coverage['scopus']+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No out scope doi in scopus coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721bf0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(scopus_coveredInDOI_tempo) - set(scopus_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6472a78",
   "metadata": {},
   "source": [
    "# Web of Science Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wos_all_DBs_check_DOI(DOIs_lists: list, database:str):\n",
    "    \"\"\"\n",
    "    It checks the coverage of DOI in the Web of Science\n",
    "    \n",
    "    :param DOIs_lists: list of list of DOIs preformatted to query form for Web of Science use\n",
    "    :param database: specifies the database to search\n",
    "    \n",
    "    :return: list of lists [available DOIs, DOIs that ran into error]\n",
    "    \n",
    "    \"\"\"\n",
    "    c=0\n",
    "    wos_covered_doi = []\n",
    "    wos_unresolved_doi = []\n",
    "\n",
    "    # Define your API key\n",
    "    WoS_api_key = wos_api_key\n",
    "\n",
    "\n",
    "    # Set the headers with the API key\n",
    "    headers = {\n",
    "            'X-ApiKey': WoS_api_key,\n",
    "            'charset': 'UTF-8',\n",
    "            'Encoding': 'UTF-8',\n",
    "            'content-type':'text/xml'\n",
    "            }\n",
    "#     base_url = 'https://api.clarivate.com/apis/wos-starter/v1/documents' \n",
    "    url = 'https://api.clarivate.com/apis/wos-starter/v1/documents'\n",
    "\n",
    "    for batch in tqdm(DOIs_lists):\n",
    "        check_now = ' OR '.join(f'DO=({doi})' for doi in batch) \n",
    "#         print(check_now)\n",
    "\n",
    "        params = {\n",
    "            'db': database, #'WOK',#'WOS',\n",
    "            'q': check_now,\n",
    "            'limit': 50\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        # Make the API request\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        # Check if the request was successful (200 status code)\n",
    "        if response.status_code == 200:\n",
    "#             print('success')\n",
    "            # Extract the response content as JSON\n",
    "            data = response.json()\n",
    "            # Print the DOI details\n",
    "            try:\n",
    "                dois_result = data['hits']\n",
    "                for doi in dois_result:\n",
    "                    try:\n",
    "                        if doi.get('identifiers'):\n",
    "                            identifiers = doi.get('identifiers','')\n",
    "                            DOI= identifiers.get('doi','')\n",
    "                            wos_covered_doi.append(DOI)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "                wos_unresolved_doi.append(check_now)\n",
    "\n",
    "        else:\n",
    "            # If the request was not successful, print the error message\n",
    "            print(f\"Request failed with status code: {response.status_code} in batch: {c}\")\n",
    "            #print(response.text)\n",
    "\n",
    "        time.sleep(0.15)\n",
    "        #print('batch: ',c)\n",
    "        c+=1 \n",
    "        \n",
    "    return [wos_covered_doi,wos_unresolved_doi]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cc479",
   "metadata": {},
   "source": [
    "### Web of Science Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "check_doi_in_woscore= get_DOIs(woscoreDOI_notindexed) #woscoreDOI_notindexed['DOI'].tolist()# change doilist_wos to notindexedasretracted_source\n",
    "\n",
    "check_doi_in_woscore_batches = batch_items(check_doi_in_woscore, wos_cut)\n",
    "\n",
    "print(f'The total items to search in Web of Science Core is {len(check_doi_in_woscore)}, which are divided into {len(check_doi_in_woscore_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOIs Coverage in Web of Science Core\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "\n",
    "woscore_results= wos_all_DBs_check_DOI(check_doi_in_woscore_batches, 'WOS')\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Web of Science Core:\n",
    "\n",
    "Filter DOIs that have Web of Science Core in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "wos_core_coveredInDOI_tempo= woscore_results[0] \n",
    "\n",
    "wos_core_coveredInDOI_tempo= [x.strip().lower() for x in wos_core_coveredInDOI_tempo]\n",
    "\n",
    "\n",
    "\n",
    "wos_core_notin_unionlist= unionlist[unionlist['DOI'].isin(wos_core_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('WoS_Core'))]\n",
    "\n",
    "wos_core_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/webofsciencecore_coverednotindexed_'+date_coverage['webofsciencecore']+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b17bb",
   "metadata": {},
   "source": [
    "### BCI - BIOSIS Citation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "check_doi_in_bci= get_DOIs(bciDOI_notindexed) #bciDOI_notindexed['DOI'].tolist()# change doilist_bci to notindexedasretracted_source\n",
    "\n",
    "# Remove this DOI causing WoS API Error  - status code: 400\n",
    "rm_doi = '10.1061/(asce)0733-9399(2010)136:2(174)'\n",
    "check_doi_in_bci = [x for x in check_doi_in_bci if x != rm_doi]\n",
    "\n",
    "check_doi_in_bci_batches = batch_items(check_doi_in_bci, wos_cut) #check_doi_in_bci_batches\n",
    "\n",
    "print(f'The total items to search in BCI is {len(check_doi_in_bci)}, which are divided into {len(check_doi_in_bci_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51998829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Troubleshooting errors in DOIs:\n",
    "Previous run:\n",
    "batch351: '10.1038/embor.2009.88 |' caused error. From Retraction Watch.\n",
    "batch393: '10.1061/(ASCE)0733-9399(2010)136:2(174)' caused error. From Retraction Watch and WoS_Core.\n",
    "Current run:\n",
    "batch491: '10.1061/(asce)0733-9399(2010)136:2(174)' caused error. From WoS_Core and Retraction Watch.\n",
    "\n",
    "# Troublshooting\n",
    "check_doi_in_bci_batches[411]\n",
    "unionlist[unionlist['DOI']=='10.1061/(ASCE)0733-9399(2010)136:2(174)']\n",
    "\"\"\"\n",
    "# wos_all_DBs_check_DOI([['10.1038/embor.2009.88 |']], 'BCI') #\n",
    "wos_all_DBs_check_DOI([['10.1061/(asce)0733-9399(2010)136:2(174)']], 'BCI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbaf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unionlist[unionlist['DOI']=='10.1061/(asce)0733-9399(2010)136:2(174)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "unionlist[unionlist['DOI']=='10.1038/embor.2009.88 |']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOIs Coverage in BCI\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "\n",
    "bci_results= wos_all_DBs_check_DOI(check_doi_in_bci_batches, 'BCI')\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in BIOSIS Citation Index\n",
    "\n",
    "Filter DOIs that have BCI in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "bci_coveredInDOI_tempo= bci_results[0] \n",
    "\n",
    "bci_coveredInDOI_tempo= [x.strip().lower() for x in bci_coveredInDOI_tempo]\n",
    "\n",
    "bci_notin_unionlist= unionlist[unionlist['DOI'].isin(bci_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('BCI'))]\n",
    "\n",
    "bci_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/bci_coverednotindexed_'+date_coverage['bci']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bci_coveredInDOI_tempo) - set(bci_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e616f6",
   "metadata": {},
   "source": [
    "### BIOABS - Biological Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "check_doi_in_bioabs= get_DOIs(bioabsDOI_notindexed) # get valid DOIs from bioabsDOI_notindexed #['DOI'].tolist()# change doilist_bioabs to notindexedasretracted_source\n",
    "\n",
    "# Remove this DOI causing WoS API Error  - status code: 400\n",
    "rm_doi = '10.1061/(asce)0733-9399(2010)136:2(174)'\n",
    "check_doi_in_bioabs = [x for x in check_doi_in_bioabs if x != rm_doi]\n",
    "\n",
    "check_doi_in_bioabs_batches = batch_items(check_doi_in_bioabs, wos_cut) #check_doi_in_bioabs_batches\n",
    "\n",
    "print(f'The total items to search in BIOABS is {len(check_doi_in_bioabs)}, which are divided into {len(check_doi_in_bioabs_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c267dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOIs Coverage in BIOABS\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "\n",
    "bioabs_results= wos_all_DBs_check_DOI(check_doi_in_bioabs_batches, 'BIOABS')\n",
    "\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Biological Abstracts\n",
    "\n",
    "Filter DOIs that have Biological Abstract in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "bioabs_coveredInDOI_tempo= bioabs_results[0]\n",
    "\n",
    "bioabs_coveredInDOI_tempo = [x.lower() for x in bioabs_coveredInDOI_tempo]\n",
    "\n",
    "bioabs_notin_unionlist= unionlist[unionlist['DOI'].isin(bioabs_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('BIOABS'))]\n",
    "\n",
    "bioabs_notin_unionlist\\\n",
    "#     .to_csv(data_dir+'coverednotindexed/bioabs_coverednotindexed_'+date_coverage['bioabs']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bioabs_coveredInDOI_tempo) - set(bioabs_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"API Messy in BIOABS\n",
    "Returned DOI 10.1002/cbic.201190007 when not in the DOIs originally requested.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34b5e6",
   "metadata": {},
   "source": [
    "### MEDLINE - Medical Literature Analysis and Retrieval System Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "check_doi_in_medline=  get_DOIs(medlineDOI_notindexed)\n",
    "\n",
    "# Remove DOIs that cause error\n",
    "error_dois= ['10.1038/embor.2009.88 |','10.1061/(asce)0733-9399(2010)136:2(174)']\n",
    "check_doi_in_medline[:] = [doi for doi in check_doi_in_medline if doi not in error_dois]\n",
    "\n",
    "check_doi_in_medline_batches = batch_items(check_doi_in_medline, wos_cut) #check_doi_in_woscore_batches\n",
    "\n",
    "print(f'The total items to search in Medline is {len(check_doi_in_medline)}, which are divided into {len(check_doi_in_medline_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOIs Coverage in Medline\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "\n",
    "medline_results= wos_all_DBs_check_DOI(check_doi_in_medline_batches[:], 'MEDLINE')\n",
    "\n",
    "end = time.time()\n",
    "end - start  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Medline\n",
    "\n",
    "Filter DOIs that have Medline in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "medline_coveredInDOI_tempo= medline_results[0]\n",
    "\n",
    "medline_coveredInDOI_tempo= [x.lower() for x in medline_coveredInDOI_tempo]\n",
    "\n",
    "medline_notin_unionlist= unionlist[unionlist['DOI'].isin(medline_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('Medline'))]\n",
    "\n",
    "medline_notin_unionlist \\\n",
    "#       .to_csv(data_dir+'coverednotindexed/medline_coverednotindexed_'+date_coverage['medline']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(medline_coveredInDOI_tempo) - set(medline_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b2f69",
   "metadata": {},
   "source": [
    "### CCC - Current Contents Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wos_ccc_check_DOI(DOIs_lists: list):\n",
    "    \"\"\"\n",
    "    It checks the coverage of DOI in the Current Contents Connect (1998-present) only \n",
    "    CCC is part of databases in the Web of Science Platform\n",
    "    \n",
    "    :param DOIs_lists: list of list of DOIs preformatted to query form for Web of Science use\n",
    "    :param database: specific the database to search, preset to Web of Knowledge (all WoS Platform)\n",
    "    \n",
    "    :return: list of list [available DOIs, DOIs that ran into error]\n",
    "    \n",
    "    \"\"\"\n",
    "    c=0\n",
    "    wos_covered_doi = []\n",
    "    wos_unresolved_doi = []\n",
    "\n",
    "    # Define your API key\n",
    "    WoS_api_key = wos_api_key\n",
    "\n",
    "\n",
    "    # Set the headers with the API key\n",
    "    headers = {\n",
    "            'X-ApiKey': WoS_api_key,\n",
    "            'charset': 'UTF-8',\n",
    "            'Encoding': 'UTF-8',\n",
    "            'content-type':'text/xml'\n",
    "            }\n",
    "    url = 'https://api.clarivate.com/apis/wos-starter/v1/documents'\n",
    "\n",
    "    for batch in tqdm(DOIs_lists):\n",
    "        formatted_dois= ' OR '.join(f'DO=({doi})' for doi in batch) \n",
    "#         print(formatted_dois)\n",
    "        \n",
    "        # Searching the WOK database and filtering for result with CCC database\n",
    "        query= f\"{formatted_dois} AND UT=CCC:*\" \n",
    "\n",
    "        params = {\n",
    "            'db': 'WOK', #'WOK',#'WOS',\n",
    "            'q': query,\n",
    "            'limit': 50\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        # Make the API request\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        # Check if the request was successful (200 status code)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the response content as JSON\n",
    "            data = response.json()\n",
    "#             print(data)\n",
    "            # Print the DOI details\n",
    "            try:\n",
    "                dois_result = data['hits']\n",
    "                for doi in dois_result:\n",
    "                    try:\n",
    "                        if doi.get('identifiers'):\n",
    "                            identifiers = doi.get('identifiers','')\n",
    "                            DOI= identifiers.get('doi','')\n",
    "                            wos_covered_doi.append(DOI) #wos_covered_doi\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "                wos_unresolved_doi.append(check_now)\n",
    "        else:\n",
    "            # If the request was not successful, print the error message\n",
    "            print(f\"Request failed with status code: {response.status_code} in batch: {c}\")\n",
    "            #print(response.text)\n",
    "\n",
    "        time.sleep(0.20)\n",
    "        #print('batch: ',c)\n",
    "        c+=1 \n",
    "        \n",
    "    return [wos_covered_doi,wos_unresolved_doi]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8158f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "check_doi_in_ccc= get_DOIs(cccDOI_notindexed) # get valid DOIs from cccDOI_notindexed\n",
    "\n",
    "# Remove DOIs that cause error\n",
    "error_dois= ['10.1038/embor.2009.88 |','10.1061/(asce)0733-9399(2010)136:2(174)']\n",
    "check_doi_in_ccc[:] = [doi for doi in check_doi_in_ccc if doi not in error_dois]\n",
    "\n",
    "check_doi_in_ccc_batches = batch_items(check_doi_in_ccc, wos_cut) #check_doi_in_ccc_batches\n",
    "\n",
    "print(f'The total items to search in CCC is {len(check_doi_in_ccc)}, which are divided into {len(check_doi_in_ccc_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a495c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOIs Coverage in CCC\n",
    "\"\"\"\n",
    "ccc_results= wos_ccc_check_DOI(check_doi_in_ccc_batches[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a21bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example of prior batching\"\"\"\n",
    "# ccc_results_tempo1= ccc_results[0]  #17874\n",
    "# ccc_results_tempo2= ccc_results[0] #14526\n",
    "# ccc_results_tempo3= ccc_results[0] #17509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Current Contents Connect\n",
    "\n",
    "Filter DOIs that have CCC in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "ccc_coveredInDOI_tempo=  ccc_results[0] # +ccc_results_tempo1[0] +ccc_results_tempo2[0] + ccc_results_tempo3[0]\n",
    "\n",
    "ccc_coveredInDOI_tempo = [x.lower() for x in ccc_coveredInDOI_tempo] # Put all DOIs covered in lowercase\n",
    "\n",
    "\n",
    "ccc_notin_unionlist= unionlist[unionlist['DOI'].isin(ccc_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('CCC'))]\n",
    "\n",
    "ccc_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/ccc_coverednotindexed_'+date_coverage['ccc']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ccc_coveredInDOI_tempo) - set(ccc_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ccc_coveredInDOI_tempo) - set(ccc_notin_unionlist['DOI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f9f7b",
   "metadata": {},
   "source": [
    "### Zoological Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wos_zoorec_check_DOI(PMIDs_lists: list):\n",
    "    \"\"\"\n",
    "    It checks the coverage of DOI in the Zoological Record (1864-present) only using PubMedID\n",
    "    ZOOREC is part of databases in the Web of Science Platform\n",
    "    \n",
    "    :param DOIs_lists: list of list of DOIs preformatted to query form for Web of Science use\n",
    "    :param database: specific the database to search\n",
    "    \n",
    "    :return: list of list [available DOIs, DOIs that ran into error]   \n",
    "    \"\"\"\n",
    "    c=0\n",
    "\n",
    "    wos_covered_pmid= []\n",
    "    wos_unresolved_pmid= []\n",
    "\n",
    "    # Define your API key\n",
    "    WoS_api_key = wos_api_key\n",
    "\n",
    "\n",
    "    # Set the headers with the API key\n",
    "    headers = {\n",
    "            'X-ApiKey': WoS_api_key,\n",
    "            'charset': 'UTF-8',\n",
    "            'Encoding': 'UTF-8',\n",
    "            'content-type':'text/xml'\n",
    "            }\n",
    "    url = 'https://api.clarivate.com/apis/wos-starter/v1/documents'\n",
    "\n",
    "    for batch in tqdm(PMIDs_lists):\n",
    "        formatted_pmids= str(\",\".join(f'\"{pmid}\"' for pmid in batch))\n",
    "        query= f'PMID=({formatted_pmids})'\n",
    "#         print(query)\n",
    "\n",
    "#         print(formatted_pmids)\n",
    "\n",
    "        params = {\n",
    "            'db': 'ZOOREC', #'WOK',#'WOS',\n",
    "            'q': query,\n",
    "            'limit': 50\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        # Make the API request\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        # Check if the request was successful (200 status code)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the response content as JSON\n",
    "            data = response.json()\n",
    "#             print(data)\n",
    "            # Print the DOI details\n",
    "            try:\n",
    "                pmids_result = data['hits']\n",
    "                for pmid in pmids_result:\n",
    "\n",
    "                    try:\n",
    "                        if pmid.get('identifiers'):\n",
    "                            identifiers = pmid.get('identifiers','')\n",
    "                            PMID= identifiers.get('pmid','')\n",
    "\n",
    "                            wos_covered_pmid.append(PMID) #wos_covered_doi\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            except Exception:\n",
    "                pass\n",
    "                wos_unresolved_pmid.append(batch)\n",
    "        else:\n",
    "            # If the request was not successful, print the error message\n",
    "            print(f\"Request failed with status code: {response.status_code} in batch: {c}\")\n",
    "            #print(response.text)\n",
    "\n",
    "        time.sleep(0.20)\n",
    "        #print('batch: ',c)\n",
    "        c+=1 \n",
    "        \n",
    "    return [wos_covered_pmid,wos_unresolved_pmid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Break the list of DOIs to search into batches of a maximum of 50 items in each batch. \n",
    "The limit per page for Web of Science is 50 items at a time.\n",
    "\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "wos_cut= 50\n",
    "\n",
    "check_pmid_in_zoorec_= unionlist[unionlist['PubMedID']!='']['PubMedID'].tolist() # Check the entire Unionlist items that has PubMedID\n",
    "\n",
    "check_pmid_in_zoorec = list(set(check_pmid_in_zoorec_))\n",
    "\n",
    "check_pmid_in_zoorec_batches = batch_items(check_pmid_in_zoorec, wos_cut) #check_doi_in_ccc_batches\n",
    "\n",
    "print(f'The total items (PubMedID) to search in ZOOREC is {len(check_pmid_in_zoorec_)}')\n",
    "print(f'The total items (unique PubMedIDs) to search in ZOOREC is {len(check_pmid_in_zoorec)}, which are divided into {len(check_pmid_in_zoorec_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {wos_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check PMIDs Coverage in Zoological Record\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "zoorec_results= wos_zoorec_check_DOI(check_pmid_in_zoorec_batches[:])\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41638193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Zoological Record Information\n",
    "\n",
    "Filter PMIDs that have ZOOREC in the Unionlist.\n",
    "\"\"\"\n",
    "\n",
    "zoorec_coveredInDOI_tempo= zoorec_results[0]\n",
    "\n",
    "zoorec_notin_unionlist= unionlist[unionlist['PubMedID'].isin(zoorec_coveredInDOI_tempo)]\n",
    "\n",
    "zoorec_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/zoorec_coverednotindexed_'+date_coverage['zoorec']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(zoorec_coveredInDOI_tempo) - set(zoorec_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(zoorec_coveredInDOI_tempo) - set(zoorec_notin_unionlist['DOI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c9183",
   "metadata": {},
   "source": [
    "# Crossref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36820374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossref.restful import Works, Etiquette\n",
    "\n",
    "# Format for Etiquette\n",
    "# given_etiquette = Etiquette('My Project Name', 'My Project version', 'My Project URL', 'My contact email')\n",
    "\n",
    "my_etiquette = Etiquette('Retraction Indexing Assessment', 'version2', 'no url', my_email)\n",
    "works = Works(etiquette=my_etiquette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get list of DOIs to search \n",
    "\n",
    "Input:\n",
    "    crossrefDOI_notindexed\n",
    "Saved_file:\n",
    "    crossref_coverednotindexed_<date>.csv\n",
    "\"\"\"\n",
    "\n",
    "check_doi_in_crossref= get_DOIs(crossrefDOI_notindexed) \n",
    "print(f'The total items to search in Crossref is {len(check_doi_in_crossref)} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e109ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOI Coverage in Crossref\n",
    "\"\"\"\n",
    "\n",
    "new = Works()\n",
    "start = time.time()\n",
    "\n",
    "crossref_covered_doi=[]\n",
    "\n",
    "\n",
    "for i in tqdm(check_doi_in_crossref[42000:]):\n",
    "    try:\n",
    "        for j in new.filter(doi = i).select('DOI'):\n",
    "            find = j['DOI']\n",
    "            if i == find:\n",
    "                crossref_covered_doi.append(i)\n",
    "\n",
    "    except Exception:\n",
    "            pass\n",
    "    time.sleep(0.10)\n",
    "        #print(i)\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can break the checking of the DOI coverage into cycles\n",
    "\"\"\"\n",
    "# crossref_covered_doi_tempo1= crossref_covered_doi.copy() # [:15000], changed csv filename to 1_crossref_coverednotindexed_2024-08-06\n",
    "# crossref_covered_doi_tempo2= crossref_covered_doi.copy() # [15000:30000], changed csv filename to 2_crossref_coverednotindexed_2024-08-06\n",
    "# crossref_covered_doi_tempo3= crossref_covered_doi.copy() # [30000:35000], changed csv filename to 3_crossref_coverednotindexed_2024-08-06\n",
    "# crossref_covered_doi_tempo4= crossref_covered_doi.copy() # [35000:42000], changed csv filename to 4_crossref_coverednotindexed_2024-08-06\n",
    "# crossref_covered_doi_tempo5= crossref_covered_doi.copy() # [42000:], changed csv filename to 5_crossref_coverednotindexed_2024-08-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crossref_covered_doi_tempo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20844182",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crossref_covered_doi_tempo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e793cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crossref_covered_doi_tempo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf51aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crossref_covered_doi_tempo4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb795483",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crossref_covered_doi_tempo5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in Crossref\n",
    "\"\"\"\n",
    "# Getting the DOIs of the matched items in Crossref\n",
    "\n",
    "crossref_coveredInDOI_tempo= crossref_covered_doi_tempo1 + crossref_covered_doi_tempo2 + crossref_covered_doi_tempo3 + crossref_covered_doi_tempo4 + crossref_covered_doi_tempo5 \n",
    "crossref_coveredInDOI_tempo=  [x.lower() for x in crossref_coveredInDOI_tempo]\n",
    "\n",
    "crossref_notin_unionlist= unionlist[unionlist['DOI'].isin(crossref_coveredInDOI_tempo) & \\\n",
    "          (~unionlist['source'].str.contains('Crossref'))]\n",
    "\n",
    "crossref_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/crossref_coverednotindexed_'+date_coverage['crossref']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e19d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(crossref_coveredInDOI_tempo) - set(crossref_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(crossref_coveredInDOI_tempo) - set(crossref_notin_unionlist['DOI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unionlist[unionlist['source'].str.contains('Crossref')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d143e10",
   "metadata": {},
   "source": [
    "# ScienceDirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fd1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "    cut: maximum number items in a batch\n",
    "\"\"\"\n",
    "scidirect_cut= 50\n",
    "check_doi_in_sciencedirect= get_DOIs(unionlist) # get valid DOIs\n",
    "\n",
    "check_doi_in_sciencedirect_batches = batch_items(check_doi_in_sciencedirect, scidirect_cut)\n",
    "\n",
    "print(f'The total items to search in ScienceDirect is {len(check_doi_in_sciencedirect)}, which are divided into {len(check_doi_in_sciencedirect_batches)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {scidirect_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3122a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_DOI_ScienceDirect(dois_list:list):   \n",
    "    \"\"\"\n",
    "    It checks DOI if it exist in a ScienceDirect\n",
    "    \n",
    "    :param dois_list: DOIs to check their coverage\n",
    "    \n",
    "    Reference:\n",
    "    - https://dev.elsevier.com/documentation/ArticleMetadataAPI.wadl\n",
    "    - https://dev.elsevier.com/sd_article_meta_tips.html\n",
    "    \"\"\"\n",
    "    \n",
    "    global elsevier_api_key\n",
    "    global elsevier_insttoken\n",
    "    store_result= []\n",
    "    unresolved_doi= []\n",
    "    \n",
    "    api_key = elsevier_api_key\n",
    "    elsevier_insttoken = elsevier_insttoken\n",
    "\n",
    "\n",
    "    base_url= 'https://api.elsevier.com/content/metadata/article'\n",
    "    headers = {\n",
    "        'X-ELS-APIKey': api_key,\n",
    "        'Accept': 'application/json',\n",
    "        'X-ELS-Insttoken':elsevier_insttoken}\n",
    "\n",
    "    formatted_dois= ' OR '.join(f'DOI({doi})' for doi in dois_list)\n",
    "    params= {\"query\": formatted_dois,\n",
    "             \"start\": 0,\n",
    "            \"count\":50}  # number of result to return\n",
    "    \n",
    "#     print(formatted_dois)\n",
    "\n",
    "    response = requests.get(base_url,headers=headers, params = params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        results= response.json()\n",
    "#         result= int(data['search-results']['opensearch:totalResults'])\n",
    "#         data['search-results']['entry'][1] #.keys() #['link']\n",
    "#         print(results)\n",
    "        totalresult= int(results['search-results'].get('opensearch:totalResults',0))\n",
    "\n",
    "        if totalresult > 0:\n",
    "\n",
    "            try:\n",
    "                for result in results['search-results']['entry']:\n",
    "                    try:\n",
    "                        store_result.append(result['prism:doi'])\n",
    "#                         print(result['prism:doi'])\n",
    "\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "            except KeyError:\n",
    "                    pass\n",
    "    else:\n",
    "        pass\n",
    "        unresolved_doi.extend(dois_list)\n",
    "        \n",
    "    return [store_result,unresolved_doi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScienceDirect DOI coverage Testing\n",
    "\n",
    "sciencedirect_dois_testing=['10.6061/clinics/2017(05)07','10.1002/jps.21888','10.1006/bbrc.1995.1675',\n",
    "                            '10.1061/(asce)0733-9399(2010)136:2(174)']\n",
    "# Checking API\n",
    "check_DOI_ScienceDirect(sciencedirect_dois_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4688b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOI Coverage in ScienceDirect\n",
    "\"\"\"\n",
    "\n",
    "sciencedirect_covered_doi=[]\n",
    "unresolved_sciencedirect_doi=[]\n",
    "\n",
    "#check_doi_in_sciencedirect_batches[:2]\n",
    "for doi_batch in tqdm(check_doi_in_sciencedirect_batches[:]):\n",
    "    sciencedirect_results= check_DOI_ScienceDirect(doi_batch)\n",
    "    sciencedirect_covered_doi.extend(sciencedirect_results[0])\n",
    "    unresolved_sciencedirect_doi.extend(sciencedirect_results[1])\n",
    "    time.sleep(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in ScienceDirect\n",
    "\"\"\"\n",
    "\n",
    "sciencedirect_coveredInDOI_tempo= sciencedirect_covered_doi\n",
    "\n",
    "sciencedirect_coveredInDOI_tempo= [x.lower() for x in sciencedirect_coveredInDOI_tempo]\n",
    "\n",
    "sciencedirect_notin_unionlist= unionlist[unionlist['DOI'].isin(sciencedirect_coveredInDOI_tempo)]\n",
    "\n",
    "sciencedirect_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/sciencedirect_coverednotindexed_'+date_coverage['sciencedirect']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee59153",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sciencedirect_coveredInDOI_tempo) - set(sciencedirect_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01513ed",
   "metadata": {},
   "source": [
    "# IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35782160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_ieee(results:list)->list:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function extracts data from the metadata result from IEEE Xplore API\n",
    "    \n",
    "    :param results: results return from IEEE Xplore\n",
    "    \n",
    "    :return store: list of extracted metadata\n",
    "    \"\"\"\n",
    "    store = []\n",
    "    \n",
    "    for metadata in results: # put in paper details\n",
    "        doi =  metadata.get('doi','')\n",
    "        year=  metadata.get('publication_year','')\n",
    "        title= metadata.get('title','')\n",
    "        au_and_affil = metadata.get('authors','')\n",
    "        doc_type = metadata.get('content_type','')\n",
    "        journal_title = metadata.get('publication_title','')\n",
    "        date= metadata.get('publication_date','')\n",
    "        index_terms= metadata.get('index_terms','')\n",
    "        \n",
    "        \n",
    "        store.append([doi,title, year,au_and_affil, doc_type, date,\n",
    "                      journal_title, index_terms])\n",
    "        \n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "ieee_cut: indicate the numbers to items in a batch; usually is the maximum number the items the API will \n",
    "          return. \n",
    "\n",
    "Output:\n",
    "all_result_ieee: list of records extracted from the metadata\n",
    "\n",
    "NB. Search the DOI in batches of 100 DOIs dataset.\n",
    "\"\"\"\n",
    "\n",
    "ieee_cut = 100 # Number of items in a batch\n",
    "\n",
    "check_doi_in_ieee =  get_DOIs(unionlist) # get valid DOIs # Check entire items with DOI\n",
    "\n",
    "\n",
    "check_doi_in_ieee_batches = batch_items(check_doi_in_ieee, ieee_cut)\n",
    "\n",
    "\n",
    "print(f'The total items to search in IEEE is {len(check_doi_in_ieee)}, which are divided into {len(check_doi_in_ieee_batches)} batches')\n",
    "print(f'The items list is divided into batches in which each list contains {ieee_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7759e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_DOI_IEEE(ieee_dois: list):\n",
    "    \n",
    "    limit = 100  # Maximum number of results to retrieve per request \n",
    "    start = 0    # Starting index of the results (page)\n",
    "\n",
    "    ieee_all_results=[]\n",
    "    ieee_error_dois=[]\n",
    "    \n",
    "    url = \"https://ieeexploreapi.ieee.org/api/v1/search/articles?\"\n",
    "\n",
    "    formatted_dois= (' OR ').join(ieee_dois)\n",
    "    \n",
    "    params = {\n",
    "            \"max_records\": limit,  \n",
    "            \"doi\": formatted_dois, \n",
    "            \"apiKey\": ieee_xplore_api_key}\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        page_result = response.json()\n",
    "#         print('Yes')\n",
    "        print(page_result)\n",
    "\n",
    "        if page_result['total_records']> 0:\n",
    "            try:\n",
    "                result= page_result['articles']\n",
    "                metadata = extract_metadata_ieee(result)\n",
    "                if len(metadata)>0:\n",
    "                    ieee_all_results.extend(metadata)\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code}\")\n",
    "        ieee_error_dois.append(ieee_dois)\n",
    "\n",
    "    \n",
    "    return [ieee_all_results,ieee_error_dois]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eccfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check for 2 DOIs that are in IEEE, see what working results look like\n",
    "\"\"\"\n",
    "check_DOI_IEEE(['10.1093/gji/ggt223', '10.1093/imaman/dpw003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc866a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from json.decoder import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7923d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check DOI Coverage in IEEE\n",
    "\"\"\"\n",
    "\n",
    "ieee_covered_doi=[]\n",
    "unresolved_ieee_doi=[]\n",
    "error_batch_list=[]\n",
    "\n",
    "for i in tqdm(range(799, 849)):  # change range function to choose batches that are run\n",
    "    doi_batch = check_doi_in_ieee_batches[i]\n",
    "    try: \n",
    "        ieee_results= check_DOI_IEEE(doi_batch)\n",
    "        ieee_covered_doi.extend(ieee_results[0])\n",
    "        unresolved_ieee_doi.extend(ieee_results[1])\n",
    "        time.sleep(0.15)\n",
    "    except JSONDecodeError:\n",
    "        print(f'JSONDecodeError at batch {i}; this batch is skipped')\n",
    "        error_batch_list.append(i)\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(0,150))\n",
    "# ieee_covered_doi_tempo1 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo1 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo1 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(150,200))\n",
    "# ieee_covered_doi_tempo2 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo2 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo2 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(200,300))\n",
    "# ieee_covered_doi_tempo3 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo3 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo3 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(300,400))\n",
    "# ieee_covered_doi_tempo4 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo4 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo4 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(400,600))\n",
    "# ieee_covered_doi_tempo5 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo5 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo5 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(599,700))\n",
    "# ieee_covered_doi_tempo6 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo6 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo6 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(700,799)) \n",
    "# ieee_covered_doi_tempo7 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo7 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo7 = error_batch_list.copy()\n",
    "\n",
    "# for i in tqdm(range(799,849))\n",
    "# ieee_covered_doi_tempo8 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo8 = unresolved_ieee_doi.copy()\n",
    "# error_batch_list_tempo8 = error_batch_list.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80732092",
   "metadata": {},
   "source": [
    "Viewing error and unresolved results of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7464bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a65796",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30415e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo6 # Batch index 684. Include with unit testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55228223",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo5 # Batch index 599, failed due to API 200-request limit. Reran with batch 6. Can also unit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da772b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ec0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39993954",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ca782",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61193b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0180751",
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_ieee_doi_tempo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_batch_list_tempo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d47d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample of JSONDecodeError\n",
    "---------------------------------------------------------------------------\n",
    "JSONDecodeError                           Traceback (most recent call last)\n",
    "File C:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:971, in Response.json(self, **kwargs)\n",
    "    970 try:\n",
    "--> 971     return complexjson.loads(self.text, **kwargs)\n",
    "    972 except JSONDecodeError as e:\n",
    "    973     # Catch JSON-related errors and raise as requests.JSONDecodeError\n",
    "    974     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n",
    "\n",
    "File C:\\ProgramData\\anaconda3\\Lib\\json\\__init__.py:346, in loads(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n",
    "    343 if (cls is None and object_hook is None and\n",
    "    344         parse_int is None and parse_float is None and\n",
    "    345         parse_constant is None and object_pairs_hook is None and not kw):\n",
    "--> 346     return _default_decoder.decode(s)\n",
    "    347 if cls is None:\n",
    "\n",
    "File C:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:337, in JSONDecoder.decode(self, s, _w)\n",
    "    333 \"Return the Python representation of ``s`` (a ``str`` instance\n",
    "    334 containing a JSON document).\n",
    "    335 \n",
    "    336 \"\n",
    "--> 337 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
    "    338 end = _w(s, end).end()\n",
    "\n",
    "File C:\\ProgramData\\anaconda3\\Lib\\json\\decoder.py:355, in JSONDecoder.raw_decode(self, s, idx)\n",
    "    354 except StopIteration as err:\n",
    "--> 355     raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
    "    356 return obj, end\n",
    "\n",
    "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "JSONDecodeError                           Traceback (most recent call last)\n",
    "Cell In[88], line 10\n",
    "      8 #check_doi_in_ieee_batches[:2]\n",
    "      9 for doi_batch in tqdm(check_doi_in_ieee_batches[:200]): # \n",
    "---> 10     ieee_results= check_DOI_IEEE(doi_batch)\n",
    "     11     ieee_covered_doi.extend(ieee_results[0])\n",
    "     12     unresolved_ieee_doi.extend(ieee_results[1])\n",
    "\n",
    "Cell In[82], line 23, in check_DOI_IEEE(ieee_dois)\n",
    "     20     response = requests.get(url, params=params)\n",
    "     22     if response.status_code == 200:\n",
    "---> 23         page_result = response.json()\n",
    "     24 #         print('Yes')\n",
    "     25 #         print(page_result)\n",
    "     27         if page_result['total_records']> 0:\n",
    "\n",
    "File C:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:975, in Response.json(self, **kwargs)\n",
    "    971     return complexjson.loads(self.text, **kwargs)\n",
    "    972 except JSONDecodeError as e:\n",
    "    973     # Catch JSON-related errors and raise as requests.JSONDecodeError\n",
    "    974     # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n",
    "--> 975     raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
    "\n",
    "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37137443",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine batches of covered DOIs\n",
    "\"\"\"\n",
    "ieee_covered_doi_regular_batches = ieee_covered_doi_tempo8 + ieee_covered_doi_tempo7 + ieee_covered_doi_tempo6 + \\ \n",
    "ieee_covered_doi_tempo5 + ieee_covered_doi_tempo4 + ieee_covered_doi_tempo3 + ieee_covered_doi_tempo2 + ieee_covered_doi_tempo1\n",
    "\n",
    "len(ieee_covered_doi_regular_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine error doi batches to complete unit testing\n",
    "\"\"\"\n",
    "error_batch_list = error_batch_list_tempo1 + error_batch_list_tempo2 + error_batch_list_tempo3 + error_batch_list_tempo4 \\\n",
    "+ error_batch_list_tempo5 + error_batch_list_tempo6 + error_batch_list_tempo7 + error_batch_list_tempo8\n",
    "\n",
    "# Add unresolved DOI batches for unit testing purposes\n",
    "error_batch_list.append(599)\n",
    "error_batch_list.append(684)\n",
    "\n",
    "error_batch_list\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test error doi batches separately. This tests each DOI within the batch individually and should only be run if \n",
    "you have been provided with increased access above the usual 200 requests/day by IEEE.\n",
    "\"\"\"\n",
    "ieee_covered_doi=[]\n",
    "unresolved_ieee_doi=[]\n",
    "\n",
    "for doi_batch in tqdm(check_doi_in_ieee_batches[684]): \n",
    "    ieee_results= check_DOI_IEEE(doi_batch)\n",
    "    ieee_covered_doi.extend(ieee_results[0])\n",
    "    unresolved_ieee_doi.extend(ieee_results[1])\n",
    "    time.sleep(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d39a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch 47\n",
    "# ieee_covered_doi_tempo_47 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_47 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 55\n",
    "# ieee_covered_doi_tempo_55 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_55 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 61\n",
    "# ieee_covered_doi_tempo_61 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_61 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 111\n",
    "# ieee_covered_doi_tempo_111 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_111 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 114\n",
    "# ieee_covered_doi_tempo_114 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_114 = unresolved_ieee_doi.copy()\n",
    "\n",
    "#  Batch 140\n",
    "# ieee_covered_doi_tempo_140 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_140 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 153\n",
    "# ieee_covered_doi_tempo_153 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_153 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 329\n",
    "# ieee_covered_doi_tempo_329 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_329 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 339\n",
    "# ieee_covered_doi_tempo_339 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_339 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 372\n",
    "# ieee_covered_doi_tempo_372 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_372 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 429\n",
    "# ieee_covered_doi_tempo_429 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_429 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 451\n",
    "# ieee_covered_doi_tempo_451 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_451 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 745\n",
    "# ieee_covered_doi_tempo_745 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_745 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 767\n",
    "# ieee_covered_doi_tempo_767 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_767 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 769\n",
    "# ieee_covered_doi_tempo_769 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_769= unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 599\n",
    "# ieee_covered_doi_tempo_599 = ieee_covered_doi.copy()\n",
    "# unresolved_ieee_doi_tempo_599 = unresolved_ieee_doi.copy()\n",
    "\n",
    "# Batch 684\n",
    "ieee_covered_doi_tempo_684 = ieee_covered_doi.copy()\n",
    "unresolved_ieee_doi_tempo_684 = unresolved_ieee_doi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69604d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine error batch covered DOIs\n",
    "\"\"\"\n",
    "error_batch_covered_doi = ieee_covered_doi_tempo_47 + ieee_covered_doi_tempo_55 + ieee_covered_doi_tempo_61 + \\\n",
    "ieee_covered_doi_tempo_111 + ieee_covered_doi_tempo_114 + ieee_covered_doi_tempo_140 + ieee_covered_doi_tempo_153 + \\\n",
    "ieee_covered_doi_tempo_329 + ieee_covered_doi_tempo_339 + ieee_covered_doi_tempo_372 + ieee_covered_doi_tempo_429 + \\\n",
    "ieee_covered_doi_tempo_451 + ieee_covered_doi_tempo_745 + ieee_covered_doi_tempo_767 + ieee_covered_doi_tempo_769 + \\\n",
    "ieee_covered_doi_tempo_599 + ieee_covered_doi_tempo_684\n",
    "\n",
    "error_batch_covered_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine regular batching results with error batch results\n",
    "\"\"\"\n",
    "ieee_covered_doi_all = ieee_covered_doi_regular_batches + error_batch_covered_doi \n",
    "len(ieee_covered_doi_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in IEEE. \n",
    "\"\"\"\n",
    "# Getting the DOIs of the covered items\n",
    "ieee_coveredInDOI = np.array(ieee_covered_doi_all)[:,0]\n",
    "\n",
    "ieee_coveredInDOI= [x.lower() for x in ieee_coveredInDOI ]\n",
    "\n",
    "ieee_notin_unionlist = unionlist[unionlist['DOI'].isin(ieee_coveredInDOI)]\n",
    "\n",
    "ieee_notin_unionlist \\\n",
    "#    .to_csv(data_dir+'coverednotindexed/ieee_coverednotindexed_'+date_coverage['ieee']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4966c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ieee_coveredInDOI) - set(ieee_notin_unionlist['DOI']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2443f",
   "metadata": {},
   "source": [
    "## Astrophysics Data System (ADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dois_ads(dois_list: list)->str:\n",
    "    \"\"\"\n",
    "    It formats the dois into standard input format for Astrophysics Data System (ADS) processing i.e. \n",
    "    \"doi:10.1016/j.optlastec.2023.109186 OR doi:10.1016/j.jqsrt.2023.108735\"\n",
    "    \n",
    "    'dois_list:' list of DOIs\n",
    "    'return': Format that ADS can use for search\n",
    "    \"\"\"\n",
    "    \n",
    "    formatted_dois= \" OR \".join(f\"doi:{doi}\" for doi in dois_list)\n",
    "    \n",
    "    return formatted_dois\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482267f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ADS_metadata(publications: list) -> list:\n",
    "    \"\"\"\n",
    "    It extracts data from the ADS API results\n",
    "    \n",
    "    :param publications: JSON file of publications - the result from the ADS API search\n",
    "    :return: List of extracted metadata of publications\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        for pub in publications:\n",
    "            authors = pub.get('author_norm', '')\n",
    "            doi = pub.get('doi', [''])[0]\n",
    "            title = pub.get('title', [''])[0]\n",
    "            journal = pub.get('pub', '')\n",
    "            year = pub.get('year', '')\n",
    "\n",
    "            results.append([doi, authors, title, year, journal])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_ADS_metadata: {e}\")\n",
    "        pass\n",
    "        # You can log the error or handle it as needed\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADS_search_DOIs(dois_list: list)->list:  \n",
    "    \"\"\"\n",
    "    It searches DOIs from ADS and uses \n",
    "    i. 'format_dois_ads()' to process the DOIs into useable format\n",
    "    ii. 'get_ADS_metadata()' to extract data from the metadata of founded items\n",
    "    \n",
    "    dois_list: list of DOIs to search via ADS API\n",
    "    \n",
    "    \n",
    "    :return: list of records found\n",
    "    \n",
    "    \n",
    "    Resources:\n",
    "    ---------\n",
    "    https://github.com/adsabs/adsabs-dev-api#access-settings\n",
    "    [5k limit]: https://github.com/adsabs/adsabs-dev-api/tree/master#access \n",
    "    https://ui.adsabs.harvard.edu/help/api/api-docs.html#get-/search/query\n",
    "\n",
    "    \"\"\"\n",
    "#     global ads_catch_errors\n",
    "    ads_catched_errors=[]\n",
    "    \n",
    "    url = 'https://api.adsabs.harvard.edu/v1/search/query'\n",
    "    headers = {'Authorization':f'Bearer:{ads_api_key}'} \n",
    "    params = {'q': format_dois_ads(dois_list), \n",
    "              'rows':200, # number of result on a page. Can take upto 1000\n",
    "              'fl': 'doi,title, author_norm, pubdate,pub, year'} #bibcode, keyword_norm, keyword_schema \n",
    "\n",
    "    response = requests.get(url, headers=headers, params=urlencode(params)) # encode the parameter\n",
    "    \n",
    "    \n",
    "    results=[]\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data=response.json()\n",
    "#         print(data)\n",
    "        \n",
    "        nfound= data['response']['numFound']\n",
    "        publications= data['response']['docs']\n",
    "        \n",
    "        results= get_ADS_metadata(publications)\n",
    "        \n",
    "    else:\n",
    "        ads_catched_errors.append(dois_list)\n",
    "        print(f\"Error: {response.status_code}, {response.text}\") \n",
    "    \n",
    "    return results, ads_catched_errors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "cut_ads: indicate the numbers to items in a batch; usually is the maximum number the items the API will \n",
    "          return. \n",
    "ads_doi_to_search: the list of DOIs to search/check coverage via the ADS API\n",
    "\n",
    "Output:\n",
    "all_result_ads: list of records extracted from the metadata\n",
    "\n",
    "NB. Search the DOI in batches of 50 DOIs dataset. Though it can contain up to 5k items on its result page, \n",
    "it will sometimes error and say the request is too large.\n",
    "\"\"\"\n",
    "\n",
    "check_doi_in_ads=  get_DOIs(unionlist) # Check the entire unionlist valid DOIs\n",
    "\n",
    "ads_cut = 50 # Number of items in a batch\n",
    "\n",
    "doi_batch_ads = batch_items(check_doi_in_ads, ads_cut) # divides dois into batches\n",
    "\n",
    "print(f'The total items to search in ADS is {len(check_doi_in_ads)}, which are divided into {len(doi_batch_ads)} batches')\n",
    "print(f'The items list is divided into lists in which each list contains {ads_cut} records maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c84fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking coverage of DOIs of the Unionlist via ADS API. Catch error batches for individual processing.\n",
    "\"\"\"\n",
    "\n",
    "ads_catch_errors_round_1=[]\n",
    "ads_all_results_round_1= []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for batch in tqdm(doi_batch_ads):\n",
    "    #print(doi_batch_ads[batch])\n",
    "    results, errors = ADS_search_DOIs(batch)\n",
    "    \n",
    "    ads_all_results_round_1.extend(results)\n",
    "    ads_catch_errors_round_1.extend(errors)\n",
    "\n",
    "end = time.time()\n",
    "end - start  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7269da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make flat list of DOIs from batches that had syntax error\n",
    "\"\"\"\n",
    "flat_list_ads_catch_errors = []\n",
    "flat_list_ads_catch_errors = [item for sublist in ads_catch_errors_round_1 for item in sublist]\n",
    "flat_list_ads_catch_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list_ads_catch_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADS_search_single_DOI(doi):\n",
    "    \"\"\"\n",
    "    Search for single DOI using ADS API.\n",
    "    param: doi: string DOI to search\n",
    "    \"\"\"\n",
    "    url = 'https://api.adsabs.harvard.edu/v1/search/query'\n",
    "    headers = {'Authorization':f'Bearer:{ads_api_key}'} \n",
    "    params = {'q': f\"doi:{doi}\", \n",
    "              'rows':200, # number of result on a page. Can take up to 1000\n",
    "              'fl': 'doi,title, author_norm, pubdate,pub, year'} #bibcode, keyword_norm, keyword_schema \n",
    "\n",
    "    response = requests.get(url, headers=headers, params=urlencode(params)) # encode the parameter\n",
    "    \n",
    "    \n",
    "    results=[]\n",
    "    ads_catched_errors=[]\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data=response.json()\n",
    "#         print(data)\n",
    "        \n",
    "        nfound= data['response']['numFound']\n",
    "        publications= data['response']['docs']\n",
    "        \n",
    "        results= get_ADS_metadata(publications)\n",
    "        \n",
    "    else:\n",
    "        ads_catched_errors.append(doi)\n",
    "        print(f\"Error: {response.status_code}, {response.text}\") \n",
    "    \n",
    "    return results, ads_catched_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e54e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Small scale test of item that is confirmed in ADS.\n",
    "\"\"\"\n",
    "doi_test= '10.1016/j.dark.2024.101586'\n",
    "result_test, error_test = ADS_search_single_DOI(doi_test)\n",
    "print(result_test)\n",
    "print(error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3263feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use API to search for DOIs from error batches individually\n",
    "\"\"\"\n",
    "ads_catch_errors_round_2=[]\n",
    "ads_all_results_round_2= []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for doi in tqdm(flat_list_ads_catch_errors):\n",
    "    results, errors= ADS_search_single_DOI(doi)\n",
    "    \n",
    "    ads_all_results_round_2.extend(results)\n",
    "    ads_catch_errors_round_2.extend(errors)\n",
    "\n",
    "end = time.time()\n",
    "end - start  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade69eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ads_all_results_round_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ads_all_results_round_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Combine results lists from round 1 and round 2\n",
    "\"\"\"\n",
    "ads_all_results = ads_all_results_round_1 + ads_all_results_round_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ads_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e820264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the retrieved covered items in ADS.\n",
    "\"\"\"\n",
    "# Getting the DOIs of the covered items\n",
    "ads_coveredInDOI = np.array(ads_all_results, dtype=object)[:,0]\n",
    "\n",
    "ads_coveredInDOI= [x.lower() for x in ads_coveredInDOI]\n",
    "\n",
    "# Filtering the DOIs that are covered but not indexed as retracted in the source \n",
    "ads_notin_unionlist = unionlist[unionlist['DOI'].isin(ads_coveredInDOI)]\n",
    "\n",
    "ads_notin_unionlist \\\n",
    "#     .to_csv(data_dir+'coverednotindexed/ads_coverednotindexed_'+date_coverage['ads']+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ads_coveredInDOI) - set(ads_notin_unionlist['DOI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DOIs parsing error\n",
    "10.1002/1096-9098(200007)74:3201::AID-JSO83.0.CO;2-5  #(worked when checked on DOI.org)\n",
    "10.1002/1098-1136(200012)32:3<247::AID-GLIA50>3.0.CO;2-T #(worked when checked on DOI.org)\n",
    "10.1002/(sici)1097-0215(19980330)76:1<154::aid-ijc24>3.0.co;2-b  #(worked when checked on DOI.org)\n",
    "10.3758/s13423-018-1505-y # worked when checked on DOI.org)\n",
    "\n",
    "DOI encoding error: \n",
    "# '10.1002/1521-396X(200207)192:1<212::AID-PSSA212>3.0.CO;2-B' (WoS: worked with doi.org)\n",
    "#'10.1002/1521-396X(200207)192:1212::AID-PSSA2123.0.CO;2-B' (RW: not worked with doi.org)\n",
    "\n",
    "Data Entry Error: This is a generic term for any mistake made during the manual entry of data. \n",
    "It can include typos, incorrect values, or entering data in the wrong format. e.g. 10.7705/biomedica.v38i0.3546)\n",
    "#10.3758/s13423-017-1376-7\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
