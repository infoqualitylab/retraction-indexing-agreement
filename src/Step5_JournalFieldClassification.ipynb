{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Journal Field Information\n",
    "- Part 1: Import Scopus Journal List to get upper-level field category for journals\n",
    "- Part 2: Identify Journal from the Known Retraction List that are not listed in the Scopus Journal List\n",
    "- Part 3: Use YAKE to find keyword in each field and match with the journals\n",
    "- Part 4: Manually generate keywords and match with the rest of the journals\n",
    "- Part 5: Append the result of each step to the original unionlist\n",
    "\n",
    "\n",
    "Input File: \n",
    "   - Scopus list of journal titles (from Step 5)\n",
    "       - 'journal/ext_list_{latest_MM_YYYY}.xlsx'  # Get latest one (See Part 1 below)\n",
    "       \n",
    "   - Union list of retracted publication with retraction year (from Step 4):\n",
    "       - unionlist/unionlist_with_retractionyear_{date}.csv\n",
    "\n",
    "\n",
    "Output File: \n",
    "   - unionlist_completed_{date}.csv\n",
    "  \n",
    "\n",
    "###### Uncomment the line of code \"....to_csv(..)\"  to save file to your local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import date, datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targeting the retraction_index_path\n",
    "retraction_index_path = os.path.abspath('./.')\n",
    "retraction_index_path\n",
    "\n",
    "data_dir = retraction_index_path+'/data/' # data directory\n",
    "result_dir = retraction_index_path+'/result/'\n",
    "\n",
    "# Create 'journal' folder for journal title classification\n",
    "if not os.path.exists(data_dir+'journal'): #(data+source)\n",
    "    os.mkdir(data_dir+'journal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Import Scopus Journal List to get upper-level field category for journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Reading Scopus journal classification. \n",
    "# See latest version: 'https://www.elsevier.com/products/scopus/content' then\n",
    "    click on 'Download the Source title list (includes discontinued sources list)'\n",
    "\n",
    "\"\"\"\n",
    "try:\n",
    "    scopus_journal_data = pd.read_excel(data_dir+'journal/ext_list_August_2024.xlsx',sheet_name=None)  #,encoding ='utf-8',errors='ignore'\n",
    "except UnicodeDecodeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_journal_data_sheets_names = list(scopus_journal_data.keys())\n",
    "scopus_journal_sheet = scopus_journal_data[scopus_journal_data_sheets_names[0]]\n",
    "\n",
    "selected_columns=['Source Title',\n",
    "                  'Top level:\\n\\nLife Sciences','Top level:\\n\\nSocial Sciences',\n",
    "                  'Top level:\\n\\nPhysical Sciences','Top level:\\n\\nHealth Sciences',\n",
    "                  '1000 \\nGeneral']\n",
    "\n",
    "scopus_journal_filtered = scopus_journal_sheet.filter(items = selected_columns).replace('',np.nan)\n",
    "scopus_journal_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Joining the cell values for each category within the subject areas for each of the journal titles\n",
    "\"\"\"\n",
    "# 'MainCategory' <-- Concatenate the cell values for journal titles \n",
    "scopus_journal_filtered['MainCategory'] = scopus_journal_filtered.apply(lambda row: ','.join(\\\n",
    "    filter(lambda x: pd.notna(x), [row[column] for column in selected_columns[1:]])),axis=1)\n",
    "\n",
    "scopus_journal_filtered = scopus_journal_filtered.rename(columns={selected_columns[0]:'JournalandConferenceProceedings'})\n",
    "\n",
    "# scopus_journal_part <-- Select needed column of interest\n",
    "scopus_journal_part = scopus_journal_filtered[['JournalandConferenceProceedings','MainCategory']]\n",
    "\n",
    "scopus_journal_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Scopus conference categories \n",
    "conference_sheet = scopus_journal_data[scopus_journal_data_sheets_names[3]].iloc[:,[1,-1]]\n",
    "conference_sheet = conference_sheet.rename(columns={'All Science Journal Classification Codes (ASJC)':'ASJC',\n",
    "                                                   'Source Title': 'JournalandConferenceProceedings'})\n",
    "conference_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assigning main category subjects to their ASJC codes\n",
    "\"\"\"\n",
    "lookup={\n",
    "10: 'General',\n",
    "11: 'Life Sciences',\n",
    "12: 'Social Sciences',\n",
    "13: 'Life Sciences',\n",
    "14: 'Social Sciences',\n",
    "15: 'Physical Sciences',\n",
    "16: 'Physical Sciences',\n",
    "17: 'Physical Sciences',\n",
    "18: 'Social Sciences',\n",
    "19: 'Physical Sciences',\n",
    "20: 'Social Sciences',\n",
    "21: 'Physical Sciences',\n",
    "22: 'Physical Sciences',\n",
    "23: 'Physical Sciences',\n",
    "24: 'Life Sciences',\n",
    "25: 'Physical Sciences',\n",
    "26: 'Physical Sciences',\n",
    "27: 'Health Sciences',\n",
    "28: 'Life Sciences',\n",
    "29: 'Health Sciences',\n",
    "30: 'Life Sciences',\n",
    "31: 'Physical Sciences',\n",
    "32: 'Social Sciences',\n",
    "33: 'Social Sciences',\n",
    "34: 'Health Sciences',\n",
    "35: 'Health Sciences',\n",
    "36: 'Health Sciences'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_asjc_to_category(asjc_value):\n",
    "    \"\"\"\n",
    "    This function assign conference proceedings of the Scopus their main categories\n",
    "    :param asjc_value: the ASJC code of the journal & Conference proceedings\n",
    "        \"\"\"\n",
    "    store=[]\n",
    "    asjc_values = asjc_value.strip().split(';')\n",
    "\n",
    "    for values in asjc_values:\n",
    "        if values:\n",
    "            values=values.strip()\n",
    "#             print(values)\n",
    "#             print((values[:2]))\n",
    "#             print(lookup[int(values[:2])])\n",
    "            store.append(lookup[int(values[:2])])\n",
    "    \n",
    "    store = list(set(store))\n",
    "    return ','.join(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conference_sheet['ASJC']=conference_sheet['ASJC'].fillna(\"\")\n",
    "conference_sheet['ASJC']= conference_sheet['ASJC'].apply(str)\n",
    "conference_sheet['MainCategory'] = conference_sheet['ASJC'].apply(map_asjc_to_category)\n",
    "conference_sheet_part= conference_sheet[['JournalandConferenceProceedings','MainCategory']]\n",
    "conference_sheet_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending Both the Journal titles & Conferences from Scopus\n",
    "\n",
    "journalscopus = pd.concat([scopus_journal_part,conference_sheet_part])\n",
    "journalscopus\\\n",
    "#         .to_csv(data_dir+'journal/scopus_journalconferencecategory.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Scopus Journal List\n",
    "journalscopus = pd.read_csv(data_dir+'journal/scopus_journalconferencecategory.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "journalscopus['JournalandConferenceProceedings_lowercase'] = journalscopus['JournalandConferenceProceedings'].str.lower().str.strip()\n",
    "journalscopus_deduplicated = journalscopus.drop_duplicates(subset='JournalandConferenceProceedings_lowercase')\n",
    "journalscopus_deduplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Cleaning the Journal and Conference Titles in the UnionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getdate= {'unionlist': '2024-07-09'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_journal_title(df_: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    param df_: The dataframe to work with\n",
    "    :return: Dataframe with clean column\n",
    "    \"\"\"\n",
    "    df= df_.copy(deep=True)\n",
    "    df['JournalandConferenceProceedings_clean'] = df_['JournalandConferenceProceedings'].str.strip().str.lower()\n",
    "\n",
    "    # remove '&amp and '&'\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(\"&amp\", \"\").str.replace(\"&\", \"\")\n",
    "\n",
    "    # remove 'the' if it starts a journal title\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(r'(?i)^(the) ', '',regex=True)\n",
    "\n",
    "    # remove position such 1st, 2nd, 3rd, 4th from the journal titles\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].apply(lambda x: re.sub(r'\\b\\d+(st|nd|rd|th)\\b', '', x))\n",
    "\n",
    "    # remove other digits and punctuation from the journal titles\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].apply(lambda x: re.sub(r'[^\\w\\s]|[\\d]', '', x))\n",
    "\n",
    "    #remove extra whitespace in between words\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(r'\\s+', ' ',regex=True).str.strip()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Unionlist list and clean --> journalknownretraction_clean and knownretractionlist (title-cleaned copy of unionlist)\n",
    "\n",
    "\"\"\"\n",
    "unionlist= pd.read_csv(data_dir+f\"unionlist/unionlist_with_retractionyear_{getdate['unionlist']}.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "knownretractionlist= unionlist.copy(deep=True) #unionlist[['Journal']].copy(deep=True)\n",
    "knownretractionlist['JournalandConferenceProceedings_lowercase'] = knownretractionlist['Journal'].str.lower().str.strip()\n",
    "\n",
    "\n",
    "journalknownretraction= unionlist[['DOI','Journal']].rename(columns={'Journal': 'JournalandConferenceProceedings'})\n",
    "journalknownretraction['JournalandConferenceProceedings_lowercase'] = journalknownretraction['JournalandConferenceProceedings'].str.lower().str.strip()\n",
    "\n",
    "# Cleaning the Journal Titles from the Unionlist\n",
    "journalknownretraction_clean = clean_journal_title(journalknownretraction)\n",
    "\n",
    "#journalknownretraction_clean.groupby('JournalandConferenceProceedings_clean')['JournalandConferenceProceedings'].count().reset_index()\n",
    "after_cleaning = len(journalknownretraction_clean[['JournalandConferenceProceedings_clean']].drop_duplicates())\n",
    "\n",
    "print(f'The total number of journal titles in the unionlist is {after_cleaning} after cleaning')\n",
    "journalknownretraction_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export the journalknownretraction_clean file for OpenRefine further cleaning\n",
    "\"\"\"\n",
    "journalknownretraction_clean \\\n",
    "#                .to_csv(data_dir+'journal/unionlist_journalcategory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Clean Journal Title From OpenRefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalknownretraction_clean2 = pd.read_csv(data_dir+'journal/unionlistjournalcategory_openrefined_updated.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Getting the unique total of journal titles in the Unionlist after OpenRefined cleaning\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_clean2['JournalandConferenceProceedings_clean']= journalknownretraction_clean2['Journal_Openrefined'] #.copy()\n",
    "\n",
    "journalknownretraction_unique=  journalknownretraction_clean2[['JournalandConferenceProceedings_lowercase','JournalandConferenceProceedings_clean']].copy()\n",
    "journalknownretraction_unique.drop_duplicates(subset='JournalandConferenceProceedings_clean', keep='first', inplace=True)\n",
    "\n",
    "after_cleaning2= len(journalknownretraction_unique)\n",
    "\n",
    "\n",
    "print(f'The total number of journal titles in the knownretraction list is {after_cleaning2} after cleaning with OpenRefine')\n",
    "\n",
    "journalknownretraction_clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalknownretraction_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Identify Journal Field Category from the Scopus Journal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resolved_journaltitle_count(df: pd.DataFrame()):\n",
    "    \"\"\"\n",
    "    It gets unique count of journal titles based on 'JournalandConferenceProceedings_clean' column\n",
    "    \"\"\"\n",
    "    x = df.copy(deep=True)\n",
    "    xC = x[~x.MainCategory.isna()][['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    xCnot = x[x.MainCategory.isna()][['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    xT = x[['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    \n",
    "    return len(xC),len(xCnot),len(xT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use 'JournalandConferenceProceedings' to merge with Scopus journal list\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_cat= pd.merge(journalknownretraction_unique,journalscopus_deduplicated.iloc[:,1:], on='JournalandConferenceProceedings_lowercase', how='left')\n",
    "# tempo_df_1.drop_duplicates(subset='JournalandConferenceProceedings_clean', keep='first', inplace=True)\n",
    "\n",
    "print(get_resolved_journaltitle_count(journalknownretraction_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalknownretraction_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Of {after_cleaning2} total journal titles in the knownretractionlist')\n",
    "\n",
    "first_pass = get_resolved_journaltitle_count(journalknownretraction_cat)\n",
    "\n",
    "print(f'Categorized Round 1: The total number of classified journal titles with Scopus Journal is {first_pass[0]}, and {first_pass[1]} remain unclassified.')\n",
    "\n",
    "print(f'That is, {(first_pass[0]/after_cleaning2)*100:.2f}% classified journals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with Scopus classification\n",
    "\"\"\"\n",
    "\n",
    "df_firstpass = pd.merge(journalknownretraction_cat.iloc[:,:2],journalscopus_deduplicated.iloc[:,1:], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_firstpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_firstpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched in Scopus journal list is:', no_doi_firstpass)\n",
    "print(f'Which is {no_doi_firstpass/len(knownretractionlist)*100:.2f}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Identify Journal from the Unionlist that are not listed in the Scopus Journal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Journals from the known retraction list that are categorized\n",
    "journalknownretraction_categories= journalknownretraction_cat.copy(deep=True)\n",
    "\n",
    "journalknownretraction_categories.MainCategory = journalknownretraction_categories.MainCategory.str.strip()\n",
    "journalknownretraction_cat1 = journalknownretraction_categories[~journalknownretraction_categories['MainCategory'].isnull()].copy(deep=True)\n",
    "\n",
    "# Identify Journals from the known retraction list that are not categorized to any field\n",
    "journalknownretraction_notcat = journalknownretraction_categories[journalknownretraction_categories['MainCategory'].isnull()].copy(deep=True)\n",
    "\n",
    "# print(journalknownretraction_notcat.info())\n",
    "\n",
    "print('Number of Journals that are not categorized: ', first_pass[1])\n",
    "print(f'Percentage of Journals that are not categoriezed: {round(int(first_pass[1])/int(after_cleaning2)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Use YAKE to find keyword in each field and match with the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalknownretraction_notcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of journal name str from journals that are already categorized\n",
    "lifescience = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Life Science', na=True)]['JournalandConferenceProceedings_clean']\n",
    "lifescience_ = \" \".join(lifescience)\n",
    "lifescience_list  = re.sub(r'[^\\w\\s]', '', lifescience_).split()\n",
    "\n",
    "healthscience= journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Health Science', na=True)]['JournalandConferenceProceedings_clean']\n",
    "healthscience_ = \" \".join(healthscience)\n",
    "healthscience_list  = re.sub(r'[^\\w\\s]', '', healthscience_).split()\n",
    "\n",
    "physicalscience = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Physical Science', na=True)]['JournalandConferenceProceedings_clean']\n",
    "physicalscience_ = \" \".join(physicalscience)\n",
    "physicalscience_list  = re.sub(r'[^\\w\\s]', '', physicalscience_).split()\n",
    "\n",
    "socialscience= journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Social Science', na=True)]['JournalandConferenceProceedings_clean']\n",
    "socialscience_ = \" \".join(socialscience)\n",
    "socialscience_list  = re.sub(r'[^\\w\\s]', '', socialscience_).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stopwordsiso\n",
    "import stopwordsiso as stopwords\n",
    "\n",
    "# stop words list of all languages in the ISO-639 standard was used to process the titles. \n",
    "# https://github.com/stopwords-iso/stopwords-iso  stopwords.stopwords(\"en\") stopwords.stopwords.lang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of stopwords\n",
    "new_stopwords = ['&', '&amp', 'acta', 'africa', 'african', 'albania', 'albanian', 'america', 'american', 'and', \n",
    "                 'andorra', 'applied', 'archives', 'armenia', 'asian', 'asian-australasian', 'association', 'australasian', \n",
    "                 'austria', 'austrian', 'azerbaijan', 'belarus', 'belgium', 'bmc', 'bosnia', 'brazil', 'brazilian', 'british', \n",
    "                 'bulgaria', 'bulgarian', 'bulletin', 'cadernos', 'canadian', 'china', 'chinese', 'communication', 'communications', \n",
    "                 'conference', 'croatia', 'croatian', 'current', 'cyprus', 'czech', 'denmark', 'dynamic', 'dynamics', 'east', \n",
    "                 'elife', 'estonia', 'europe', 'european', 'experimental', 'f1000research', 'finland', 'france', 'georgia', \n",
    "                 'german', 'germany', 'greece', 'herzegovina', 'hungary', 'iceland', 'india', 'indian', 'indonesia', 'indonesian', \n",
    "                 'international', 'iran', 'iranian', 'ireland', 'italian', 'italy', 'jama', 'japan', 'japanese', 'journal', 'jurnal', \n",
    "                 'kazakhstan', 'korean', 'latvia', 'lecture', 'letters', 'liechtenstein', 'list', 'lithuania', 'luxembourg', 'macedonia', \n",
    "                 'malta', 'management', 'moldova', 'monaco', 'montenegro', 'moscow', 'national academy', 'netherlands', 'north', 'norway',\n",
    "                 'note', 'notes', 'opinion', 'oxford', 'peerj', 'poland', 'portugal', 'proceeding', 'proceedings', 'reports', 'republic',\n",
    "                 'research', 'review', 'reviews', 'revista', 'romania', 'russia', 'russian', 'saudi', 'scandinavian', 'science', 'sciences',\n",
    "                 'serbia', 'serials', 'slovakia', 'slovenia', 'society', 'south', 'spain', 'spainish', 'studies', 'sweden', 'switzerland',\n",
    "                 'targets', 'trabalhos', 'turkey', 'turkukraine', 'uk', 'ukrainian', 'united kingdom', 'universities', 'university', 'vakblad', 'west']\n",
    "\n",
    "new_stopwords.extend(stopwords.stopwords([\"en\", \"de\", \"fr\", \"la\", \"ru\"])) # adding English, German, French, Latin, and Russian stopwords\n",
    "\n",
    "print('The total stopwords is',len(new_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing stopwords from the main categories lists\n",
    "\"\"\"\n",
    "lifescience_str= set(lifescience_list)\n",
    "healthscience_str = set(healthscience_list)\n",
    "physicalscience_str= set(physicalscience_list)\n",
    "socialscience_str= set(socialscience_list)\n",
    "\n",
    "for remove_item in set(new_stopwords):\n",
    "    if remove_item in lifescience_str:\n",
    "        lifescience_str.remove(remove_item)\n",
    "    if remove_item in healthscience_str:\n",
    "        healthscience_str.remove(remove_item)\n",
    "    if remove_item in physicalscience_str:\n",
    "        physicalscience_str.remove(remove_item)\n",
    "    if remove_item in socialscience_str:\n",
    "        socialscience_str.remove(remove_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting relevant keywords in each field into list\n",
    "\"\"\"\n",
    "text_list = [lifescience_str, healthscience_str, physicalscience_str, socialscience_str]\n",
    "store_keywords = []\n",
    "\n",
    "for i in text_list[:]:\n",
    "    keywords_per_science=[]\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    text = ' '.join(set(i))\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1\n",
    "    deduplication_threshold = 0.5\n",
    "    numOfKeywords = 1000\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    for kw in keywords:\n",
    "        keywords_per_science.append(kw[0])\n",
    "    store_keywords.append(keywords_per_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to display the keywords of each field\n",
    "cat = ['Life Sciences', 'Health Sciences', 'Physical Sciences', 'Social Sciences']\n",
    "cat_key_df = pd.DataFrame()\n",
    "\n",
    "cat_key_df['Categories'] = cat\n",
    "\n",
    "#lifescience_keywords,healthscience_keywords,physicalscience_keywords,socialscience_keywords = store_keywords\n",
    "cat_key_df['Keyword'] = [store_keywords[0][9:], store_keywords[1][9:], store_keywords[2][9:], store_keywords[3][9:]]\n",
    "\n",
    "cat_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize journals and return a list of categories\n",
    "def categorize_journal(title, cat_key_df):\n",
    "    \"\"\"\n",
    "    It categorizes the journal titles based on keyword subjects\n",
    "    :param title: the title of the journal\n",
    "    :param cat_key_df: dataframe of topical keywords and linked categories\n",
    "    \n",
    "    :return: the main categories of the title\n",
    "    \"\"\"\n",
    "    categories = []\n",
    "    for index, row in cat_key_df.iterrows():\n",
    "        if any(keyword in title for keyword in row['Keyword']):\n",
    "            categories.append(row['Categories'])\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate not-yet-classified journal titles and categorize using categorize_journal\n",
    "\n",
    "for i in range(len(journalknownretraction_notcat)):\n",
    "    title = journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'].iloc[i]\n",
    "    categories = categorize_journal(title, cat_key_df)\n",
    "    \n",
    "    if categories:\n",
    "        journalknownretraction_notcat['MainCategory'].iloc[i] = ', '.join(categories)\n",
    "\n",
    "journalknownretraction_notcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering classified and unclassified journals after using YAKE approach\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_cat2 = journalknownretraction_notcat[~journalknownretraction_notcat['MainCategory'].isna()]\n",
    "\n",
    "journalknownretraction_notcat2 = journalknownretraction_notcat[journalknownretraction_notcat['MainCategory'].isna()]\n",
    "\n",
    "second_pass = get_resolved_journaltitle_count(journalknownretraction_notcat)\n",
    "\n",
    "print(f'Categorized Round 2: The total number of second phase classified journal titles is {second_pass[0]}')\n",
    "print(f'The total number of classified journal titles from first & second phase is {first_pass[0]+second_pass[0]}')\n",
    "print(f'Uncategorized Round 2: The total number of remaining unclassified journal titles is {second_pass[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with YAKE approach\n",
    "\"\"\"\n",
    "df_secondpass = pd.merge(journalknownretraction_unique,journalknownretraction_cat2.iloc[:,:], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_secondpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_secondpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched with YAKE Approach is:' , no_doi_secondpass)\n",
    "print(f'Which is {no_doi_secondpass/len(knownretractionlist)*100:.2f}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Manually generate keywords and match with the rest of the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nameclean = []\n",
    "for i in journalknownretraction_notcat2['JournalandConferenceProceedings_clean']:\n",
    "    stripped = i.split('(', 1)[0]\n",
    "    stripped = i.split('=', 1)[0]\n",
    "    nameclean.append(stripped)\n",
    "\n",
    "journalknownretraction_notcat2['name_clean'] = nameclean\n",
    "\n",
    "journalknownretraction_notcat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifescience_words = ['acids',\n",
    " 'agric',\n",
    " 'agronomy',\n",
    " 'akuakultur',\n",
    " 'anatomical',\n",
    " 'anatomy',\n",
    " 'aquaculture',\n",
    " 'bacteriology',\n",
    " 'biochemistry',\n",
    " 'bioengineering',\n",
    " 'bioethics',\n",
    " 'bioinformatics',\n",
    " 'biolog',\n",
    " 'biological',\n",
    " 'biology',\n",
    " 'biomedicine',\n",
    " 'biomolecular',\n",
    " 'biophysics',\n",
    " 'biorxiv',\n",
    " 'biotechnology',\n",
    " 'cell',\n",
    " 'cells',\n",
    " 'cellular',\n",
    " 'chemical',\n",
    " 'chemie',\n",
    " 'chemistry',\n",
    " 'clinic',\n",
    " 'clínica',\n",
    " 'crispr',\n",
    " 'cytology',\n",
    " 'dendrology',\n",
    " 'dna',\n",
    " 'ecology',\n",
    " 'endocrinology',\n",
    " 'entomologica',\n",
    " 'entomology',\n",
    " 'epidemiology',\n",
    " 'evolution',\n",
    " 'genetics',\n",
    " 'genomic',\n",
    " 'genomics',\n",
    " 'histology',\n",
    " 'immunology',\n",
    " 'lipids',\n",
    " 'medical',\n",
    " 'medrxiv',\n",
    " 'microbial',\n",
    " 'microbiology',\n",
    " 'microchemistry',\n",
    " 'microchimica',\n",
    " 'microrna',\n",
    " 'microscopy',\n",
    " 'molecul',\n",
    " 'molecular',\n",
    " 'mosquito',\n",
    " 'nanomedicine',\n",
    " 'nematology',\n",
    " 'neurochemistry',\n",
    " 'neurology',\n",
    " 'neurophysiology',\n",
    " 'neuroscience',\n",
    " 'nicotine',\n",
    " 'nucleosides',\n",
    " 'nucleotides',\n",
    " 'parasites',\n",
    " 'pathology',\n",
    " 'pharmaceutics',\n",
    " 'pharmacology',\n",
    " 'pharmocognosy',\n",
    " 'physiology',\n",
    " 'plant',\n",
    " 'polyadenylation',\n",
    " 'poultry',\n",
    " 'protein',\n",
    " 'tobacco',\n",
    " 'toxicology',\n",
    " 'virology',\n",
    " ]\n",
    "\n",
    "healthscience_words= [ 'age',\n",
    " 'aging',\n",
    " 'aids',\n",
    " 'anaesthesia',\n",
    " 'anaesthesist',\n",
    " 'anästhesiologie',\n",
    " 'anatomy',\n",
    " 'anesthesia',\n",
    " 'anesthesiology',\n",
    " 'arthritis',\n",
    " 'biochemistry',\n",
    " 'bioengineering',\n",
    " 'bioethics',\n",
    " 'biomedical',\n",
    " 'biorxiv',\n",
    " 'biotechnology',\n",
    " 'blood',\n",
    " 'bone',\n",
    " 'cancer',\n",
    " 'cardiac',\n",
    " 'cardiological',\n",
    " 'cardiologist',\n",
    " 'cardiology',\n",
    " 'cardiovascular',\n",
    " 'chiropractic',\n",
    " 'chirurg',\n",
    " 'cirugía',\n",
    " 'clinic',\n",
    " 'clínica',\n",
    " 'clinical',\n",
    " 'counseling',\n",
    " 'craniofacial',\n",
    " 'dementia',\n",
    " 'dental',\n",
    " 'dentistry',\n",
    " 'dermatology',\n",
    " 'dermo-sifiliográficas',\n",
    " 'dermo-sifiliographics',\n",
    " 'diabetes',\n",
    " 'diabetology',\n",
    " 'digestive',\n",
    " 'disease',\n",
    " 'diseases',\n",
    " 'drug',\n",
    " 'drugs',\n",
    " 'e-health',\n",
    " 'endocrinology',\n",
    " 'enfermería',\n",
    " 'epidemiology',\n",
    " 'epilepsy',\n",
    " 'eye',\n",
    " 'foot',\n",
    " 'gastroenterology',\n",
    " 'genetics',\n",
    " 'geriatrics',\n",
    " 'gerontologist',\n",
    " 'gerontology',\n",
    " 'gynaecologist',\n",
    " 'gynécologie',\n",
    " 'gynecology',\n",
    " 'health',\n",
    " 'heart',\n",
    " 'hematology',\n",
    " 'hemostasis',\n",
    " 'hypertension',\n",
    " 'imaging',\n",
    " 'immunology',\n",
    " 'infection',\n",
    " 'infectious',\n",
    " 'intervention',\n",
    " 'kardiologe',\n",
    " 'lancet',\n",
    " 'leukemia',\n",
    " 'liver',\n",
    " 'lymphoma',\n",
    " 'maxillofacial',\n",
    " 'medical',\n",
    " 'médicale',\n",
    " 'medicine',\n",
    " 'medrxiv',\n",
    " 'metabolic',\n",
    " 'metabolism',\n",
    " 'microbiology',\n",
    " 'molecular',\n",
    " 'morbidity',\n",
    " 'nefrología',\n",
    " 'néphrologie',\n",
    " 'néphrologology',\n",
    " 'nephrology',\n",
    " 'neuro',\n",
    " 'neurology',\n",
    " 'neurotology',\n",
    " 'nicotine',\n",
    " 'nurse',\n",
    " 'nursing',\n",
    " 'nutrition',\n",
    " 'obesity',\n",
    " 'obstetrician',\n",
    " 'obstetrics',\n",
    " 'occupational',\n",
    " 'oncology',\n",
    " 'onkologie',\n",
    " 'ophthalmic',\n",
    " 'ophthalmologe',\n",
    " 'ophthalmology',\n",
    " 'oral',\n",
    " 'orthopäde',\n",
    " 'orthopaedic',\n",
    " 'orthopaedics',\n",
    " 'orthopedist',\n",
    " 'ortopediya',\n",
    " 'osteoporosis',\n",
    " 'otorhinolaryngology',\n",
    " 'pain',\n",
    " 'parasites',\n",
    " 'pathology',\n",
    " 'patient',\n",
    " 'pediatría',\n",
    " 'pediatric',\n",
    " 'pediatrics',\n",
    " 'pédiatrie',\n",
    " 'pharmaceutical',\n",
    " 'pharmacology',\n",
    " 'pharmazie',\n",
    " 'pharmocognosy',\n",
    " 'physiology',\n",
    " 'prosthodontics',\n",
    " 'psychiatry',\n",
    " 'psychoanalysis',\n",
    " 'psychology',\n",
    " 'psychonomic',\n",
    " 'pulmonology',\n",
    " 'radiology',\n",
    " 'rehabilitación',\n",
    " 'rehabilitation',\n",
    " 'reproductive',\n",
    " 'respiration',\n",
    " 'respiratory',\n",
    " 'retina',\n",
    " 'reumatologia',\n",
    " 'reumatología',\n",
    " 'revista',\n",
    " 'rheumatology',\n",
    " 'roentgenology',\n",
    " 'sclerosis',\n",
    " 'seizure',\n",
    " 'shoulder',\n",
    " 'spine',\n",
    " 'std',\n",
    " 'surgeon',\n",
    " 'surgery',\n",
    " 'surgical',\n",
    " 'thrombosis',\n",
    " 'thyroid',\n",
    " 'tobacco',\n",
    " 'toxicology',\n",
    " 'trauma',\n",
    " 'urological',\n",
    " 'urológicas',\n",
    " 'urology',\n",
    " 'vascular',\n",
    " 'veterinar',\n",
    " 'veterinary',\n",
    " 'virology']\n",
    "\n",
    "\n",
    "physicalscience_words= ['acs',\n",
    " 'actuators',\n",
    " 'aeroacoustics',\n",
    " 'aerodynamic',\n",
    " 'aerospace',\n",
    " 'akuakultur',\n",
    " 'algebra',\n",
    " 'antenna',\n",
    " 'aquaculture',\n",
    " 'astro',\n",
    " 'astronomy',\n",
    " 'atmospheric',\n",
    " 'automation',\n",
    " 'bifurcation',\n",
    " 'bioengineering',\n",
    " 'bioinformatics',\n",
    " 'biomaterials',\n",
    " 'biotechnology',\n",
    " 'broadband',\n",
    " 'catalysis',\n",
    " 'chaos',\n",
    " 'circuits',\n",
    " 'computation',\n",
    " 'computational',\n",
    " 'computer',\n",
    " 'computing',\n",
    " 'crystal',\n",
    " 'crystallography',\n",
    " 'cyber',\n",
    " 'dynamics',\n",
    " 'earth',\n",
    " 'educational technology',\n",
    " 'edutainment',\n",
    " 'e-government',\n",
    " 'e-learning',\n",
    " 'electrical',\n",
    " 'electronics',\n",
    " 'energy',\n",
    " 'engineering',\n",
    " 'engineers',\n",
    " 'equations',\n",
    " 'ergonomics',\n",
    " 'fisika',\n",
    " 'force',\n",
    " 'geochemistry',\n",
    " 'geometry',\n",
    " 'geoscience',\n",
    " 'ieee',\n",
    " 'informatics',\n",
    " 'internet',\n",
    " 'linguistics',\n",
    " 'linguística',\n",
    " 'manufacturing',\n",
    " 'matemática',\n",
    " 'material',\n",
    " 'mathematical',\n",
    " 'mathematics',\n",
    " 'mathematics',\n",
    " 'metallurgy',\n",
    " 'measurement',\n",
    " 'mechanical',\n",
    " 'mechanics',\n",
    " 'microchimica',\n",
    " 'microchemistry',\n",
    " 'microelectronics',\n",
    " 'microsystems',\n",
    " 'nanotechnology',\n",
    " 'navigation',\n",
    " 'nuclear',\n",
    " 'oberflächentechnik',\n",
    " 'optic',\n",
    " 'optical',\n",
    " 'particles',\n",
    " 'physics',\n",
    " 'planetary',\n",
    " 'plastic',\n",
    " 'polymer',\n",
    " 'robotic',\n",
    " 'satellite',\n",
    " 'sensing',\n",
    " 'sensors',\n",
    " 'software',\n",
    " 'solar',\n",
    " 'sound',\n",
    " 'statistics',\n",
    " 'steel',\n",
    " 'superconductivity',\n",
    " 'surface technology',\n",
    " 'telecommunications',\n",
    " 'thermo',\n",
    " 'topology',\n",
    " 'transportation',\n",
    " 'waste',\n",
    " 'waves',\n",
    " 'wireless']\n",
    "\n",
    "socialscience_words= ['accounting',\n",
    " 'age',\n",
    " 'aging',\n",
    " 'anthropology',\n",
    " 'archaeology',\n",
    " 'architecture',\n",
    " 'art',\n",
    " 'behavioral',\n",
    " 'bioethics',\n",
    " 'business',\n",
    " 'christian',\n",
    " 'church',\n",
    " 'cognition',\n",
    " 'consumer',\n",
    " 'crime',\n",
    " 'criminology',\n",
    " 'crisis',\n",
    " 'cultural',\n",
    " 'decision',\n",
    " 'e-government',\n",
    " 'e-learning',\n",
    " 'econometric',\n",
    " 'economic',\n",
    " 'economics',\n",
    " 'economy',\n",
    " 'education',\n",
    " 'educational',\n",
    " 'educational technology',\n",
    " 'ekonomi',\n",
    " 'entrepreneurship',\n",
    " 'environment',\n",
    " 'ethics',\n",
    " 'ethnography',\n",
    " 'family',\n",
    " 'finance',\n",
    " 'financial',\n",
    " 'forensic',\n",
    " 'geograph',\n",
    " 'governance',\n",
    " 'history',\n",
    " 'humanities',\n",
    " 'identity',\n",
    " 'interpreter',\n",
    " 'islam',\n",
    " 'jew',\n",
    " 'jewish',\n",
    " 'judge',\n",
    " 'juridica',\n",
    " 'juridical',\n",
    " 'justice',\n",
    " 'law',\n",
    " 'learning',\n",
    " 'legal',\n",
    " 'librarian',\n",
    " 'linguistic',\n",
    " 'linguistics',\n",
    " 'linguistik',\n",
    " 'linguística',\n",
    " 'marital',\n",
    " 'market',\n",
    " 'marketing',\n",
    " 'media',\n",
    " 'microeconomics',\n",
    " 'mikroökonomik',\n",
    " 'museum',\n",
    " 'muslim',\n",
    " 'naturalist',\n",
    " 'pedagogy',\n",
    " 'pedagogía',\n",
    " 'pedagógika',\n",
    " 'pedagógike',\n",
    " 'personality',\n",
    " 'philosoph',\n",
    " 'philosophy',\n",
    " 'police',\n",
    " 'policy',\n",
    " 'politic',\n",
    " 'politics',\n",
    " 'pravo',\n",
    " 'psychoanalysis',\n",
    " 'psychology',\n",
    " 'punishment',\n",
    " 'religion',\n",
    " 'reorganisation',\n",
    " 'school',\n",
    " 'sex',\n",
    " 'social',\n",
    " 'society',\n",
    " 'sociologies',\n",
    " 'sociology',\n",
    " 'sozialgeschichte',\n",
    " 'sport',\n",
    " 'sustainable',\n",
    " 'taxes',\n",
    " 'teaching',\n",
    " 'tourism',\n",
    " 'trade',\n",
    " 'transportation',\n",
    " 'wrestling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_titles = journalknownretraction_notcat2['name_clean'].tolist()\n",
    "cate2 = []\n",
    "\n",
    "for i in range(0,len(clean_titles)):\n",
    "    cate = []\n",
    "    if any(item in clean_titles[i] for item in physicalscience_words):\n",
    "        cate.append('Physical Sciences')\n",
    "    if any(item in clean_titles[i] for item in healthscience_words):\n",
    "        cate.append('Health Science')\n",
    "    if any(item in clean_titles[i] for item in socialscience_words):\n",
    "        cate.append('Social Science')\n",
    "    if any(item in clean_titles[i] for item in lifescience_words):\n",
    "        cate.append('Life Science')\n",
    "        \n",
    "    cate2.append(cate)\n",
    "\n",
    "        \n",
    "journalknownretraction_notcat2['MainCategory'] = cate2\n",
    "\n",
    "journalknownretraction_notcat2['MainCategory'] = [', '.join(map(str, l)) for l in journalknownretraction_notcat2['MainCategory']]\n",
    "journalknownretraction_notcat2['MainCategory'] = journalknownretraction_notcat2['MainCategory'].astype(str).replace('', np.nan)\n",
    "\n",
    "journalknownretraction_notcat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering classified and unclassified after using manually generate keyword approach\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_cat3 = journalknownretraction_notcat2[~((journalknownretraction_notcat2['MainCategory'].isna()) |\\\n",
    "                               (journalknownretraction_notcat2['MainCategory'] == ''))]\n",
    "\n",
    "journalknownretraction_notcat_last = journalknownretraction_notcat2[(journalknownretraction_notcat2['MainCategory'].isna()) |\\\n",
    "                               (journalknownretraction_notcat2['MainCategory'] == '')]\n",
    "\n",
    "third_pass = get_resolved_journaltitle_count(journalknownretraction_notcat2)\n",
    "\n",
    "print(f'Categorized Round 3: The total number of second phase classified journal titles is {third_pass[0]}')\n",
    "print(f'The total number of classified journal titles from first, second & third phases is {first_pass[0]+second_pass[0]+third_pass[0]}')\n",
    "print(f'Uncategorized Round 3: The total number of remaining unclassified journal titles is {third_pass[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with manually curated list approach\n",
    "\"\"\"\n",
    "\n",
    "df_thirdpass = pd.merge(journalknownretraction_unique,journalknownretraction_cat3.iloc[:,:], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_thirdpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_thirdpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched with manually curated list approach is:', no_doi_thirdpass)\n",
    "print(f'Which is {no_doi_thirdpass/len(knownretractionlist)*100:.2f}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Joining all the journal titles that were classified: journalknownretraction_cat1,journalknownretraction_cat2,\n",
    "journalknownretraction_cat3 and the remaining unclassified one: journalknownretraction_notcat_last\n",
    "\n",
    "Output: journal_cat\n",
    "\n",
    "\"\"\"\n",
    "journalcategories = [journalknownretraction_cat1,journalknownretraction_cat2,\n",
    "                     journalknownretraction_cat3.iloc[:,:-1], journalknownretraction_notcat_last]\n",
    "\n",
    "journal_cat = pd.concat(journalcategories, axis=0).reset_index(drop=True).drop(['name_clean'], axis=1)\n",
    "\n",
    "assert len(journal_cat) == len(journalknownretraction_categories), 'Length of journal_cat should be equal to that of journalknownretraction_categories'\n",
    "# The table will not show if the assertion above is false.\n",
    "\n",
    "journal_cat\\\n",
    "#            .to_csv(data_dir+ 'journal/journalcategory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save journal categories to unionlist\n",
    "\"\"\"\n",
    "unionlist_updated=\\\n",
    "pd.merge(knownretractionlist,journal_cat.iloc[:,:], on='JournalandConferenceProceedings_lowercase', how='left')\n",
    "\n",
    "unionlist_updated.drop(['JournalandConferenceProceedings_lowercase', 'JournalandConferenceProceedings_clean'], axis=1, inplace=True)\n",
    "\n",
    "unionlist_updated\\\n",
    "#         .to_csv(data_dir+f\"unionlist/unionlist_completed_{getdate['unionlist']}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
