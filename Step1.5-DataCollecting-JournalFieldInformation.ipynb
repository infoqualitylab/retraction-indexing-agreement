{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5 : Journal Field Information\n",
    "- Part 1: Import Scopus Journal List to get upper-level field category for journals\n",
    "- Part 2: Identify Journal from the Known Retraction List that are not listed in the Scopus' Journal List\n",
    "- Part 3: Use YAKE to find keyword in each field and match with the journals\n",
    "- Part 4: Manually generate keywords and match with the rest of the journals\n",
    "- Part 5: Append the result of each step to the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yake\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import date, datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('\\\\.')\n",
    "path.parent.absolute()\n",
    "os.listdir()\n",
    "box_path_1= 'INPUT_YOUR_DATA_DIRECTORY'\n",
    "box_path_2 = 'INPUT_YOUR_RESULT_DIRECTORY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Import Scopus Journal List to get upper-level field category for journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Scopus journal classification. See latest version: https://www.elsevier.com/?a=91122\n",
    "\n",
    "try:\n",
    "    scopus_journal_data = pd.read_excel(box_path_1+'extlistJune2023.xlsx',sheet_name=None)  #,encoding ='utf-8',errors='ignore'\n",
    "except UnicodeDecodeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scopus_journal_sheet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_journal_data_sheets_names = list(scopus_journal_data.keys())\n",
    "scopus_journal_sheet = scopus_journal_data[scopus_journal_data_sheets_names[0]]\n",
    "\n",
    "selected_columns=['Source Title (Medline-sourced journals are indicated in Green)',\n",
    "                  'Top level:\\n\\nLife Sciences','Top level:\\n\\nSocial Sciences',\n",
    "                  'Top level:\\n\\nPhysical Sciences','Top level:\\n\\nHealth Sciences',\n",
    "                  '1000 \\nGeneral']\n",
    "\n",
    "scopus_journal_filtered = scopus_journal_sheet.filter(items = selected_columns).replace('',np.nan)\n",
    "scopus_journal_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Joining the cell values for each category within the subject areas for each of the journal titles\n",
    "\"\"\"\n",
    "\n",
    "# 'MainCategory' <-- Concatenate the cell values for journal titles \n",
    "scopus_journal_filtered['MainCategory'] = scopus_journal_filtered.apply(lambda row: ','.join(\\\n",
    "    filter(lambda x: pd.notna(x), [row[column] for column in selected_columns[1:]])),axis=1)\n",
    "\n",
    "\n",
    "scopus_journal_filtered = scopus_journal_filtered.rename(columns={selected_columns[0]:'JournalandConferenceProceedings'})  #journalscopus = journalscopus\n",
    "\n",
    "# scopus_journal <-- Select needed column of interesr \n",
    "scopus_journal_part = scopus_journal_filtered[['JournalandConferenceProceedings','MainCategory']]\n",
    "\n",
    "#founded.to_csv(save_file_dir_proj+'journal/journalcategory_founded_tempo.csv')\n",
    "\n",
    "#scopus_journal.to_csv(save_file_dir_proj+'journal/scopus_journalsubject.csv')\n",
    "scopus_journal_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Scopus conference categories \n",
    "conference_sheet = scopus_journal_data[scopus_journal_data_sheets_names[3]].iloc[:,[1,-1]]\n",
    "conference_sheet = conference_sheet.rename(columns={'All Science Journal Classification Codes (ASJC)':'ASJC',\n",
    "                                                   'Source Title': 'JournalandConferenceProceedings'})\n",
    "conference_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assigning main category subjects to their ASJC codes\n",
    "\"\"\"\n",
    "lookup={\n",
    "10: 'General',\n",
    "11: 'Life Sciences',\n",
    "12: 'Social Sciences',\n",
    "13: 'Life Sciences',\n",
    "14: 'Social Sciences',\n",
    "15: 'Physical Sciences',\n",
    "16: 'Physical Sciences',\n",
    "17: 'Physical Sciences',\n",
    "18: 'Social Sciences',\n",
    "19: 'Physical Sciences',\n",
    "20: 'Social Sciences',\n",
    "21: 'Physical Sciences',\n",
    "22: 'Physical Sciences',\n",
    "23: 'Physical Sciences',\n",
    "24: 'Life Sciences',\n",
    "25: 'Physical Sciences',\n",
    "26: 'Physical Sciences',\n",
    "27: 'Health Sciences',\n",
    "28: 'Life Sciences',\n",
    "29: 'Health Sciences',\n",
    "30: 'Life Sciences',\n",
    "31: 'Physical Sciences',\n",
    "32: 'Social Sciences',\n",
    "33: 'Social Sciences',\n",
    "34: 'Health Sciences',\n",
    "35: 'Health Sciences',\n",
    "36: 'Health Sciences'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_asjc_to_category(asjc_value):\n",
    "    \"\"\"\n",
    "    :params asjc_value: the ASJC code of the journal & Conference proceedings\n",
    "    This function assign conference proceedings of the Scopus their main categories\n",
    "    \"\"\"\n",
    "    store=[]\n",
    "    asjc_values = asjc_value.strip().split(';')\n",
    "\n",
    "    for values in asjc_values:\n",
    "        if values:\n",
    "            values=values.strip()\n",
    "#             print(values)\n",
    "#             print((values[:2]))\n",
    "#         print(lookup[int(values[:2])])\n",
    "            store.append(lookup[int(values[:2])])\n",
    "    \n",
    "    store = list(set(store))\n",
    "    return ','.join(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conference_sheet['ASJC']=conference_sheet['ASJC'].fillna(\"\")\n",
    "# conference_sheet['ASJC']= conference_sheet['ASJC'].apply(str)\n",
    "conference_sheet['MainCategory'] = conference_sheet['ASJC'].apply(map_asjc_to_category)\n",
    "conference_sheet_part= conference_sheet[['JournalandConferenceProceedings','MainCategory']]\n",
    "conference_sheet_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scopus_journal_part[scopus_journal_part['MainCategory'].str.contains('General')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending Both the Journal titles & Conferences from Scopus\n",
    "\n",
    "journalscopus = pd.concat([scopus_journal_part,conference_sheet_part])\n",
    "journalscopus\n",
    "#journalscopus.to_csv(box_path_1+'scopus_journalconferencecategory.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(journalscopus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Scopus Journal List\n",
    "journalscopus = pd.read_csv(box_path_1 + 'scopus_journalconferencecategory.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "journalscopus['JournalandConferenceProceedings_lowercase'] = journalscopus['JournalandConferenceProceedings'].str.lower().str.strip()\n",
    "journalscopus_deduplicated = journalscopus.drop_duplicates(subset='JournalandConferenceProceedings_lowercase')\n",
    "journalscopus_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalscopus[~journalscopus['MainCategory'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Cleaning the Journal Title's Names in the KnownRetraction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownretractionlist= pd.read_csv(box_path_1 +'2023-04-13-knownretractionlist.csv').drop(['Unnamed: 0','MainCategory'],axis=1)\n",
    "knownretractionlist['JournalandConferenceProceedings_lowercase'] = knownretractionlist['Journal'].str.lower().str.strip()\n",
    "\n",
    "journalknownretraction_= knownretractionlist[['Journal','JournalandConferenceProceedings_lowercase']].rename(columns={'Journal': 'JournalandConferenceProceedings'})\n",
    "\n",
    "journalknownretraction_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_journal_title(df_: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    param df_: The dataframe to work with\n",
    "    :return: Dataframe with clean column\n",
    "    \"\"\"\n",
    "    df= df_.copy(deep=True)\n",
    "    df['JournalandConferenceProceedings_clean'] = df_['JournalandConferenceProceedings'].str.strip().str.lower()\n",
    "\n",
    "    # remove '&amp and '&'\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(\"&amp\", \"\").str.replace(\"&\", \"\")\n",
    "\n",
    "    # remove 'the' if it starts a journal title\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(r'(?i)^(the) ', '',regex=True)\n",
    "\n",
    "    # remove position such 1st, 2nd, 3rd, 4th from the journal titles\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].apply(lambda x: re.sub(r'\\b\\d+(st|nd|rd|th)\\b', '', x)) #re.sub(r'\\b\\d+(st|nd|rd|th)\\b', '', text)\n",
    "\n",
    "    # remove other digits and punctuation from the journal titles\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].apply(lambda x: re.sub(r'[^\\w\\s]|[\\d]', '', x))\n",
    "\n",
    "    #remove extra whitespace in between words\n",
    "    df['JournalandConferenceProceedings_clean'] = df['JournalandConferenceProceedings_clean'].str.replace(r'\\s+', ' ',regex=True).str.strip()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Journal Titles \n",
    "journalknownretraction_clean = clean_journal_title(journalknownretraction_)\n",
    "\n",
    "#journalknownretraction_clean.groupby('JournalandConferenceProceedings_clean')['JournalandConferenceProceedings'].count().reset_index()\n",
    "after_cleaning = len(journalknownretraction_clean[['JournalandConferenceProceedings_clean']].drop_duplicates())\n",
    "\n",
    "print(f'The total number of journal titles in the knownretraction list is {after_cleaning} after cleaning')\n",
    "journalknownretraction_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the journalknownretraction_clean file for OpenRefine further cleaning\n",
    "#journalknownretraction_clean.to_csv(box_path_1+'2023-08-08-journalcategory-knownretractionlist_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journalknownretraction_clean2 = pd.read_csv(box_path_1+ '2023-08-08-STI_journalcategory_openrefined_cleaned.csv').drop('Column', axis=1)\n",
    "\n",
    "after_cleaning2 = len(journalknownretraction_clean2[['JournalandConferenceProceedings_clean']].drop_duplicates())\n",
    "\n",
    "print(f'The total number of journal titles in the knownretraction list is {after_cleaning2} after cleaning with OpenRefine')\n",
    "journalknownretraction_clean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Identify Journal Field Category from the Scopus Journal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resolved_journaltitle_count(df: pd.DataFrame()):\n",
    "    \"\"\"\n",
    "    It gets unique count of journal titles based on 'JournalandConferenceProceedings_clean' column\n",
    "    \"\"\"\n",
    "    x = df.copy(deep=True)\n",
    "    xC = x[~x.MainCategory.isna()][['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    xCnot = x[x.MainCategory.isna()][['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    xT = x[['JournalandConferenceProceedings_clean']].drop_duplicates()\n",
    "    \n",
    "    return len(xC),len(xCnot),len(xT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use 'JournalandConferenceProceedings' to merge with Scopus journal list\n",
    "journalknownretraction_clean2['JournalandConferenceProceedings_lowercase'] = journalknownretraction_clean2['JournalandConferenceProceedings'].str.lower().str.strip()\n",
    "\n",
    "journalknownretraction= pd.merge(journalknownretraction_clean2,journalscopus_deduplicated.iloc[:,1:], on='JournalandConferenceProceedings_lowercase', how='left')\n",
    "\n",
    "print(get_resolved_journaltitle_count(journalknownretraction))\n",
    "\"\"\"\n",
    "Mapping out items from 'JournalandConferenceProceedings_clean' with no MainCategory with\n",
    "same items in 'JournalandConferenceProceedings_lowercase' that have MainCategory. This is because items were merged\n",
    "with Scopus journal list based on 'JournalandConferenceProceedings_lowercase'\n",
    "\"\"\"\n",
    "mapping = journalknownretraction.dropna(subset=['MainCategory']).set_index('JournalandConferenceProceedings_clean')['MainCategory']\n",
    "\n",
    "# Fill in missing values in column using the mapping\n",
    "journalknownretraction['MainCategory'] = journalknownretraction['MainCategory'].fillna(journalknownretraction['JournalandConferenceProceedings_clean'].map(mapping))\n",
    "\n",
    "\n",
    "#journalknownretraction[journalknownretraction['MainCategory'].isna()][['JournalandConferenceProceedings_clean']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Of {after_cleaning2} total number of journal titles in the knownretractionlist')\n",
    "first_pass = get_resolved_journaltitle_count(journalknownretraction)\n",
    "print(f'The total no of classified journal titles with Scopus Journal is {first_pass[0]} and {first_pass[1]} remaining unclassified')\n",
    "\n",
    "print(f'That is {(first_pass[0]/after_cleaning2)*100}% classified journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with Scopus classification\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_firstpass = pd.merge(journalknownretraction_clean2,journalscopus_deduplicated.iloc[:,1:], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_firstpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_firstpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched in Scopus journal list is:' , no_doi_firstpass)\n",
    "print(f'Which is {round(no_doi_firstpass/len(knownretractionlist)*100,2)}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Identify Journal from the Known Retraction List that are not listed in the Scopus' Journal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Journals from the known retraction list that are categorized\n",
    "#journalknownretraction_cat = journalknownretraction.merge(journalscopus, left_on= 'JournalandConferenceProceedings_lowercase', right_on= 'JournalandConferenceProceedings_lowercase', how='left')\n",
    "\n",
    "journalknownretraction.MainCategory = journalknownretraction.MainCategory.str.strip()\n",
    "journalknownretraction_cat = journalknownretraction[~journalknownretraction['MainCategory'].isnull()].copy(deep=True)\n",
    "#print(journalknownretraction_cat.info())\n",
    "\n",
    "# Identify Journals from the known retraction list that are not categorized to any field\n",
    "journalknownretraction_notcat = journalknownretraction[journalknownretraction['MainCategory'].isnull()].copy(deep=True)\n",
    "# journalknownretraction_notcat.MainCategory= journalknownretraction_cat.MainCategory.str.strip()\n",
    "\n",
    "# #print(journalknownretraction_notcat.info())\n",
    "print('Count of Journal that are not categorized: ', first_pass[1])\n",
    "print(f'Percentage of Journals that are not categoriezed: {round(int(first_pass[1])/int(after_cleaning2)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Use YAKE to find keyword in each field and match with the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of journal name str from journals that are categorized\n",
    "lifescience = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Life Science')]['JournalandConferenceProceedings_clean']\n",
    "lifescience_ = \" \".join(lifescience)\n",
    "lifescience_list  = re.sub(r'[^\\w\\s]', '', lifescience_).split()\n",
    "\n",
    "healthscience= journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Health Science')]['JournalandConferenceProceedings_clean']\n",
    "healthscience_ = \" \".join(healthscience)\n",
    "healthscience_list  = re.sub(r'[^\\w\\s]', '', healthscience_).split()\n",
    "\n",
    "\n",
    "physicalscience = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Physical Science')]['JournalandConferenceProceedings_clean']\n",
    "physicalscience_ = \" \".join(physicalscience)\n",
    "physicalscience_list  = re.sub(r'[^\\w\\s]', '', physicalscience_).split()\n",
    "\n",
    "socialscience= journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Social Science')]['JournalandConferenceProceedings_clean']\n",
    "socialscience_ = \" \".join(socialscience)\n",
    "socialscience_list  = re.sub(r'[^\\w\\s]', '', socialscience_).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stopwordsiso\n",
    "import stopwordsiso as stopwords\n",
    "\n",
    "# stop words list of all languages in the ISO-639 standard was used to process the titles. \n",
    "# https://github.com/stopwords-iso/stopwords-iso  stopwords.stopwords(\"en\") stopwords.stopwords.lang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat list of stopwords\n",
    "new_stopwords = ['&', '&amp', 'acta', 'africa', 'african', 'albania', 'albanian', 'america', 'american', 'and', \n",
    "                 'andorra', 'applied', 'archives', 'armenia', 'asian', 'asian-australasian', 'association', 'australasian', \n",
    "                 'austria', 'austrian', 'azerbaijan', 'belarus', 'belgium', 'bmc', 'bosnia', 'brazil', 'brazilian', 'british', \n",
    "                 'bulgaria', 'bulgarian', 'bulletin', 'cadernos', 'canadian', 'china', 'chinese', 'communication', 'communications', \n",
    "                 'conference', 'croatia', 'croatian', 'current', 'cyprus', 'czech', 'denmark', 'dynamic', 'dynamics', 'east', \n",
    "                 'elife', 'estonia', 'europe', 'european', 'experimental', 'f1000research', 'finland', 'france', 'georgia', \n",
    "                 'german', 'germany', 'greece', 'herzegovina', 'hungary', 'iceland', 'india', 'indian', 'indonesia', 'indonesian', \n",
    "                 'international', 'iran', 'iranian', 'ireland', 'italian', 'italy', 'jama', 'japan', 'japanese', 'journal', 'jurnal', \n",
    "                 'kazakhstan', 'korean', 'latvia', 'lecture', 'letters', 'liechtenstein', 'list', 'lithuania', 'luxembourg', 'macedonia', \n",
    "                 'malta', 'management', 'moldova', 'monaco', 'montenegro', 'moscow', 'national academy', 'netherlands', 'north', 'norway',\n",
    "                 'note', 'notes', 'opinion', 'oxford', 'peerj', 'poland', 'portugal', 'proceeding', 'proceedings', 'reports', 'republic',\n",
    "                 'research', 'review', 'reviews', 'revista', 'romania', 'russia', 'russian', 'saudi', 'scandinavian', 'science', 'sciences',\n",
    "                 'serbia', 'serials', 'slovakia', 'slovenia', 'society', 'south', 'spain', 'spainish', 'studies', 'sweden', 'switzerland',\n",
    "                 'targets', 'trabalhos', 'turkey', 'turkukraine', 'uk', 'ukrainian', 'united kingdom', 'universities', 'university', 'vakblad', 'west']\n",
    "\n",
    "\n",
    "#\"de\", \"id\", \"zh\"\n",
    "new_stopwords.extend(stopwords.stopwords([\"en\",\"de\",\"fr\", \"la\",\"ru\"])) # adding English stopwords\n",
    "# new_stopwords.extend(stopwords.stopwords(\"fr\")) # adding French stopwords\n",
    "# new_stopwords.extend(stopwords.stopwords(\"de\")) # adding German stopwords\n",
    "# Add stopwords from stopwordsiso #stopwords.langs()  stopwords.stopwords(\"en\")\n",
    "print('The total stopwords is ',len(new_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing stopwords from the main categories lists\n",
    "\"\"\"\n",
    "lifescience_str= set(lifescience_list)\n",
    "healthscience_str = set(healthscience_list)\n",
    "physicalscience_str= set(physicalscience_list)\n",
    "socialscience_str= set(socialscience_list)\n",
    "\n",
    "for remove_item in set(new_stopwords):\n",
    "    if remove_item in lifescience_str:\n",
    "        lifescience_str.remove(remove_item)\n",
    "    if remove_item in healthscience_str:\n",
    "        healthscience_str.remove(remove_item)\n",
    "    if remove_item in physicalscience_str:\n",
    "        physicalscience_str.remove(remove_item)\n",
    "    if remove_item in socialscience_str:\n",
    "        socialscience_str.remove(remove_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting relevant keywords in each field\n",
    "\"\"\"\n",
    "text_list = [lifescience_str, healthscience_str, physicalscience_str, socialscience_str]\n",
    "store_keywords = []\n",
    "\n",
    "for i in text_list:\n",
    "    keywords_per_science=[]\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    text = ' '.join(set(i))\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1\n",
    "    deduplication_threshold = 0.5\n",
    "    numOfKeywords = 1000\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    for kw in keywords:\n",
    "        keywords_per_science.append(kw[0])\n",
    "    store_keywords.append(keywords_per_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to display the keywords of each field\n",
    "cat = ['Life Sciences', 'Health Sciences', 'Physical Sciences', 'Social Sciences']\n",
    "cat_key_df = pd.DataFrame()\n",
    "\n",
    "cat_key_df['Categories'] = cat\n",
    "\n",
    "#lifescience_keywords,healthscience_keywords,physicalscience_keywords,socialscience_keywords = store_keywords\n",
    "cat_key_df['Keyword'] = [store_keywords[0], store_keywords[1], store_keywords[2], store_keywords[3]]\n",
    "\n",
    "cat_key_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to categorize journals and return a list of categories\n",
    "def categorize_journal(title, cat_key_df):\n",
    "    \"\"\"\n",
    "    It categorizes the journal titles into subjects\n",
    "    :param title: the title of the journal\n",
    "    :param cat_key_df: list of topical keywords\n",
    "    \n",
    "    :return: the main categories of the title\n",
    "    \"\"\"\n",
    "    categories = []\n",
    "    for index, row in cat_key_df.iterrows():\n",
    "        if any(keyword in title for keyword in row['Keyword']):\n",
    "            categories.append(row['Categories'])\n",
    "    return categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate not yet classified journal titles and categorize using categorize_journal\n",
    "for i in range(len(journalknownretraction_notcat)):\n",
    "\n",
    "    title = journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'].iloc[i]\n",
    "    categories = categorize_journal(title, cat_key_df)\n",
    "    \n",
    "    if categories:\n",
    "        journalknownretraction_notcat['MainCategory'].iloc[i] = ', '.join(categories)\n",
    "\n",
    "journalknownretraction_notcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering classified and unclassified after using YAKE approach\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_cat2 = journalknownretraction_notcat[~journalknownretraction_notcat['MainCategory'].isna()]\n",
    "# print(f'Categoried 2: The total number of second classified journal titles is {len(journalknownretraction_cat2)}')\n",
    "\n",
    "\n",
    "\n",
    "journalknownretraction_notcat2 = journalknownretraction_notcat[journalknownretraction_notcat['MainCategory'].isna()]\n",
    "# print(f'Uncategoried 2: The total number of remaining unclassified journal titles from \\\n",
    "# journalknownretraction_notcat2 is {len(journalknownretraction_notcat2)}')\n",
    "\n",
    "second_pass = get_resolved_journaltitle_count(journalknownretraction_notcat)\n",
    "print(f'Categoried 2: The total number of second phase classified journal titles is {second_pass[0]}')\n",
    "print(f'The total number of classified journal titles from first & second phase is {first_pass[0]+second_pass[0]}')\n",
    "print(f'Uncategoried 2: The total number of remaining unclassified journal titles is {second_pass[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with YAKE approach\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_secondpass = pd.merge(journalknownretraction_clean2,journalknownretraction_cat2.iloc[:,1:4], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_secondpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_secondpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched with YAKE Approach is:' , no_doi_secondpass)\n",
    "print(f'Which is {round(no_doi_secondpass/len(knownretractionlist)*100,2)}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Manually generate keywords and match with the rest of the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nameclean = []\n",
    "for i in journalknownretraction_notcat2['JournalandConferenceProceedings_clean']:\n",
    "    #notfound['name_clean']=[]\n",
    "    stripped = i.split('(', 1)[0]\n",
    "    stripped = i.split('=', 1)[0]\n",
    "    nameclean.append(stripped)\n",
    "\n",
    "journalknownretraction_notcat2['name_clean'] = nameclean\n",
    "\n",
    "journalknownretraction_notcat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifescience_words = ['acids',\n",
    " 'agric',\n",
    " 'agronomy',\n",
    " 'akuakultur',\n",
    " 'anatomical',\n",
    " 'anatomy',\n",
    " 'aquaculture',\n",
    " 'bacteriology',\n",
    " 'biochemistry',\n",
    " 'bioengineering',\n",
    " 'bioethics',\n",
    " 'bioinformatics',\n",
    " 'biolog',\n",
    " 'biological',\n",
    " 'biology',\n",
    " 'biomedicine',\n",
    " 'biomolecular',\n",
    " 'biophysics',\n",
    " 'biorxiv',\n",
    " 'biotechnology',\n",
    " 'cell',\n",
    " 'cells',\n",
    " 'cellular',\n",
    " 'chemical',\n",
    " 'chemie',\n",
    " 'chemistry',\n",
    " 'clinic',\n",
    " 'clínica',\n",
    " 'crispr',\n",
    " 'cytology',\n",
    " 'dendrology',\n",
    " 'dna',\n",
    " 'ecology',\n",
    " 'endocrinology',\n",
    " 'entomologica',\n",
    " 'entomology',\n",
    " 'epidemiology',\n",
    " 'evolution',\n",
    " 'genetics',\n",
    " 'genomic',\n",
    " 'genomics',\n",
    " 'histology',\n",
    " 'immunology',\n",
    " 'lipids',\n",
    " 'medical',\n",
    " 'medrxiv',\n",
    " 'microbial',\n",
    " 'microbiology',\n",
    " 'microchemistry',\n",
    " 'microchimica',\n",
    " 'microrna',\n",
    " 'microscopy',\n",
    " 'molecul',\n",
    " 'molecular',\n",
    " 'mosquito',\n",
    " 'nanomedicine',\n",
    " 'nematology',\n",
    " 'neurochemistry',\n",
    " 'neurology',\n",
    " 'neurophysiology',\n",
    " 'neuroscience',\n",
    " 'nicotine',\n",
    " 'nucleosides',\n",
    " 'nucleotides',\n",
    " 'parasites',\n",
    " 'pathology',\n",
    " 'pharmaceutics',\n",
    " 'pharmacology',\n",
    " 'pharmocognosy',\n",
    " 'physiology',\n",
    " 'plant',\n",
    " 'polyadenylation',\n",
    " 'poultry',\n",
    " 'protein',\n",
    " 'tobacco',\n",
    " 'toxicology',\n",
    " 'virology',\n",
    " ]\n",
    "\n",
    "healthscience_words= [ 'age',\n",
    " 'aging',\n",
    " 'aids',\n",
    " 'anaesthesia',\n",
    " 'anaesthesist',\n",
    " 'anästhesiologie',\n",
    " 'anatomy',\n",
    " 'anesthesia',\n",
    " 'anesthesiology',\n",
    " 'arthritis',\n",
    " 'biochemistry',\n",
    " 'bioengineering',\n",
    " 'bioethics',\n",
    " 'biomedical',\n",
    " 'biorxiv',\n",
    " 'biotechnology',\n",
    " 'blood',\n",
    " 'bone',\n",
    " 'cancer',\n",
    " 'cardiac',\n",
    " 'cardiological',\n",
    " 'cardiologist',\n",
    " 'cardiology',\n",
    " 'cardiovascular',\n",
    " 'chiropractic',\n",
    " 'chirurg',\n",
    " 'cirugía',\n",
    " 'clinic',\n",
    " 'clínica',\n",
    " 'clinical',\n",
    " 'counseling',\n",
    " 'craniofacial',\n",
    " 'dementia',\n",
    " 'dental',\n",
    " 'dentistry',\n",
    " 'dermatology',\n",
    " 'dermo-sifiliográficas',\n",
    " 'dermo-sifiliographics',\n",
    " 'diabetes',\n",
    " 'diabetology',\n",
    " 'digestive',\n",
    " 'disease',\n",
    " 'diseases',\n",
    " 'drug',\n",
    " 'drugs',\n",
    " 'e-health',\n",
    " 'endocrinology',\n",
    " 'enfermería',\n",
    " 'epidemiology',\n",
    " 'epilepsy',\n",
    " 'eye',\n",
    " 'foot',\n",
    " 'gastroenterology',\n",
    " 'genetics',\n",
    " 'geriatrics',\n",
    " 'gerontologist',\n",
    " 'gerontology',\n",
    " 'gynaecologist',\n",
    " 'gynécologie',\n",
    " 'gynecology',\n",
    " 'health',\n",
    " 'heart',\n",
    " 'hematology',\n",
    " 'hemostasis',\n",
    " 'hypertension',\n",
    " 'imaging',\n",
    " 'immunology',\n",
    " 'infection',\n",
    " 'infectious',\n",
    " 'intervention',\n",
    " 'kardiologe',\n",
    " 'lancet',\n",
    " 'leukemia',\n",
    " 'liver',\n",
    " 'lymphoma',\n",
    " 'maxillofacial',\n",
    " 'medical',\n",
    " 'médicale',\n",
    " 'medicine',\n",
    " 'medrxiv',\n",
    " 'metabolic',\n",
    " 'metabolism',\n",
    " 'microbiology',\n",
    " 'molecular',\n",
    " 'morbidity',\n",
    " 'nefrología',\n",
    " 'néphrologie',\n",
    " 'néphrologology',\n",
    " 'nephrology',\n",
    " 'neuro',\n",
    " 'neurology',\n",
    " 'neurotology',\n",
    " 'nicotine',\n",
    " 'nurse',\n",
    " 'nursing',\n",
    " 'nutrition',\n",
    " 'obesity',\n",
    " 'obstetrician',\n",
    " 'obstetrics',\n",
    " 'occupational',\n",
    " 'oncology',\n",
    " 'onkologie',\n",
    " 'ophthalmic',\n",
    " 'ophthalmologe',\n",
    " 'ophthalmology',\n",
    " 'oral',\n",
    " 'orthopäde',\n",
    " 'orthopaedic',\n",
    " 'orthopaedics',\n",
    " 'orthopedist',\n",
    " 'ortopediya',\n",
    " 'osteoporosis',\n",
    " 'otorhinolaryngology',\n",
    " 'pain',\n",
    " 'parasites',\n",
    " 'pathology',\n",
    " 'patient',\n",
    " 'pediatría',\n",
    " 'pediatric',\n",
    " 'pediatrics',\n",
    " 'pédiatrie',\n",
    " 'pharmaceutical',\n",
    " 'pharmacology',\n",
    " 'pharmazie',\n",
    " 'pharmocognosy',\n",
    " 'physiology',\n",
    " 'prosthodontics',\n",
    " 'psychiatry',\n",
    " 'psychoanalysis',\n",
    " 'psychology',\n",
    " 'psychonomic',\n",
    " 'pulmonology',\n",
    " 'radiology',\n",
    " 'rehabilitación',\n",
    " 'rehabilitation',\n",
    " 'reproductive',\n",
    " 'respiration',\n",
    " 'respiratory',\n",
    " 'retina',\n",
    " 'reumatologia',\n",
    " 'reumatología',\n",
    " 'revista',\n",
    " 'rheumatology',\n",
    " 'roentgenology',\n",
    " 'sclerosis',\n",
    " 'seizure',\n",
    " 'shoulder',\n",
    " 'spine',\n",
    " 'std',\n",
    " 'surgeon',\n",
    " 'surgery',\n",
    " 'surgical',\n",
    " 'thrombosis',\n",
    " 'thyroid',\n",
    " 'tobacco',\n",
    " 'toxicology',\n",
    " 'trauma',\n",
    " 'urological',\n",
    " 'urológicas',\n",
    " 'urology',\n",
    " 'vascular',\n",
    " 'veterinar',\n",
    " 'veterinary',\n",
    " 'virology']\n",
    "\n",
    "\n",
    "physicalscience_words= ['acs',\n",
    " 'actuators',\n",
    " 'aeroacoustics',\n",
    " 'aerodynamic',\n",
    " 'aerospace',\n",
    " 'akuakultur',\n",
    " 'algebra',\n",
    " 'antenna',\n",
    " 'aquaculture',\n",
    " 'astro',\n",
    " 'astronomy',\n",
    " 'atmospheric',\n",
    " 'automation',\n",
    " 'bifurcation',\n",
    " 'bioengineering',\n",
    " 'bioinformatics',\n",
    " 'biomaterials',\n",
    " 'biotechnology',\n",
    " 'broadband',\n",
    " 'catalysis',\n",
    " 'chaos',\n",
    " 'circuits',\n",
    " 'computation',\n",
    " 'computational',\n",
    " 'computer',\n",
    " 'computing',\n",
    " 'crystal',\n",
    " 'crystallography',\n",
    " 'cyber',\n",
    " 'dynamics',\n",
    " 'earth',\n",
    " 'educational technology',\n",
    " 'edutainment',\n",
    " 'e-government',\n",
    " 'e-learning',\n",
    " 'electrical',\n",
    " 'electronics',\n",
    " 'energy',\n",
    " 'engineering',\n",
    " 'engineers',\n",
    " 'equations',\n",
    " 'ergonomics',\n",
    " 'fisika',\n",
    " 'force',\n",
    " 'geochemistry',\n",
    " 'geometry',\n",
    " 'geoscience',\n",
    " 'ieee',\n",
    " 'informatics',\n",
    " 'internet',\n",
    " 'linguistics',\n",
    " 'linguística',\n",
    " 'manufacturing',\n",
    " 'matemática',\n",
    " 'material',\n",
    " 'mathematical',\n",
    " 'mathematics',\n",
    " 'mathematics',\n",
    " 'metallurgy',\n",
    " 'measurement',\n",
    " 'mechanical',\n",
    " 'mechanics',\n",
    " 'microchimica',\n",
    " 'microchemistry',\n",
    " 'microelectronics',\n",
    " 'microsystems',\n",
    " 'nanotechnology',\n",
    " 'navigation',\n",
    " 'nuclear',\n",
    " 'oberflächentechnik',\n",
    " 'optic',\n",
    " 'optical',\n",
    " 'particles',\n",
    " 'physics',\n",
    " 'planetary',\n",
    " 'plastic',\n",
    " 'polymer',\n",
    " 'robotic',\n",
    " 'satellite',\n",
    " 'sensing',\n",
    " 'sensors',\n",
    " 'software',\n",
    " 'solar',\n",
    " 'sound',\n",
    " 'statistics',\n",
    " 'steel',\n",
    " 'superconductivity',\n",
    " 'surface technology',\n",
    " 'telecommunications',\n",
    " 'thermo',\n",
    " 'topology',\n",
    " 'transportation',\n",
    " 'waste',\n",
    " 'waves',\n",
    " 'wireless']\n",
    "\n",
    "socialscience_words= ['accounting',\n",
    " 'age',\n",
    " 'aging',\n",
    " 'anthropology',\n",
    " 'archaeology',\n",
    " 'architecture',\n",
    " 'art',\n",
    " 'behavioral',\n",
    " 'bioethics',\n",
    " 'business',\n",
    " 'christian',\n",
    " 'church',\n",
    " 'cognition',\n",
    " 'consumer',\n",
    " 'crime',\n",
    " 'criminology',\n",
    " 'crisis',\n",
    " 'cultural',\n",
    " 'decision',\n",
    " 'e-government',\n",
    " 'e-learning',\n",
    " 'econometric',\n",
    " 'economic',\n",
    " 'economics',\n",
    " 'economy',\n",
    " 'education',\n",
    " 'educational',\n",
    " 'educational technology',\n",
    " 'ekonomi',\n",
    " 'entrepreneurship',\n",
    " 'environment',\n",
    " 'ethics',\n",
    " 'ethnography',\n",
    " 'family',\n",
    " 'finance',\n",
    " 'financial',\n",
    " 'forensic',\n",
    " 'geograph',\n",
    " 'governance',\n",
    " 'history',\n",
    " 'humanities',\n",
    " 'identity',\n",
    " 'interpreter',\n",
    " 'islam',\n",
    " 'jew',\n",
    " 'jewish',\n",
    " 'judge',\n",
    " 'juridica',\n",
    " 'juridical',\n",
    " 'justice',\n",
    " 'law',\n",
    " 'learning',\n",
    " 'legal',\n",
    " 'librarian',\n",
    " 'linguistic',\n",
    " 'linguistics',\n",
    " 'linguistik',\n",
    " 'linguística',\n",
    " 'marital',\n",
    " 'market',\n",
    " 'marketing',\n",
    " 'media',\n",
    " 'microeconomics',\n",
    " 'mikroökonomik',\n",
    " 'museum',\n",
    " 'muslim',\n",
    " 'naturalist',\n",
    " 'pedagogy',\n",
    " 'pedagogía',\n",
    " 'pedagógika',\n",
    " 'pedagógike',\n",
    " 'personality',\n",
    " 'philosoph',\n",
    " 'philosophy',\n",
    " 'police',\n",
    " 'policy',\n",
    " 'politic',\n",
    " 'politics',\n",
    " 'pravo',\n",
    " 'psychoanalysis',\n",
    " 'psychology',\n",
    " 'punishment',\n",
    " 'religion',\n",
    " 'reorganisation',\n",
    " 'school',\n",
    " 'sex',\n",
    " 'social',\n",
    " 'society',\n",
    " 'sociologies',\n",
    " 'sociology',\n",
    " 'sozialgeschichte',\n",
    " 'sport',\n",
    " 'sustainable',\n",
    " 'taxes',\n",
    " 'teaching',\n",
    " 'tourism',\n",
    " 'trade',\n",
    " 'transportation',\n",
    " 'wrestling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_titles = journalknownretraction_notcat2['name_clean'].tolist()\n",
    "cate2 = []\n",
    "\n",
    "for i in range(0,len(clean_titles)):\n",
    "    cate = []\n",
    "    if any(item in clean_titles[i] for item in physicalscience_words):\n",
    "        cate.append('Physical Sciences')\n",
    "    if any(item in clean_titles[i] for item in healthscience_words):\n",
    "        cate.append('Health Science')\n",
    "    if any(item in clean_titles[i] for item in socialscience_words):\n",
    "        cate.append('Social Science')\n",
    "    if any(item in clean_titles[i] for item in lifescience_words):\n",
    "        cate.append('Life Science')\n",
    "        \n",
    "    cate2.append(cate)\n",
    "\n",
    "        \n",
    "journalknownretraction_notcat2['MainCategory'] = cate2\n",
    "\n",
    "journalknownretraction_notcat2['MainCategory'] = [', '.join(map(str, l)) for l in journalknownretraction_notcat2['MainCategory']]\n",
    "journalknownretraction_notcat2['MainCategory'] = journalknownretraction_notcat2['MainCategory'].astype(str).replace('', np.nan)\n",
    "# journalknownretraction_notcat2['MainCategory'] = journalknownretraction_notcat2['MainCategory'].astype(str).replace('nan', '')\n",
    "journalknownretraction_notcat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filtering classified and unclassified after using Manually generate keyword approach\n",
    "\"\"\"\n",
    "\n",
    "journalknownretraction_cat3 = journalknownretraction_notcat2[journalknownretraction_notcat2['MainCategory']!='']\n",
    "#print(f'Categoried 3: The total number of third classified journal titles is {len(journalknownretraction_cat3)}')\n",
    "\n",
    "\n",
    "\n",
    "journalknownretraction_notcat_last = journalknownretraction_notcat2[journalknownretraction_notcat2['MainCategory']=='']\n",
    "#print(f'Uncategoried 3: The total number of remaining unclassified journal titles from \\\n",
    "#after manual keyword processing of journalknownretraction_notcat2 is {len(journalknownretraction_notcat_last)}')\n",
    "\n",
    "\n",
    "third_pass = get_resolved_journaltitle_count(journalknownretraction_notcat2)\n",
    "print(f'Categoried 3: The total number of second phase classified journal titles is {third_pass[0]}')\n",
    "print(f'The total number of classified journal titles from first, second & third phases is {first_pass[0]+second_pass[0]+third_pass[0]}')\n",
    "print(f'Uncategoried 3: The total number of remaining unclassified journal titles is {third_pass[1]}')\n",
    "\n",
    "# journalknownretraction_notcat_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding Numbers of DOIs matched with Manually curated list approach\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df_thirdpass = pd.merge(journalknownretraction_clean2,journalknownretraction_cat3.iloc[:,1:4], on='JournalandConferenceProceedings_lowercase', how='inner')\n",
    "\n",
    "no_doi_thirdpass=\\\n",
    "    len(pd.merge(knownretractionlist[['DOI','JournalandConferenceProceedings_lowercase']],df_thirdpass[['JournalandConferenceProceedings_lowercase','MainCategory']],\n",
    "                             on= 'JournalandConferenceProceedings_lowercase', how='inner'))\n",
    "\n",
    "print('The total number of DOIs matched with Manually curated list Approach is:' , no_doi_thirdpass)\n",
    "print(f'Which is {round(no_doi_thirdpass/len(knownretractionlist)*100,2)}% of the {len(knownretractionlist)} DOIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Joining all the journal titles that were classified: journalknownretraction_cat,journalknownretraction_cat2,\n",
    "journalknownretraction_cat3 and the remaining unclassified one: journalknownretraction_notcat_last\n",
    "\n",
    "Output: journal_cat\n",
    "\n",
    "\"\"\"\n",
    "journalcategories = [journalknownretraction_cat,journalknownretraction_cat2,\n",
    "                     journalknownretraction_cat3, journalknownretraction_notcat_last]\n",
    "\n",
    "\n",
    "journal_cat = pd.concat([journalknownretraction_cat,journalknownretraction_cat2])\n",
    "for df in journalcategories[2:]:\n",
    "    journal_cat = pd.concat([journal_cat,df])\n",
    "\n",
    "\n",
    "journal_cat.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "journal_cat = journal_cat.drop(columns=['index'], axis=1)#.rename(columns={'JournalandConferenceProceedings_x': 'JournalandConferenceProceedings'})\n",
    "\n",
    "assert len(journal_cat)== len(journalknownretraction), 'Length of journal_cat should be equal to that of journalknownretraction '\n",
    "\n",
    "\n",
    "journal_cat = journal_cat.drop(['JournalandConferenceProceedings_lowercase', 'name_clean'], axis=1)\n",
    "\n",
    "\n",
    "journal_cat\\\n",
    "            #.to_csv(box_path_1 + '2023-09-03_journalcategory_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving uncategorized journal list\n",
    "journal_cat[journal_cat['MainCategory'].isna()]\\\n",
    "    #.to_csv(box_path_1 + '2023-09-03_journalcategory_notcategorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#journal_cat['JournalandConferenceProceedings_lowercase']= journal_cat['JournalandConferenceProceedings'].str.lower().str.strip()\n",
    "\n",
    "knownretractionlist_update=\\\n",
    "pd.merge(knownretractionlist,journal_cat.iloc[:,-2:], on='JournalandConferenceProceedings_lowercase', how='left')\n",
    "\n",
    "knownretractionlist_update\\\n",
    "    #.to_csv(box_path_1 + '2023-09-03_journalcategory_knownretractionlist_updated.csv')\n",
    "knownretractionlist_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
