{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5 : Journal Field Information\n",
    "- Part 1: Import Scopus Journal List to get upper-level field category for journals\n",
    "- Part 2: Identify Journal from the Known Retraction List that are not listed in the Scopus' Journal List\n",
    "- Part 3: Use YAKE to find keyword in each field and match with the journals\n",
    "- Part 4: Manually generate keywords and match with the rest of the journals\n",
    "- Part 5: Append the result of each step to the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yake\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime as dt\n",
    "today = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path --- Link to the box folder with your name\n",
    "# Download Box Desktop to copy the pathname\n",
    "\n",
    "# Folder name: step1.5-inputfile\n",
    "box_path_1 = {enterdirectorytofolder}\n",
    "# Folder name: step1-inputfile\n",
    "box_path_2 = {enterdirectorytofolder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Import Scopus Journal List to get upper-level field category for journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Scopus Journal List\n",
    "journalscopus = pd.read_csv(box_path_1 + 'journalcategoryscopus.csv')\n",
    "journalscopus['JournalandConferenceProceedings_lowercase'] = journalscopus['JournalandConferenceProceedings'].str.lower()\n",
    "journalscopus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Identify Journal from the Known Retraction List that are not listed in the Scopus' Journal List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the list of our journals from the Known Retraction List\n",
    "journalknownretraction = pd.read_csv(box_path_1 + 'knownretractionlist-journalcategories.csv')\n",
    "journalknownretraction['JournalandConferenceProceedings_lowercase'] = journalknownretraction['JournalandConferenceProceedings'].str.lower()\n",
    "journalknownretraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Journals from the known retraction list that are categorized\n",
    "journalknownretraction_cat = journalknownretraction.merge(journalscopus, left_on= 'JournalandConferenceProceedings_lowercase', right_on= 'JournalandConferenceProceedings_lowercase', how='left')\n",
    "\n",
    "journalknownretraction_cat = journalknownretraction[~journalknownretraction['MainCategory'].isnull()]\n",
    "print(journalknownretraction_cat.info())\n",
    "\n",
    "# Identify Journals from the known retraction list that are not categorized to any field\n",
    "journalknownretraction_notcat = journalknownretraction[journalknownretraction['MainCategory'].isnull()]\n",
    "print(journalknownretraction_notcat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of Journal that are not categorized: ', int(journalknownretraction_notcat.JournalandConferenceProceedings.count()))\n",
    "print('Percentage of Journals that are not categoriezed: ', round(int(journalknownretraction_notcat.JournalandConferenceProceedings.count())/int(journalknownretraction.JournalandConferenceProceedings.count())*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Use YAKE to find keyword in each field and match with the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of journal name str from journals that are categorized\n",
    "lifescience_list = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Life Science')]['JournalandConferenceProceedings_lowercase']\n",
    "lifescience_str = \" \".join(lifescience_list)\n",
    "\n",
    "healthscience_list = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Health Science')]['JournalandConferenceProceedings_lowercase']\n",
    "healthscience_str = \" \".join(healthscience_list)\n",
    "\n",
    "physicalscience_list = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Physical Science')]['JournalandConferenceProceedings_lowercase']\n",
    "physicalscience_str = \" \".join(physicalscience_list)\n",
    "\n",
    "socialscience_list = journalknownretraction_cat[journalknownretraction_cat['MainCategory'].str.contains('Social Science')]['JournalandConferenceProceedings_lowercase']\n",
    "socialscience_str = \" \".join(socialscience_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat list of stopwords\n",
    "new_stopwords = ['science', 'journal', 'conference', 'bulletin', 'proceeding', \n",
    "                 'research', 'experimental', 'reports','current', 'international',\n",
    "                 'reviews', 'archives', 'review','communication', 'opinion', 'american',\n",
    "                 'indian','european', 'serials','letters', 'korean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace stopwords\n",
    "for i in new_stopwords:\n",
    "    lifescience_str = lifescience_str.replace(i, '')\n",
    "    healthscience_str = healthscience_str.replace(i, '')\n",
    "    physicalscience_str = physicalscience_str.replace(i, '')\n",
    "    socialscience_str = socialscience_str.replace(i, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 100 keywords in each field\n",
    "text_list = [lifescience_str, healthscience_str, physicalscience_str, socialscience_str]\n",
    "keyword = []\n",
    "\n",
    "for i in text_list:\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    text = i\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 1\n",
    "    deduplication_threshold = 0.9\n",
    "    numOfKeywords = 100\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    for kw in keywords:\n",
    "        keyword.append(kw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to display the keywords of each field\n",
    "cat = ['Life Science', 'Health Science', 'Physical Science', 'Social Science']\n",
    "cat_key_df = pd.DataFrame()\n",
    "\n",
    "cat_key_df['Categories'] = cat\n",
    "cat_key_df['Keyword'] = [keyword[0:100], keyword[100:200], keyword[200:300], keyword[300:400]]\n",
    "\n",
    "cat_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorized the journals that are not categorized based on field keywords\n",
    "for i in range(0, len(journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'])):\n",
    "    if any([x in journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'][i] for x in cat_key_df['Keyword'][0]]):\n",
    "        journalknownretraction_notcat['MainCategory'][i] = cat_key_df['Categories'][0]\n",
    "    elif any([x in journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'][i] for x in cat_key_df['Keyword'][1]]):\n",
    "        journalknownretraction_notcat['MainCategory'][i] = cat_key_df['Categories'][1]\n",
    "    elif any([x in journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'][i] for x in cat_key_df['Keyword'][2]]):\n",
    "        journalknownretraction_notcat['MainCategory'][i] = cat_key_df['Categories'][2]\n",
    "    elif any([x in journalknownretraction_notcat['JournalandConferenceProceedings_lowercase'][i] for x in cat_key_df['Keyword'][3]]):\n",
    "        journalknownretraction_notcat['MainCategory'][i] = cat_key_df['Categories'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Manually generate keywords and match with the rest of the journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify journals that still are not categorized\n",
    "notfound = journalknownretraction_notcat[journalknownretraction_notcat['MainCategory'].isnull()].reset_index().drop(['index'],axis=1)\n",
    "notfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean encoding error symbol\n",
    "nameclean = []\n",
    "\n",
    "for i in notfound['JournalandConferenceProceedings_lowercase']:\n",
    "    #notfound['name_clean']=[]\n",
    "    stripped = i.split('(', 1)[0]\n",
    "    nameclean.append(stripped)\n",
    "\n",
    "notfound['name_clean'] = nameclean\n",
    "\n",
    "notfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select lists of keywords for each field\n",
    "\n",
    "conf = ['conference', 'workshop', 'summit', 'congress', 'symposium']\n",
    "\n",
    "phy_term = ['actuators','aeroacoustics','aerodynamic','aerospace','antenna','astronautical','astronomical',\n",
    "            'automation','rhumatisme','atmosphere','equations','software','electronics','microelectronics',\n",
    "            'bioengineering','broadband','chemie','circuits','cloud','computer','computing','crystal','cyber',\n",
    "            'energy','engineering','ergonomics','geoscience','internet','iron','materials','mathematics',\n",
    "            'micron','microsystems','mobile','nanotechnology','robotics','satellite','security','sensors','signal',\n",
    "            'steel','telecommunications','toxicological','waste','wireless','airfield','highway','navigation',\n",
    "            'cryptography','geometry','topology','bifurcation','chaos','algebra','algebraic','atmospheres',\n",
    "            'geographic','physica','superconductivity','plastic','geographer', 'differentiable', 'rhumatisme',\n",
    "            'symbolic', 'logic', 'solar']\n",
    "\n",
    "life_phy_term = ['bioinformatics','entomology','nematology','nicotine','tobacco','protein','crispr','poultry'\n",
    "                 'parasites', 'mosquito', 'dendrology', 'dna', 'forestry', 'plant','bioengineering',\n",
    "                 'acids','anatomical','anatomy','bacteriology','cytology','embo','entomologica','febs','genomic',\n",
    "                 'histology','lipids','metallurgy','microbial','microrna','microscopy','nucleosides','nucleotides'] \n",
    "\n",
    "heal_phy_term = ['aging','AIDS','anesthesia','anesthesiology','arthroplasty','bioengineering','biomedical','reumatologia',\n",
    "                 'blood','bone','bronchology ','chiropractic','dementia','dentistry','diabetology','digestive','wrestling',\n",
    "                 'disease','diseases','dna','e-Health','elder','encephalopathy','epilepsy','eye','food','foot',\n",
    "                 'geriatrics','gerontology','healthcare','illness','maxiollofacial','medical','medicine','metabolic',\n",
    "                 'morbidity','mosquito','muscle','neurology','nicotine','nurse','obesity','ophthalmic','ophthalmology',\n",
    "                 'opthamology','orofacial','orthopaedic','osteoporosis','otorhinolaryngology','parasites','patient',\n",
    "                 'psychonomic','pulmonology','respiration','rheumatology','roentgenology','shoulder','spine','surgeon',\n",
    "                 'surgery','surgical','tobacco','trauma','dermatologie','psychiatrique','cardiac','cardiological',\n",
    "                 'urologe','ophthalmologe','traitement','gait','posture','gerontologist','head','neck','std','aids',\n",
    "                 'thrombosis','hemostasis','arthritis','dental','prosthodontics','strength','conditioning','pharmacists',\n",
    "                 'pharmacist','lancet','leukemia','lymphoma','liver','sclerosis','opthalmology','pharmazie','counseling',\n",
    "                 'urologie','retina','seizure','breathing','anatomical','anatomy','thyroid','urolgia','prostate', \n",
    "                 'craniofacial', 'cleft', 'laryngoscope', 'oncologist', 'obstetrician', 'gynaecologist', 'oncologist', \n",
    "                 'urologia', 'kardiologe']\n",
    "\n",
    "soc_phy_term = ['age', 'business', 'education', 'e-government', 'politics', 'law', 'legal','e-learning', \n",
    "                'humanities','anthropology', 'linguistic','naturalist','librarianship', 'reorganisation',\n",
    "                'information', 'learning', 'architecture', 'museum', 'aging', 'culture', 'economy', 'elder', \n",
    "                'geography', 'media', 'librarian','christian','church','coaching','crime','egalitarian',\n",
    "                'entrepreneurship','interpreter','islam','judge','muslim','philosophical','philosophy','police',\n",
    "                'punishment','reoganisation','school','supervision','taxation','taxes','urban','wrestling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first run\n",
    "string = notfound['name_clean'].tolist()\n",
    "cate2 = []\n",
    "\n",
    "for i in range(0,len(string)):\n",
    "    cate = []\n",
    "    if any(item in string[i] for item in conf):\n",
    "            cate.append('Physical Science')\n",
    "            if any(item in string[i] for item in heal_phy_term):\n",
    "                cate.append('Health Science')\n",
    "            if any(item in string[i] for item in soc_phy_term):\n",
    "                cate.append('Social Science')\n",
    "            if any(item in string[i] for item in life_phy_term):\n",
    "                cate.append('Life Science')\n",
    "        \n",
    "    cate2.append(cate)\n",
    "\n",
    "        \n",
    "notfound['MainCategory'] = cate2\n",
    "\n",
    "notfound['MainCategory'] = [', '.join(map(str, l)) for l in notfound['MainCategory']]\n",
    "notfound['MainCategory'] = notfound['MainCategory'].astype(str).replace('nan', '')\n",
    "notfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second run\n",
    "stillnotfound = notfound[notfound['MainCategory']=='']\n",
    "\n",
    "string = stillnotfound['name_clean'].tolist()\n",
    "cate3 = []\n",
    "\n",
    "for i in range(0,len(string)):\n",
    "        cate = []\n",
    "            \n",
    "        if any(item in string[i] for item in phy_term):\n",
    "                cate.append('Physical Science')\n",
    "        if any(item in string[i] for item in heal_phy_term):\n",
    "                cate.append('Health Science')\n",
    "        if any(item in string[i] for item in soc_phy_term):\n",
    "                cate.append('Social Science')\n",
    "        if any(item in string[i] for item in life_phy_term):\n",
    "                cate.append('Life Science')\n",
    "\n",
    "        cate3.append(cate)\n",
    "\n",
    "        \n",
    "stillnotfound['MainCategory'] = cate3\n",
    "stillnotfound['MainCategory'] = [', '.join(map(str, l)) for l in stillnotfound['MainCategory']]\n",
    "stillnotfound['MainCategory']= stillnotfound['MainCategory'].astype(str).replace('nan', '')\n",
    "\n",
    "stillnotfound = stillnotfound.drop(['name_clean'], axis=1)\n",
    "stillnotfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the end result of this part\n",
    "founded = pd.merge(notfound, stillnotfound, on='JournalandConferenceProceedings_lowercase', how='left').drop(['name_clean'], axis =1)\n",
    "founded['MainCategory_x'] = founded['MainCategory_x'].astype(str).replace('nan', '')\n",
    "founded['MainCategory_y'] = founded['MainCategory_y'].astype(str).replace('nan', '')\n",
    "\n",
    "founded = founded.drop(columns=['JournalandConferenceProceedings_lowercase','JournalandConferenceProceedings_y'], axis=1).rename(columns={'JournalandConferenceProceedings_x': 'JournalandConferenceProceedings'}) \n",
    "founded['MainCategory'] = founded[founded.columns[1:]].apply(lambda x: ''.join(x.dropna().astype(str)),axis=1)\n",
    "founded = founded[['JournalandConferenceProceedings', 'MainCategory']]\n",
    "founded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Append the result of each step to the original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = pd.merge(journalknownretraction_notcat, founded, on='JournalandConferenceProceedings', how='left')\n",
    "result_1['MainCategory_x'] = result_1['MainCategory_x'].astype(str).replace('nan', '')\n",
    "result_1['MainCategory_y'] = result_1['MainCategory_y'].astype(str).replace('nan', '')\n",
    "\n",
    "result_1['MainCategory'] = result_1[result_1.columns[1:]].apply(lambda x: ''.join(x.dropna().astype(str)),axis=1)\n",
    "result_1 = result_1[['JournalandConferenceProceedings', 'MainCategory']]\n",
    "\n",
    "print(result_1.info())\n",
    "print(result_1.MainCategory.value_counts())\n",
    "result_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_2 = pd.concat([journalknownretraction_cat,result_1]).reset_index().drop(['index'], axis=1)\n",
    "result_2 = result_2[['JournalandConferenceProceedings', 'MainCategory']]\n",
    "\n",
    "print(result_2.info())\n",
    "result_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2.to_csv(today + '-journalcategory-knownretractionlist.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
