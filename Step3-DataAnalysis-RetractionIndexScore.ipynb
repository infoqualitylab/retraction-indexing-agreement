{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform Data Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install dataframe-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set path --- Link to the box folder with your name\n",
    "# Download Box Desktop to copy the pathname\n",
    "\n",
    "# Input\n",
    "# Folder name: step1-inputfile\n",
    "box_path = '/Users/lirou/Library/CloudStorage/Box-Box/RetractionWatch2023-03-28/testing/Laura/step1-inputfile/'\n",
    "# Folder name: step1-outputfile\n",
    "box_path_1 = '/Users/lirou/Library/CloudStorage/Box-Box/RetractionWatch2023-03-28/testing/Laura/step1-outputfile/'\n",
    "# Folder name: step2-outputfile\n",
    "box_path_2 = '/Users/lirou/Library/CloudStorage/Box-Box/RetractionWatch2023-03-28/testing/Laura/step2-outputfile/'\n",
    "# Folder name: step3-inputfile\n",
    "box_path_3 = '/Users/lirou/Library/CloudStorage/Box-Box/RetractionWatch2023-03-28/testing/Laura/step2-outputfile/'\n",
    "\n",
    "\n",
    "# Output\n",
    "# Folder name: step3-outputfile\n",
    "box_path_4 = '/Users/lirou/Library/CloudStorage/Box-Box/RetractionWatch2023-03-28/testing/Laura/step3-outputfile/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate files and generate a new list for data analysis \n",
    "We import the output files from the previous notebook and combine them with the Known Retraction List. When records are discovered to be present in (“covered by”) a source, the source is added to the records, and a new list is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Files:  \n",
    "# One CSV file of the known retraction list  \n",
    "# Three CSV files (one for each source) \n",
    "# of the items from the known retraction list \n",
    "# that are covered by a given source but not indexed as retracted in that source \n",
    "\n",
    "\n",
    "# Known Retraction List\n",
    "knownretraction = pd.read_csv(box_path_1 + '2023-04-12-knownretractionlist-1.csv').drop(['Unnamed: 0'], axis=1).sort_values('Year', ascending=False).reset_index(drop=True)\n",
    "knownretraction\n",
    "\n",
    "print(knownretraction.shape)\n",
    "print(knownretraction.info())\n",
    "print(knownretraction.head())\n",
    "\n",
    "# Scopus\n",
    "scopus = pd.read_csv(box_path_2 + '2023-04-09-notindexedasretracted-scopus.csv').drop(['Unnamed: 0'], axis=1).sort_values('Year', ascending=False).reset_index(drop=True).rename(columns={'Database': 'source'})\n",
    "scopus['source'] = 'Scopus'\n",
    "\n",
    "print(scopus.shape)\n",
    "print(scopus.info())\n",
    "print(scopus.head())\n",
    "\n",
    "\n",
    "# Web of Science\n",
    "wos = pd.read_csv(box_path_2 + '2023-04-08-notindexedasretracted-webofscience.csv').drop(['Unnamed: 0'], axis=1).sort_values('Year', ascending=False).reset_index(drop=True).rename(columns={'Database': 'source'})\n",
    "wos['source'] = 'Web of Science'\n",
    "\n",
    "print(wos.shape)\n",
    "print(wos.info())\n",
    "print(wos.head())\n",
    "\n",
    "\n",
    "# Crossref\n",
    "crossref = pd.read_csv(box_path_2 + '2023-04-09-notindexedasretracted-crossref.csv').drop(['Unnamed: 0'], axis=1).sort_values('Year', ascending=False).reset_index(drop=True).rename(columns={'Database': 'source'})\n",
    "crossref['source'] = 'Crossref'\n",
    "\n",
    "print(crossref.shape)\n",
    "print(crossref.info())\n",
    "print(crossref.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concat the input files into one dataframe\n",
    "\n",
    "merged_withdoi = pd.concat([knownretraction, scopus, wos, crossref])\n",
    "\n",
    "knownretraction_2 = merged_withdoi.groupby('DOI').agg({'Author':'first', \n",
    "                              'Title': 'first',\n",
    "                              'Year': 'first', \n",
    "                              'Journal': 'first',                    \n",
    "                              'source':'; '.join, \n",
    "                              'PubMedID':'first'}).reset_index()\n",
    "\n",
    "knownretraction_2.fillna('', inplace=True)\n",
    "\n",
    "knownretraction_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean dataframe-- removing duplicate values in 'source' column\n",
    "\n",
    "dedup_source = []\n",
    "\n",
    "for i in knownretraction_2['source']:\n",
    "    sourceinlist = i.split(\"; \")\n",
    "    unique_list = pd.Series(sourceinlist).drop_duplicates().tolist()\n",
    "    dedup_source.append(sorted(unique_list))\n",
    "\n",
    "knownretraction_2['source_new'] = dedup_source\n",
    "knownretraction_2 = knownretraction_2.drop(['source'], axis=1)\n",
    "\n",
    "# Print the new Known Retraction List\n",
    "knownretraction_3 = pd.merge(knownretraction_2, knownretraction[['DOI','source']].rename(columns={'source':'source_old'}), on='DOI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store value in source_old in list format\n",
    "\n",
    "source_old = []\n",
    "\n",
    "for i in knownretraction_3['source_old']:\n",
    "    sourceinlist = i.split(\"; \")\n",
    "    source_old.append(sourceinlist)\n",
    "    \n",
    "knownretraction_3['source_old'] = source_old\n",
    "knownretraction_3 = knownretraction_3.sort_values(by='source_old')\n",
    "\n",
    "knownretraction_3\n",
    "\n",
    "#changesourcenew/old "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output File for Step 3.5\n",
    "knownretraction_3.to_csv(box_path_4 + today + '-knownretractionlist-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Step3.5 then return to below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add retraction year to known retraction list\n",
    "# Import files\n",
    "\n",
    "cr_retractionyear = pd.read_table(box_path_3 + '-retractionyear-crossref.csv').rename(columns={'retraction-date':'RetractionYear'})\n",
    "\n",
    "retractionwatch_retracted = pd.read_csv(box_path_1 + '2023-04-09-recordswithdoi-retractionwatch.csv')\n",
    "retractionwatch_retracted[\"RetractionYear\"] = pd.to_datetime(retractionwatch_retracted[\"RetractionDate\"]).dt.strftime(\"%Y\").fillna(0).astype(int)\n",
    "rw_retractionyear = retractionwatch_retracted[['DOI', 'RetractionYear']]\n",
    "\n",
    "print(journalcategory.info())\n",
    "print(cr_retractionyear.info())\n",
    "print(rw_retractionyear.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add retraction year to known retraction list\n",
    "# Merge dataframes\n",
    "\n",
    "retractionyear_merged = pd.merge(cr_retractionyear,rw_retractionyear, on='DOI', how='outer')\n",
    "retractionyear_merged['RetractionYear_x'] = retractionyear_merged['RetractionYear_x'].fillna(0).astype(int)\n",
    "retractionyear_merged['RetractionYear_y'] = retractionyear_merged['RetractionYear_y'].fillna(0).astype(int)\n",
    "retractionyear_merged['RetractionYear'] = retractionyear_merged['RetractionYear_x'] + retractionyear_merged['RetractionYear_y']\n",
    "retractionyear_merged['RetractionYear'] = retractionyear_merged['RetractionYear'].fillna(0).astype(int)\n",
    "\n",
    "retractionyear_merged = retractionyear_merged[['DOI', 'RetractionYear']]\n",
    "retractionyear_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add retraction year to known retraction list\n",
    "knownretraction_4 = knownretraction_3.merge(retractionyear_merged, on = 'DOI', how='left')\n",
    "knownretraction_4['RetractionYear'] = knownretraction_4['RetractionYear'].fillna(0).astype(int)\n",
    "\n",
    "knownretraction_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create New column: TimetoRetraction\n",
    "retractionyearfiltered = knownretraction_4[knownretraction_4['RetractionYear'] > 0]\n",
    "retractionyearfiltered['TimetoRetraction'] = retractionyearfiltered['RetractionYear'] - retractionyearfiltered['Year']\n",
    "\n",
    "retractionyearfiltered = retractionyearfiltered[['DOI', 'TimetoRetraction']]\n",
    "retractionyearfiltered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownretraction_4 = pd.merge(knownretraction_4,retractionyearfiltered, on='DOI', how='left')\n",
    "knownretraction_4['TimetoRetraction'] = knownretraction_4['TimetoRetraction'].fillna(0).astype(int)\n",
    "\n",
    "# Create DOI link\n",
    "knownretraction_4['DOILink'] = ['http://doi.org/']+ knownretraction_4['DOI']\n",
    "\n",
    "knownretraction_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix minor errors in dataframe\n",
    "knownretraction_4['Journal_lower'] = knownretraction_4['Journal'].str.lower()\n",
    "knownretraction_4 = knownretraction_4.merge(journalcategory, left_on= 'Journal_lower', right_on= 'JournalandConferenceProceedings', how='left')\n",
    "\n",
    "knownretraction_4 = knownretraction_4.drop(columns=['Unnamed: 0', 'JournalandConferenceProceedings', 'Journal_lower'], axis=1)\n",
    "knownretraction_4['MainCategory'] = knownretraction_4['MainCategory'].fillna('notcategorized').str.replace('Sciences', 'Science')\n",
    "\n",
    "print(knownretraction_4.info())\n",
    "knownretraction_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output File\n",
    "# One CSV file with new source added to items  \n",
    "\n",
    "knownretraction_4.to_csv(box_path_4 + today + '-knownretractionlist-3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate the index score for each item and source\n",
    "\n",
    "Then, we introduce our calculations for retraction indexing and use visualizations to enhance the analysis outcome. The part is divided into two sections: retraction index scores by publication and retraction index scores by source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Calculation by item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up the formula for the calculation\n",
    "count_sources_covering_item = knownretraction_4.source_new.str.len()\n",
    "count_sources_indexing_item_as_retracted = knownretraction_4.source_old.str.len()\n",
    "RetractionIndexingDiscrepancy_ITEM = count_sources_indexing_item_as_retracted / count_sources_covering_item\n",
    "\n",
    "# add and show the calculation score to dataframe\n",
    "knownretraction_4['RetractionIndexingAgreement_ITEM(%)'] = ((RetractionIndexingDiscrepancy_ITEM)*100).astype(int)\n",
    "knownretraction_4 = knownretraction_4.sort_index()\n",
    "knownretraction_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result to folder\n",
    "\n",
    "v, c = np.unique(knownretraction_4['RetractionIndexingAgreement_ITEM(%)'], return_counts=True)\n",
    "s = v.tolist()\n",
    "\n",
    "for i in s:\n",
    "    exp = knownretraction_4[knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== i]\n",
    "    exp.to_csv(box_path_4 + 'RetractionIndexingAgreement_ITEM/' + today + '-RetractionIndexingAgreement_ITEM-' + str(i) + '.csv' )\n",
    "\n",
    "knownretraction_4.to_csv(box_path_4 + 'RetractionIndexingAgreement_ITEM/' + today + '-RetractionIndexingAgreement_ITEM-all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Calculation by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the count of items that appear in a source\n",
    "cr_rtr = len(knownretraction[knownretraction['source'].str.contains('Crossref', na=False)])\n",
    "rw_rtr = len(knownretraction[knownretraction['source'].str.contains('Retraction Watch', na=False)])\n",
    "sp_rtr = len(knownretraction[knownretraction['source'].str.contains('Scopus', na=False)])\n",
    "wos_rtr = len(knownretraction[knownretraction['source'].str.contains('Web of Science', na=False)])\n",
    "\n",
    "# get the count of items that does not appear in a source\n",
    "cr_ntc = len(knownretraction[~knownretraction['source'].str.contains('Crossref', na=False)])\n",
    "rw_ntc = len(knownretraction[~knownretraction['source'].str.contains('Retraction Watch', na=False)])\n",
    "sp_ntc = len(knownretraction[~knownretraction['source'].str.contains('Scopus', na=False)])\n",
    "wos_ntc = len(knownretraction[~knownretraction['source'].str.contains('Web of Science', na=False)])\n",
    "\n",
    "# get the count of items in known retraction list\n",
    "total_count = len(knownretraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a table showing the count showing \n",
    "# the ratio of the three indexing statuses:\n",
    "# indexed_as_retracted, covered_but_not_indexed_as_retracted, not_covered\n",
    "# and the calculation score by source\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table['source'] = ['Scopus', 'Web of Science', 'Retraction Watch', 'Crossref']\n",
    "table['indexed_as_retracted'] = [sp_rtr, wos_rtr, rw_rtr, cr_rtr]\n",
    "table['covered_but_not_indexed_as_retracted'] = [len(scopus), len(wos), 0, len(crossref)]\n",
    "table['not_covered'] = [sp_ntc-len(scopus), wos_ntc-len(wos), rw_ntc, cr_ntc-len(crossref)]\n",
    "\n",
    "cal=[]\n",
    "\n",
    "for i in range(0,4):\n",
    "    D = table['indexed_as_retracted'][i] + table['covered_but_not_indexed_as_retracted'][i]   \n",
    "    cal.append(round(((table['indexed_as_retracted'][i]/D)*100), 2))\n",
    "    \n",
    "table['RetractionIndexingAgreement_SOURCE(%)'] = [cal[0], cal[1], cal[2], cal[3]]\n",
    "\n",
    "#set first column as index\n",
    "table = table.sort_values(by='source') #.set_index(table.columns[0])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export table\n",
    "dfi.export(table, box_path_4 + today + 'Numberofretractionsineachsource.png', table_conversion=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat bar plot for the table\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "x = np.arange(len(table['source']))\n",
    "y1 = table['indexed_as_retracted']\n",
    "y2 = table['covered_but_not_indexed_as_retracted']\n",
    "width = 0.4\n",
    "\n",
    "\n",
    "# plot data in grouped manner of bar type\n",
    "rects1 = plt.bar(x-0.2, y1, width, color='#377eb8', hatch='/',edgecolor= 'white')\n",
    "rects2 = plt.bar(x+0.2, y2, width, color='#f781bf',hatch='o',edgecolor= 'white')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "plt.xticks(x, table['source'])    \n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Number of DOIs\")\n",
    "plt.legend([\"indexed_as_retracted\", \"covered_but_not_indexed_as_retracted\"],loc='upper left')\n",
    "plt.margins(y=0.25)\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-recordsineachsource.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pie Chart for the table\n",
    "new = table[['indexed_as_retracted', 'not_covered', 'covered_but_not_indexed_as_retracted']]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), facecolor='#FFFFFF')\n",
    "\n",
    "for i, (idx, row) in enumerate(new.iterrows()):\n",
    "    ax = axes[i//2, i % 2]\n",
    "    row = row[row.gt(row.sum() * .01)]\n",
    "    \n",
    "    patterns = [ \"/\", \"+\", \"o\"]\n",
    "\n",
    "    piechart = ax.pie(row,\n",
    "           #labels=row.values,\n",
    "           #autopct='%.2f%%',\n",
    "           pctdistance = 1.3, \n",
    "           labeldistance = 1,\n",
    "           startangle = 90 * row[0],\n",
    "           autopct=lambda x: f'{x:.2f}%\\n({(x/100)*sum(row):.0f})',\n",
    "           wedgeprops={'edgecolor': 'white'},\n",
    "           textprops={'size': 'x-large'},\n",
    "           colors=['#377eb8','#ff7f00', '#f781bf'])\n",
    "    \n",
    "    for i in range(len(piechart[0])):\n",
    "        piechart[0][i].set_hatch(patterns[(i)%len(patterns)])\n",
    "\n",
    "    #plt.setp(pcts, color='white', fontweight='bold')    \n",
    "    ax.set_title(idx, fontsize=16)\n",
    "        \n",
    "    # create and show legend \n",
    "legend = plt.legend([x for x in row.index], \n",
    "                    loc='lower left',  \n",
    "                    ncol=1) \n",
    "                    #fancybox=True)\n",
    "    \n",
    "fig.subplots_adjust(wspace=.2) # Space between charts\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(box_path_4 + today + '-percentagebysource.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Visualizations\n",
    "Last, we create visualizations to support the outcome of our analysis from the the known retraction list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaion 1 : Publication Year - Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an overview table\n",
    "\n",
    "y, yc = np.unique(knownretraction_4['Year'], return_counts=True)\n",
    "\n",
    "year_count = pd.DataFrame()\n",
    "year_count['Year'] = y\n",
    "year_count['Count'] = yc\n",
    "year_count = year_count.set_index(year_count.columns[0])\n",
    "\n",
    "year_count.sort_values(by='Count', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating the bar plot\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "plt.bar(y, yc)\n",
    " \n",
    "plt.xlabel(\"Publication Year\")\n",
    "plt.ylabel(\"No. of Items\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(box_path_4 + today + '-itembyyear.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to specific year range: 1940-1990\n",
    "# create an overview table\n",
    "\n",
    "limityear = knownretraction_3.loc[(knownretraction_3['Year'] >= 1940) & (knownretraction_3['Year'] <= 1990)]\n",
    "\n",
    "l_values, l_counts = np.unique(limityear['Year'], return_counts=True)\n",
    "\n",
    "limityear_count = pd.DataFrame()\n",
    "limityear_count['Year'] = l_values\n",
    "limityear_count['Count'] = l_counts\n",
    "limityear_count = limityear_count.set_index(limityear_count.columns[0])\n",
    "\n",
    "limityear_count.sort_values(by='Count', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Limit to specific year range: 1940-1990\n",
    "# creating the bar plot\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "plt.bar(l_values, l_counts)\n",
    " \n",
    "plt.xlabel(\"Publication Year\")\n",
    "plt.ylabel(\"No. of Items\")\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(box_path_4 + today + '-itembyyearlimited.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two plot into one plot\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.bar(values, counts)\n",
    "plt.xlabel(\"Publication Year\")\n",
    "plt.ylabel(\"No. of Items\")\n",
    "\n",
    "# First new axes\n",
    "ax1 = fig.add_axes([0.2, 0.45, 0.4, 0.4])\n",
    "ax1.bar(l_values, l_counts)\n",
    "\n",
    "plt.xlabel(\"Publication Year\")\n",
    "plt.ylabel(\"No. of Items\")\n",
    "\n",
    "\n",
    "plt.savefig(box_path_4 + today + '-itembyyear-twoinone.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Visualization 2: PublicationYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a table showing the count of items in different RetractionIndexingAgreement_ITEM(%)\n",
    "\n",
    "score = knownretraction_3['RetractionIndexingAgreement_ITEM(%)']\n",
    "s_values, s_counts = np.unique(score, return_counts=True)\n",
    "\n",
    "score_count = pd.DataFrame()\n",
    "score_count['RetractionIndexingAgreement_ITEM(%)'] = s_values\n",
    "score_count['Count'] = s_counts\n",
    "score_count = score_count.set_index(score_count.columns[0])\n",
    "\n",
    "score_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots\n",
    "itemscore = knownretraction_4[['RetractionIndexingAgreement_ITEM(%)', 'Year']]\n",
    "\n",
    "fig_2, axes_2 = plt.subplots(3, 2, figsize=(10, 10), facecolor='#FFFFFF')\n",
    "fig_2.subplots_adjust(hspace=0.5, wspace=0.25) # Space between charts\n",
    "\n",
    "specscore = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 25]\n",
    "values, counts = np.unique(specscore['Year'], return_counts=True)\n",
    "axes_2[0, 0].bar(values, counts)\n",
    "axes_2[0, 0].set_title(\"RetractionIndexingAgreement_DOI = 25%\")\n",
    "axes_2[0, 0].set_xlabel(\"Publication Year\")\n",
    "axes_2[0, 0].set_ylabel(\"No. of Items\")\n",
    "axes_2[0, 0].set_xticks([2022])\n",
    "\n",
    "specscore2 = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 33]\n",
    "values2, counts2 = np.unique(specscore2['Year'], return_counts=True)\n",
    "axes_2[0, 1].bar(values2, counts2)\n",
    "axes_2[0, 1].set_title(\"RetractionIndexingAgreement_DOI = 33%\")\n",
    "axes_2[0, 1].set_xlabel(\"Publication Year\")\n",
    "axes_2[0, 1].set_ylabel(\"No. of Items\")\n",
    "axes_2[0, 1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axes_2[0, 1].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore3 = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 50]\n",
    "values3, counts3 = np.unique(specscore3['Year'], return_counts=True)\n",
    "axes_2[1, 0].bar(values3, counts3)\n",
    "axes_2[1, 0].set_title(\"RetractionIndexingAgreement_DOI = 50%\")\n",
    "axes_2[1, 0].set_xlabel(\"Publication Year\")\n",
    "axes_2[1, 0].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore4 = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 66]\n",
    "values4, counts4 = np.unique(specscore4['Year'], return_counts=True)\n",
    "axes_2[1, 1].bar(values4, counts4)\n",
    "axes_2[1, 1].set_title(\"RetractionIndexingAgreement_DOI = 66%\")\n",
    "axes_2[1, 1].set_xlabel(\"Publication Year\")\n",
    "axes_2[1, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore5 = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 75]\n",
    "values5, counts5 = np.unique(specscore5['Year'], return_counts=True)\n",
    "axes_2[2, 0].bar(values5, counts5)\n",
    "axes_2[2, 0].set_title(\"RetractionIndexingAgreement_DOI = 75%\")\n",
    "axes_2[2, 0].set_xlabel(\"Publication Year\")\n",
    "axes_2[2, 0].set_ylabel(\"No. of Items\")\n",
    "axes_2[2, 0].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axes_2[2, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore6 = itemscore[itemscore['RetractionIndexingAgreement_ITEM(%)']== 100]\n",
    "values6, counts6 = np.unique(specscore6['Year'], return_counts=True)\n",
    "axes_2[2, 1].bar(values6, counts6)\n",
    "axes_2[2, 1].set_title(\"RetractionIndexingAgreement_DOI = 100%\")\n",
    "axes_2[2, 1].set_xlabel(\"Publication Year\")\n",
    "axes_2[2, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-pubyearbyscore.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 3: RetractionYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table showing the count of items in different RetractionIndexingAgreement_ITEM(%)\n",
    "\n",
    "withretractiondate = knownretraction_4[knownretraction_4['RetractionYear'] > 0]\n",
    "withoutretractiondate = knownretraction_4[knownretraction_4['RetractionYear'] == 0]\n",
    "\n",
    "retractionyeardata = pd.DataFrame()\n",
    "retractionyeardata['RetractionYear'] = ['withretractiondate', 'withoutretractiondate']\n",
    "retractionyeardata['Count'] = [len(withretractiondate), len(withoutretractiondate)]\n",
    "\n",
    "retractionyeardata.set_index(retractionyeardata.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutretractiondate.source_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots\n",
    "\n",
    "fig_3, axes_3 = plt.subplots(3, 2, figsize=(10, 10), facecolor='#FFFFFF')\n",
    "fig_3.subplots_adjust(hspace=0.5, wspace=0.25) # Space between charts\n",
    "\n",
    "specscore = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 25) & (knownretraction_4['RetractionYear'] > 0)]\n",
    "values, counts = np.unique(specscore['RetractionYear'], return_counts=True)\n",
    "axes_3[0, 0].bar(values, counts)\n",
    "axes_3[0, 0].set_title(\"RetractionIndexingAgreement_DOI = 25%\")\n",
    "axes_3[0, 0].set_xlabel(\"Retraction Year\")\n",
    "axes_3[0, 0].set_ylabel(\"No. of Items\")\n",
    "axes_3[0, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore2 = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 33) & (knownretraction_4['RetractionYear'] > 0)]\n",
    "values2, counts2 = np.unique(specscore2['RetractionYear'], return_counts=True)\n",
    "axes_3[0, 1].bar(values2, counts2)\n",
    "axes_3[0, 1].set_title(\"RetractionIndexingAgreement_DOI = 33%\")\n",
    "axes_3[0, 1].set_xlabel(\"Retraction Year\")\n",
    "axes_3[0, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "\n",
    "specscore3 = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 50) & (knownretraction_4['RetractionYear'] > 0)]\n",
    "values3, counts3 = np.unique(specscore3['RetractionYear'], return_counts=True)\n",
    "axes_3[1, 0].bar(values3, counts3)\n",
    "axes_3[1, 0].set_title(\"RetractionIndexingAgreement_DOI = 50%\")\n",
    "axes_3[1, 0].set_xlabel(\"Retraction Year\")\n",
    "axes_3[1, 0].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore4 = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 66) & (knownretraction_4['RetractionYear'] > 0)]\n",
    "values4, counts4 = np.unique(specscore4['RetractionYear'], return_counts=True)\n",
    "axes_3[1, 1].bar(values4, counts4)\n",
    "axes_3[1, 1].set_title(\"RetractionIndexingAgreement_DOI = 66%\")\n",
    "axes_3[1, 1].set_xlabel(\"Retraction Year\")\n",
    "axes_3[1, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore5 = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 75) & (knownretraction_4['RetractionYear'] > 0)]\n",
    "values5, counts5 = np.unique(specscore5['RetractionYear'], return_counts=True)\n",
    "axes_3[2, 0].bar(values5, counts5)\n",
    "axes_3[2, 0].set_title(\"RetractionIndexingAgreement_DOI = 75%\")\n",
    "axes_3[2, 0].set_xlabel(\"Retraction Year\")\n",
    "axes_3[2, 0].set_ylabel(\"No. of Items\")\n",
    "axes_3[2, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore6 = knownretraction_4[(knownretraction_4['RetractionIndexingAgreement_ITEM(%)']== 100 )& (knownretraction_4['RetractionYear'] > 0)]\n",
    "values6, counts6 = np.unique(specscore6['RetractionYear'], return_counts=True)\n",
    "axes_3[2, 1].bar(values6, counts6)\n",
    "axes_3[2, 1].set_title(\"RetractionIndexingAgreement_DOI = 100%\")\n",
    "axes_3[2, 1].set_xlabel(\"Retraction Year\")\n",
    "axes_3[2, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-retractionyearbyscore.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 4: TimetoRetraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetoretraction_filtered = knownretraction_4[knownretraction_4['RetractionYear']!= 0]\n",
    "timetoretraction_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plots\n",
    "\n",
    "fig_4, axes_4 = plt.subplots(3, 2, figsize=(10, 10), facecolor='#FFFFFF')\n",
    "fig_4.subplots_adjust(hspace=0.5, wspace=0.25) # Space between charts\n",
    "\n",
    "specscore = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 25]\n",
    "values, counts = np.unique(specscore['TimetoRetraction'], return_counts=True)\n",
    "axes_4[0, 0].bar(values, counts)\n",
    "axes_4[0, 0].set_title(\"RetractionIndexingAgreement_DOI = 25%\")\n",
    "axes_4[0, 0].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[0, 0].set_ylabel(\"No. of Items\")\n",
    "axes_4[0, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore2 = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 33]\n",
    "values2, counts2 = np.unique(specscore2['TimetoRetraction'], return_counts=True)\n",
    "axes_4[0, 1].bar(values2, counts2)\n",
    "axes_4[0, 1].set_title(\"RetractionIndexingAgreement_DOI = 33%\")\n",
    "axes_4[0, 1].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[0, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore3 = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 50]\n",
    "values3, counts3 = np.unique(specscore3['TimetoRetraction'], return_counts=True)\n",
    "axes_4[1, 0].bar(values3, counts3)\n",
    "axes_4[1, 0].set_title(\"RetractionIndexingAgreement_DOI = 50%\")\n",
    "axes_4[1, 0].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[1, 0].set_ylabel(\"No. of Items\")\n",
    "axes_4[1, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore4 = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 66]\n",
    "values4, counts4 = np.unique(specscore4['TimetoRetraction'], return_counts=True)\n",
    "axes_4[1, 1].bar(values4, counts4)\n",
    "axes_4[1, 1].set_title(\"RetractionIndexingAgreement_DOI = 66%\")\n",
    "axes_4[1, 1].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[1, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore5 = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 75]\n",
    "values5, counts5 = np.unique(specscore5['TimetoRetraction'], return_counts=True)\n",
    "axes_4[2, 0].bar(values5, counts5)\n",
    "axes_4[2, 0].set_title(\"RetractionIndexingAgreement_DOI = 75%\")\n",
    "axes_4[2, 0].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[2, 0].set_ylabel(\"No. of Items\")\n",
    "axes_4[2, 0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "specscore6 = timetoretraction_filtered[timetoretraction_filtered['RetractionIndexingAgreement_ITEM(%)']== 100]\n",
    "values6, counts6 = np.unique(specscore6['TimetoRetraction'], return_counts=True)\n",
    "axes_4[2, 1].bar(values6, counts6)\n",
    "axes_4[2, 1].set_title(\"RetractionIndexingAgreement_DOI = 100%\")\n",
    "axes_4[2, 1].set_xlabel(\"Time to Retraction\")\n",
    "axes_4[2, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-timetoretraction.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 5: Field of Study - Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_2 = cat + ['notcategorized']\n",
    "print(cat)\n",
    "print(cat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "cat_3 = ['General', 'Health \\nScience', 'Life \\nScience', 'Physical \\nScience', 'Social \\nScience', 'Not \\nCategorized']\n",
    "\n",
    "count=[]\n",
    "for i in cat_2:\n",
    "    counts = knownretraction_4.MainCategory.str.count(i).sum()\n",
    "    count.append(counts)\n",
    "\n",
    "df = pd.DataFrame({'Fields of Study': cat_3, 'Count': count}).sort_values('Count', ascending=False)#.set_index(df.columns[0])\n",
    "\n",
    "#ax.bar('Fields of Study', 'Count', data=df)\n",
    "x = np.arange(len(df['Fields of Study'])) \n",
    "\n",
    "ax.set_xlabel(\"Fields of Study\")\n",
    "ax.set_ylabel(\"Number of DOIs\")\n",
    "ax.set_xticklabels([0, 'Life \\nScience',\n",
    " 'Physical \\nScience',\n",
    " 'Health \\nScience',\n",
    " 'Not \\nCategorized',\n",
    " 'Social \\nScience',\n",
    " 'General'])\n",
    "\n",
    "pps = ax.bar(x/2, df['Count'], width, label='No. of Items')\n",
    "for p in pps:\n",
    "    height = p.get_height()\n",
    "    ax.text(x=p.get_x() + p.get_width() / 2, y=height+0.1,\n",
    "            s=\"{}\".format(height),\n",
    "            ha='center')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-fieldofstudytotal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 6: Field of Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knownretraction_5 = knownretraction_4[knownretraction_4['MainCategory'] != 'notcategorized']\n",
    "knownretraction_5['MainCategory'] = knownretraction_5['MainCategory'].str.replace('Sciences', 'Science')\n",
    "knownretraction_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['General', 'Health Science', 'Life Science', 'Physical Science', 'Social Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_5, axes_5 = plt.subplots(3, 2, figsize=(10, 10), facecolor='#FFFFFF')\n",
    "fig_5.subplots_adjust(hspace=0.5, wspace=0.3) # Space between charts\n",
    "\n",
    "cat_1 = ['General', 'Health \\nScience', 'Life \\nScience', 'Physical \\nScience', 'Social \\nScience']\n",
    "\n",
    "specscore = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 25]\n",
    "category=[]\n",
    "num=[]\n",
    "for i in cat:\n",
    "    count = specscore.MainCategory.str.count(i).sum()\n",
    "    category.append(i)\n",
    "    num.append(count)\n",
    "axes_5[0, 0].bar(cat_1, num)\n",
    "axes_5[0, 0].set_title(\"RetractionIndexingAgreement_DOI = 25%\")\n",
    "axes_5[0, 0].set_xlabel(\"Field of Study\")\n",
    "axes_5[0, 0].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore2 = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 33]\n",
    "category2=[]\n",
    "num2=[]\n",
    "for i in cat:\n",
    "    count = specscore2.MainCategory.str.count(i).sum()\n",
    "    category2.append(i)\n",
    "    num2.append(count)\n",
    "axes_5[0, 1].bar(cat_1, num2)\n",
    "axes_5[0, 1].set_title(\"RetractionIndexingAgreement_DOI = 33%\")\n",
    "axes_5[0, 1].set_xlabel(\"Field of Study\")\n",
    "axes_5[0, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore3 = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 50]\n",
    "category3=[]\n",
    "num3=[]\n",
    "for i in cat:\n",
    "    count = specscore3.MainCategory.str.count(i).sum()\n",
    "    category3.append(i)\n",
    "    num3.append(count)\n",
    "axes_5[1, 0].bar(cat_1, num3)\n",
    "axes_5[1, 0].set_title(\"RetractionIndexingAgreement_DOI = 50%\")\n",
    "axes_5[1, 0].set_xlabel(\"Field of Study\")\n",
    "axes_5[1, 0].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore4 = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 66]\n",
    "category4=[]\n",
    "num4=[]\n",
    "for i in cat:\n",
    "    count = specscore4.MainCategory.str.count(i).sum()\n",
    "    category4.append(i)\n",
    "    num4.append(count)\n",
    "axes_5[1, 1].bar(cat_1, num4)\n",
    "axes_5[1, 1].set_title(\"RetractionIndexingAgreement_DOI = 66%\")\n",
    "axes_5[1, 1].set_xlabel(\"Field of Study\")\n",
    "axes_5[1, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore5 = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 75]\n",
    "category5=[]\n",
    "num5=[]\n",
    "for i in cat:\n",
    "    count = specscore5.MainCategory.str.count(i).sum()\n",
    "    category5.append(i)\n",
    "    num5.append(count)\n",
    "axes_5[2, 0].bar(cat_1, num5)\n",
    "axes_5[2, 0].set_title(\"RetractionIndexingAgreement_DOI = 75%\")\n",
    "axes_5[2, 0].set_xlabel(\"Field of Study\")\n",
    "axes_5[2, 0].set_ylabel(\"No. of Items\")\n",
    "\n",
    "specscore6 = knownretraction_5[knownretraction_5['RetractionIndexingAgreement_ITEM(%)']== 100]\n",
    "category6=[]\n",
    "num6=[]\n",
    "for i in cat:\n",
    "    count = specscore6.MainCategory.str.count(i).sum()\n",
    "    category6.append(i)\n",
    "    num6.append(count)\n",
    "axes_5[2, 1].bar(cat_1, num6)\n",
    "axes_5[2, 1].set_title(\"RetractionIndexingAgreement_DOI = 100%\")\n",
    "axes_5[2, 1].set_xlabel(\"Field of Study\")\n",
    "axes_5[2, 1].set_ylabel(\"No. of Items\")\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(box_path_4 + today + '-fieldofstudybyscore.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
